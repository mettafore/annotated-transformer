{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bac703",
   "metadata": {
    "time_run": "2025-12-01T10:15:46.472829+00:00"
   },
   "outputs": [],
   "source": [
    "#|default_exp attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf1c3b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b22657e",
   "metadata": {
    "time_run": "2025-12-01T11:09:53.198620+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from IPython.core.magic import register_cell_magic\n",
    "from IPython.display import HTML, display\n",
    "import html\n",
    "import math\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da32e390",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1706.03762"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf3156",
   "metadata": {},
   "source": [
    "I will be doing an implementation of the seminal paper \"Attention Is All You Need.\" "
   ]
  },
  {
   "cell_type": "raw",
   "id": "e34f8575",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     formats: ipynb,py:percent\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: percent\n",
    "#       format_version: '1.3'\n",
    "#       jupytext_version: 1.13.0\n",
    "#   kernelspec:\n",
    "#     display_name: Python 3 (ipykernel)\n",
    "#     language: python\n",
    "#     name: python3\n",
    "# ---\n",
    "# %% [markdown] id=\"SX7UC-8jTsp7\" tags=[]\n",
    "#\n",
    "# <center><h1>The Annotated Transformer</h1> </center>\n",
    "#\n",
    "#\n",
    "# <center>\n",
    "# <p><a href=\"https://arxiv.org/abs/1706.03762\">Attention is All You Need\n",
    "# </a></p>\n",
    "# </center>\n",
    "#\n",
    "# <img src=\"images/aiayn.png\" width=\"70%\"/>\n",
    "#\n",
    "# * *v2022: Austin Huang, Suraj Subramanian, Jonathan Sum, Khalid Almubarak,\n",
    "#    and Stella Biderman.*\n",
    "# * *[Original](https://nlp.seas.harvard.edu/2018/04/03/attention.html):\n",
    "#    [Sasha Rush](http://rush-nlp.com/).*\n",
    "#\n",
    "#\n",
    "# The Transformer has been on a lot of\n",
    "# people's minds over the last <s>year</s> five years.\n",
    "# This post presents an annotated version of the paper in the\n",
    "# form of a line-by-line implementation. It reorders and deletes\n",
    "# some sections from the original paper and adds comments\n",
    "# throughout. This document itself is a working notebook, and should\n",
    "# be a completely usable implementation.\n",
    "# Code is available\n",
    "# [here](https://github.com/harvardnlp/annotated-transformer/).\n",
    "#\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"RSntDwKhTsp-\"\n",
    "# <h3> Table of Contents </h3>\n",
    "# <ul>\n",
    "# <li><a href=\"#prelims\">Prelims</a></li>\n",
    "# <li><a href=\"#background\">Background</a></li>\n",
    "# <li><a href=\"#part-1-model-architecture\">Part 1: Model Architecture</a></li>\n",
    "# <li><a href=\"#model-architecture\">Model Architecture</a><ul>\n",
    "# <li><a href=\"#encoder-and-decoder-stacks\">Encoder and Decoder Stacks</a></li>\n",
    "# <li><a href=\"#position-wise-feed-forward-networks\">Position-wise Feed-Forward\n",
    "# Networks</a></li>\n",
    "# <li><a href=\"#embeddings-and-softmax\">Embeddings and Softmax</a></li>\n",
    "# <li><a href=\"#positional-encoding\">Positional Encoding</a></li>\n",
    "# <li><a href=\"#full-model\">Full Model</a></li>\n",
    "# <li><a href=\"#inference\">Inference:</a></li>\n",
    "# </ul></li>\n",
    "# <li><a href=\"#part-2-model-training\">Part 2: Model Training</a></li>\n",
    "# <li><a href=\"#training\">Training</a><ul>\n",
    "# <li><a href=\"#batches-and-masking\">Batches and Masking</a></li>\n",
    "# <li><a href=\"#training-loop\">Training Loop</a></li>\n",
    "# <li><a href=\"#training-data-and-batching\">Training Data and Batching</a></li>\n",
    "# <li><a href=\"#hardware-and-schedule\">Hardware and Schedule</a></li>\n",
    "# <li><a href=\"#optimizer\">Optimizer</a></li>\n",
    "# <li><a href=\"#regularization\">Regularization</a></li>\n",
    "# </ul></li>\n",
    "# <li><a href=\"#a-first-example\">A First Example</a><ul>\n",
    "# <li><a href=\"#synthetic-data\">Synthetic Data</a></li>\n",
    "# <li><a href=\"#loss-computation\">Loss Computation</a></li>\n",
    "# <li><a href=\"#greedy-decoding\">Greedy Decoding</a></li>\n",
    "# </ul></li>\n",
    "# <li><a href=\"#part-3-a-real-world-example\">Part 3: A Real World Example</a>\n",
    "# <ul>\n",
    "# <li><a href=\"#data-loading\">Data Loading</a></li>\n",
    "# <li><a href=\"#iterators\">Iterators</a></li>\n",
    "# <li><a href=\"#training-the-system\">Training the System</a></li>\n",
    "# </ul></li>\n",
    "# <li><a href=\"#additional-components-bpe-search-averaging\">Additional\n",
    "# Components: BPE, Search, Averaging</a></li>\n",
    "# <li><a href=\"#results\">Results</a><ul>\n",
    "# <li><a href=\"#attention-visualization\">Attention Visualization</a></li>\n",
    "# <li><a href=\"#encoder-self-attention\">Encoder Self Attention</a></li>\n",
    "# <li><a href=\"#decoder-self-attention\">Decoder Self Attention</a></li>\n",
    "# <li><a href=\"#decoder-src-attention\">Decoder Src Attention</a></li>\n",
    "# </ul></li>\n",
    "# <li><a href=\"#conclusion\">Conclusion</a></li>\n",
    "# </ul>\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"BhmOhn9lTsp8\"\n",
    "# # Prelims\n",
    "#\n",
    "# <a href=\"#background\">Skip</a>\n",
    "\n",
    "# %% id=\"NwClcbH6Tsp8\"\n",
    "# # !pip install -r requirements.txt\n",
    "\n",
    "# %% id=\"NwClcbH6Tsp8\"\n",
    "# # Uncomment for colab\n",
    "# #\n",
    "# # !pip install -q torchdata==0.3.0 torchtext==0.12 spacy==3.2 altair GPUtil\n",
    "# # !python -m spacy download de_core_news_sm\n",
    "# # !python -m spacy download en_core_web_sm\n",
    "\n",
    "\n",
    "# %% id=\"v1-1MX6oTsp9\"\n",
    "import os\n",
    "from os.path import exists\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import log_softmax, pad\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext.datasets as datasets\n",
    "import spacy\n",
    "import GPUtil\n",
    "import warnings\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "\n",
    "# Set to False to skip notebook execution (e.g. for debugging)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RUN_EXAMPLES = True\n",
    "\n",
    "\n",
    "# %%\n",
    "# Some convenience helper functions used throughout the notebook\n",
    "\n",
    "\n",
    "def is_interactive_notebook():\n",
    "    return __name__ == \"__main__\"\n",
    "\n",
    "\n",
    "def show_example(fn, args=[]):\n",
    "    if __name__ == \"__main__\" and RUN_EXAMPLES:\n",
    "        return fn(*args)\n",
    "\n",
    "\n",
    "def execute_example(fn, args=[]):\n",
    "    if __name__ == \"__main__\" and RUN_EXAMPLES:\n",
    "        fn(*args)\n",
    "\n",
    "\n",
    "class DummyOptimizer(torch.optim.Optimizer):\n",
    "    def __init__(self):\n",
    "        self.param_groups = [{\"lr\": 0}]\n",
    "        None\n",
    "\n",
    "    def step(self):\n",
    "        None\n",
    "\n",
    "    def zero_grad(self, set_to_none=False):\n",
    "        None\n",
    "\n",
    "\n",
    "class DummyScheduler:\n",
    "    def step(self):\n",
    "        None\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"jx49WRyfTsp-\"\n",
    "# > My comments are blockquoted. The main text is all from the paper itself.\n",
    "\n",
    "# %% [markdown] id=\"7phVeWghTsp_\"\n",
    "# # Background\n",
    "\n",
    "# %% [markdown] id=\"83ZDS91dTsqA\"\n",
    "#\n",
    "# The goal of reducing sequential computation also forms the\n",
    "# foundation of the Extended Neural GPU, ByteNet and ConvS2S, all of\n",
    "# which use convolutional neural networks as basic building block,\n",
    "# computing hidden representations in parallel for all input and\n",
    "# output positions. In these models, the number of operations required\n",
    "# to relate signals from two arbitrary input or output positions grows\n",
    "# in the distance between positions, linearly for ConvS2S and\n",
    "# logarithmically for ByteNet. This makes it more difficult to learn\n",
    "# dependencies between distant positions. In the Transformer this is\n",
    "# reduced to a constant number of operations, albeit at the cost of\n",
    "# reduced effective resolution due to averaging attention-weighted\n",
    "# positions, an effect we counteract with Multi-Head Attention.\n",
    "#\n",
    "# Self-attention, sometimes called intra-attention is an attention\n",
    "# mechanism relating different positions of a single sequence in order\n",
    "# to compute a representation of the sequence. Self-attention has been\n",
    "# used successfully in a variety of tasks including reading\n",
    "# comprehension, abstractive summarization, textual entailment and\n",
    "# learning task-independent sentence representations. End-to-end\n",
    "# memory networks are based on a recurrent attention mechanism instead\n",
    "# of sequencealigned recurrence and have been shown to perform well on\n",
    "# simple-language question answering and language modeling tasks.\n",
    "#\n",
    "# To the best of our knowledge, however, the Transformer is the first\n",
    "# transduction model relying entirely on self-attention to compute\n",
    "# representations of its input and output without using sequence\n",
    "# aligned RNNs or convolution.\n",
    "\n",
    "# %% [markdown]\n",
    "# # Part 1: Model Architecture\n",
    "\n",
    "# %% [markdown] id=\"pFrPajezTsqB\"\n",
    "# # Model Architecture\n",
    "\n",
    "# %% [markdown] id=\"ReuU_h-fTsqB\"\n",
    "#\n",
    "# Most competitive neural sequence transduction models have an\n",
    "# encoder-decoder structure\n",
    "# [(cite)](https://arxiv.org/abs/1409.0473). Here, the encoder maps an\n",
    "# input sequence of symbol representations $(x_1, ..., x_n)$ to a\n",
    "# sequence of continuous representations $\\mathbf{z} = (z_1, ...,\n",
    "# z_n)$. Given $\\mathbf{z}$, the decoder then generates an output\n",
    "# sequence $(y_1,...,y_m)$ of symbols one element at a time. At each\n",
    "# step the model is auto-regressive\n",
    "# [(cite)](https://arxiv.org/abs/1308.0850), consuming the previously\n",
    "# generated symbols as additional input when generating the next.\n",
    "\n",
    "# %% id=\"k0XGXhzRTsqB\"\n",
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many\n",
    "    other models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
    "\n",
    "\n",
    "# %% id=\"NKGoH2RsTsqC\"\n",
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return log_softmax(self.proj(x), dim=-1)\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"mOoEnF_jTsqC\"\n",
    "#\n",
    "# The Transformer follows this overall architecture using stacked\n",
    "# self-attention and point-wise, fully connected layers for both the\n",
    "# encoder and decoder, shown in the left and right halves of Figure 1,\n",
    "# respectively.\n",
    "\n",
    "# %% [markdown] id=\"oredWloYTsqC\"\n",
    "# ![](images/ModalNet-21.png)\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"bh092NZBTsqD\"\n",
    "# ## Encoder and Decoder Stacks\n",
    "#\n",
    "# ### Encoder\n",
    "#\n",
    "# The encoder is composed of a stack of $N=6$ identical layers.\n",
    "\n",
    "# %% id=\"2gxTApUYTsqD\"\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "\n",
    "# %% id=\"xqVTz9MkTsqD\"\n",
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"GjAKgjGwTsqD\"\n",
    "#\n",
    "# We employ a residual connection\n",
    "# [(cite)](https://arxiv.org/abs/1512.03385) around each of the two\n",
    "# sub-layers, followed by layer normalization\n",
    "# [(cite)](https://arxiv.org/abs/1607.06450).\n",
    "\n",
    "# %% id=\"3jKa_prZTsqE\"\n",
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"nXSJ3QYmTsqE\"\n",
    "#\n",
    "# That is, the output of each sub-layer is $\\mathrm{LayerNorm}(x +\n",
    "# \\mathrm{Sublayer}(x))$, where $\\mathrm{Sublayer}(x)$ is the function\n",
    "# implemented by the sub-layer itself.  We apply dropout\n",
    "# [(cite)](http://jmlr.org/papers/v15/srivastava14a.html) to the\n",
    "# output of each sub-layer, before it is added to the sub-layer input\n",
    "# and normalized.\n",
    "#\n",
    "# To facilitate these residual connections, all sub-layers in the\n",
    "# model, as well as the embedding layers, produce outputs of dimension\n",
    "# $d_{\\text{model}}=512$.\n",
    "\n",
    "# %% id=\"U1P7zI0eTsqE\"\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"ML6oDlEqTsqE\"\n",
    "#\n",
    "# Each layer has two sub-layers. The first is a multi-head\n",
    "# self-attention mechanism, and the second is a simple, position-wise\n",
    "# fully connected feed-forward network.\n",
    "\n",
    "# %% id=\"qYkUFr6GTsqE\"\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"7ecOQIhkTsqF\"\n",
    "# ### Decoder\n",
    "#\n",
    "# The decoder is also composed of a stack of $N=6$ identical layers.\n",
    "#\n",
    "\n",
    "# %%\n",
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"dXlCB12pTsqF\"\n",
    "#\n",
    "# In addition to the two sub-layers in each encoder layer, the decoder\n",
    "# inserts a third sub-layer, which performs multi-head attention over\n",
    "# the output of the encoder stack.  Similar to the encoder, we employ\n",
    "# residual connections around each of the sub-layers, followed by\n",
    "# layer normalization.\n",
    "\n",
    "# %% id=\"M2hA1xFQTsqF\"\n",
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"FZz5rLl4TsqF\"\n",
    "#\n",
    "# We also modify the self-attention sub-layer in the decoder stack to\n",
    "# prevent positions from attending to subsequent positions.  This\n",
    "# masking, combined with fact that the output embeddings are offset by\n",
    "# one position, ensures that the predictions for position $i$ can\n",
    "# depend only on the known outputs at positions less than $i$.\n",
    "\n",
    "# %% id=\"QN98O2l3TsqF\"\n",
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
    "        torch.uint8\n",
    "    )\n",
    "    return subsequent_mask == 0\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"Vg_f_w-PTsqG\"\n",
    "#\n",
    "# > Below the attention mask shows the position each tgt word (row) is\n",
    "# > allowed to look at (column). Words are blocked for attending to\n",
    "# > future words during training.\n",
    "\n",
    "# %% id=\"ht_FtgYAokC4\"\n",
    "def example_mask():\n",
    "    LS_data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Subsequent Mask\": subsequent_mask(20)[0][x, y].flatten(),\n",
    "                    \"Window\": y,\n",
    "                    \"Masking\": x,\n",
    "                }\n",
    "            )\n",
    "            for y in range(20)\n",
    "            for x in range(20)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        alt.Chart(LS_data)\n",
    "        .mark_rect()\n",
    "        .properties(height=250, width=250)\n",
    "        .encode(\n",
    "            alt.X(\"Window:O\"),\n",
    "            alt.Y(\"Masking:O\"),\n",
    "            alt.Color(\"Subsequent Mask:Q\", scale=alt.Scale(scheme=\"viridis\")),\n",
    "        )\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "\n",
    "show_example(example_mask)\n",
    "\n",
    "# %% [markdown] id=\"Qto_yg7BTsqG\"\n",
    "# ### Attention\n",
    "#\n",
    "# An attention function can be described as mapping a query and a set\n",
    "# of key-value pairs to an output, where the query, keys, values, and\n",
    "# output are all vectors.  The output is computed as a weighted sum of\n",
    "# the values, where the weight assigned to each value is computed by a\n",
    "# compatibility function of the query with the corresponding key.\n",
    "#\n",
    "# We call our particular attention \"Scaled Dot-Product Attention\".\n",
    "# The input consists of queries and keys of dimension $d_k$, and\n",
    "# values of dimension $d_v$.  We compute the dot products of the query\n",
    "# with all keys, divide each by $\\sqrt{d_k}$, and apply a softmax\n",
    "# function to obtain the weights on the values.\n",
    "#\n",
    "#\n",
    "#\n",
    "# ![](images/ModalNet-19.png)\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"EYJLWk6cTsqG\"\n",
    "#\n",
    "# In practice, we compute the attention function on a set of queries\n",
    "# simultaneously, packed together into a matrix $Q$.  The keys and\n",
    "# values are also packed together into matrices $K$ and $V$.  We\n",
    "# compute the matrix of outputs as:\n",
    "#\n",
    "# $$\n",
    "#    \\mathrm{Attention}(Q, K, V) = \\mathrm{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V\n",
    "# $$\n",
    "\n",
    "# %% id=\"qsoVxS5yTsqG\"\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = scores.softmax(dim=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"jUkpwu8kTsqG\"\n",
    "#\n",
    "# The two most commonly used attention functions are additive\n",
    "# attention [(cite)](https://arxiv.org/abs/1409.0473), and dot-product\n",
    "# (multiplicative) attention.  Dot-product attention is identical to\n",
    "# our algorithm, except for the scaling factor of\n",
    "# $\\frac{1}{\\sqrt{d_k}}$. Additive attention computes the\n",
    "# compatibility function using a feed-forward network with a single\n",
    "# hidden layer.  While the two are similar in theoretical complexity,\n",
    "# dot-product attention is much faster and more space-efficient in\n",
    "# practice, since it can be implemented using highly optimized matrix\n",
    "# multiplication code.\n",
    "#\n",
    "#\n",
    "# While for small values of $d_k$ the two mechanisms perform\n",
    "# similarly, additive attention outperforms dot product attention\n",
    "# without scaling for larger values of $d_k$\n",
    "# [(cite)](https://arxiv.org/abs/1703.03906). We suspect that for\n",
    "# large values of $d_k$, the dot products grow large in magnitude,\n",
    "# pushing the softmax function into regions where it has extremely\n",
    "# small gradients (To illustrate why the dot products get large,\n",
    "# assume that the components of $q$ and $k$ are independent random\n",
    "# variables with mean $0$ and variance $1$.  Then their dot product,\n",
    "# $q \\cdot k = \\sum_{i=1}^{d_k} q_ik_i$, has mean $0$ and variance\n",
    "# $d_k$.). To counteract this effect, we scale the dot products by\n",
    "# $\\frac{1}{\\sqrt{d_k}}$.\n",
    "#\n",
    "#\n",
    "\n",
    "# %% [markdown] id=\"bS1FszhVTsqG\"\n",
    "# ![](images/ModalNet-20.png)\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"TNtVyZ-pTsqH\"\n",
    "#\n",
    "# Multi-head attention allows the model to jointly attend to\n",
    "# information from different representation subspaces at different\n",
    "# positions. With a single attention head, averaging inhibits this.\n",
    "#\n",
    "# $$\n",
    "# \\mathrm{MultiHead}(Q, K, V) =\n",
    "#     \\mathrm{Concat}(\\mathrm{head_1}, ..., \\mathrm{head_h})W^O \\\\\n",
    "#     \\text{where}~\\mathrm{head_i} = \\mathrm{Attention}(QW^Q_i, KW^K_i, VW^V_i)\n",
    "# $$\n",
    "#\n",
    "# Where the projections are parameter matrices $W^Q_i \\in\n",
    "# \\mathbb{R}^{d_{\\text{model}} \\times d_k}$, $W^K_i \\in\n",
    "# \\mathbb{R}^{d_{\\text{model}} \\times d_k}$, $W^V_i \\in\n",
    "# \\mathbb{R}^{d_{\\text{model}} \\times d_v}$ and $W^O \\in\n",
    "# \\mathbb{R}^{hd_v \\times d_{\\text{model}}}$.\n",
    "#\n",
    "# In this work we employ $h=8$ parallel attention layers, or\n",
    "# heads. For each of these we use $d_k=d_v=d_{\\text{model}}/h=64$. Due\n",
    "# to the reduced dimension of each head, the total computational cost\n",
    "# is similar to that of single-head attention with full\n",
    "# dimensionality.\n",
    "\n",
    "# %% id=\"D2LBMKCQTsqH\"\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = [\n",
    "            lin(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "            for lin, x in zip(self.linears, (query, key, value))\n",
    "        ]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = attention(\n",
    "            query, key, value, mask=mask, dropout=self.dropout\n",
    "        )\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = (\n",
    "            x.transpose(1, 2)\n",
    "            .contiguous()\n",
    "            .view(nbatches, -1, self.h * self.d_k)\n",
    "        )\n",
    "        del query\n",
    "        del key\n",
    "        del value\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"EDRba3J3TsqH\"\n",
    "# ### Applications of Attention in our Model\n",
    "#\n",
    "# The Transformer uses multi-head attention in three different ways:\n",
    "# 1) In \"encoder-decoder attention\" layers, the queries come from the\n",
    "# previous decoder layer, and the memory keys and values come from the\n",
    "# output of the encoder.  This allows every position in the decoder to\n",
    "# attend over all positions in the input sequence.  This mimics the\n",
    "# typical encoder-decoder attention mechanisms in sequence-to-sequence\n",
    "# models such as [(cite)](https://arxiv.org/abs/1609.08144).\n",
    "#\n",
    "#\n",
    "# 2) The encoder contains self-attention layers.  In a self-attention\n",
    "# layer all of the keys, values and queries come from the same place,\n",
    "# in this case, the output of the previous layer in the encoder.  Each\n",
    "# position in the encoder can attend to all positions in the previous\n",
    "# layer of the encoder.\n",
    "#\n",
    "#\n",
    "# 3) Similarly, self-attention layers in the decoder allow each\n",
    "# position in the decoder to attend to all positions in the decoder up\n",
    "# to and including that position.  We need to prevent leftward\n",
    "# information flow in the decoder to preserve the auto-regressive\n",
    "# property.  We implement this inside of scaled dot-product attention\n",
    "# by masking out (setting to $-\\infty$) all values in the input of the\n",
    "# softmax which correspond to illegal connections.\n",
    "\n",
    "# %% [markdown] id=\"M-en97_GTsqH\"\n",
    "# ## Position-wise Feed-Forward Networks\n",
    "#\n",
    "# In addition to attention sub-layers, each of the layers in our\n",
    "# encoder and decoder contains a fully connected feed-forward network,\n",
    "# which is applied to each position separately and identically.  This\n",
    "# consists of two linear transformations with a ReLU activation in\n",
    "# between.\n",
    "#\n",
    "# $$\\mathrm{FFN}(x)=\\max(0, xW_1 + b_1) W_2 + b_2$$\n",
    "#\n",
    "# While the linear transformations are the same across different\n",
    "# positions, they use different parameters from layer to\n",
    "# layer. Another way of describing this is as two convolutions with\n",
    "# kernel size 1.  The dimensionality of input and output is\n",
    "# $d_{\\text{model}}=512$, and the inner-layer has dimensionality\n",
    "# $d_{ff}=2048$.\n",
    "\n",
    "# %% id=\"6HHCemCxTsqH\"\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(self.w_1(x).relu()))\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"dR1YM520TsqH\"\n",
    "# ## Embeddings and Softmax\n",
    "#\n",
    "# Similarly to other sequence transduction models, we use learned\n",
    "# embeddings to convert the input tokens and output tokens to vectors\n",
    "# of dimension $d_{\\text{model}}$.  We also use the usual learned\n",
    "# linear transformation and softmax function to convert the decoder\n",
    "# output to predicted next-token probabilities.  In our model, we\n",
    "# share the same weight matrix between the two embedding layers and\n",
    "# the pre-softmax linear transformation, similar to\n",
    "# [(cite)](https://arxiv.org/abs/1608.05859). In the embedding layers,\n",
    "# we multiply those weights by $\\sqrt{d_{\\text{model}}}$.\n",
    "\n",
    "# %% id=\"pyrChq9qTsqH\"\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"vOkdui-cTsqH\"\n",
    "# ## Positional Encoding\n",
    "#\n",
    "# Since our model contains no recurrence and no convolution, in order\n",
    "# for the model to make use of the order of the sequence, we must\n",
    "# inject some information about the relative or absolute position of\n",
    "# the tokens in the sequence.  To this end, we add \"positional\n",
    "# encodings\" to the input embeddings at the bottoms of the encoder and\n",
    "# decoder stacks.  The positional encodings have the same dimension\n",
    "# $d_{\\text{model}}$ as the embeddings, so that the two can be summed.\n",
    "# There are many choices of positional encodings, learned and fixed\n",
    "# [(cite)](https://arxiv.org/pdf/1705.03122.pdf).\n",
    "#\n",
    "# In this work, we use sine and cosine functions of different frequencies:\n",
    "#\n",
    "# $$PE_{(pos,2i)} = \\sin(pos / 10000^{2i/d_{\\text{model}}})$$\n",
    "#\n",
    "# $$PE_{(pos,2i+1)} = \\cos(pos / 10000^{2i/d_{\\text{model}}})$$\n",
    "#\n",
    "# where $pos$ is the position and $i$ is the dimension.  That is, each\n",
    "# dimension of the positional encoding corresponds to a sinusoid.  The\n",
    "# wavelengths form a geometric progression from $2\\pi$ to $10000 \\cdot\n",
    "# 2\\pi$.  We chose this function because we hypothesized it would\n",
    "# allow the model to easily learn to attend by relative positions,\n",
    "# since for any fixed offset $k$, $PE_{pos+k}$ can be represented as a\n",
    "# linear function of $PE_{pos}$.\n",
    "#\n",
    "# In addition, we apply dropout to the sums of the embeddings and the\n",
    "# positional encodings in both the encoder and decoder stacks.  For\n",
    "# the base model, we use a rate of $P_{drop}=0.1$.\n",
    "#\n",
    "#\n",
    "\n",
    "# %% id=\"zaHGD4yJTsqH\"\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"EfHacTJLTsqH\"\n",
    "#\n",
    "# > Below the positional encoding will add in a sine wave based on\n",
    "# > position. The frequency and offset of the wave is different for\n",
    "# > each dimension.\n",
    "\n",
    "# %% id=\"rnvHk_1QokC6\" type=\"example\"\n",
    "def example_positional():\n",
    "    pe = PositionalEncoding(20, 0)\n",
    "    y = pe.forward(torch.zeros(1, 100, 20))\n",
    "\n",
    "    data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"embedding\": y[0, :, dim],\n",
    "                    \"dimension\": dim,\n",
    "                    \"position\": list(range(100)),\n",
    "                }\n",
    "            )\n",
    "            for dim in [4, 5, 6, 7]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        alt.Chart(data)\n",
    "        .mark_line()\n",
    "        .properties(width=800)\n",
    "        .encode(x=\"position\", y=\"embedding\", color=\"dimension:N\")\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "\n",
    "show_example(example_positional)\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"g8rZNCrzTsqI\"\n",
    "#\n",
    "# We also experimented with using learned positional embeddings\n",
    "# [(cite)](https://arxiv.org/pdf/1705.03122.pdf) instead, and found\n",
    "# that the two versions produced nearly identical results.  We chose\n",
    "# the sinusoidal version because it may allow the model to extrapolate\n",
    "# to sequence lengths longer than the ones encountered during\n",
    "# training.\n",
    "\n",
    "# %% [markdown] id=\"iwNKCzlyTsqI\"\n",
    "# ## Full Model\n",
    "#\n",
    "# > Here we define a function from hyperparameters to a full model.\n",
    "\n",
    "# %% id=\"mPe1ES0UTsqI\"\n",
    "def make_model(\n",
    "    src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1\n",
    "):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab),\n",
    "    )\n",
    "\n",
    "    # This was important from their code.\n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Inference:\n",
    "#\n",
    "# > Here we make a forward step to generate a prediction of the\n",
    "# model. We try to use our transformer to memorize the input. As you\n",
    "# will see the output is randomly generated due to the fact that the\n",
    "# model is not trained yet. In the next tutorial we will build the\n",
    "# training function and try to train our model to memorize the numbers\n",
    "# from 1 to 10.\n",
    "\n",
    "# %%\n",
    "def inference_test():\n",
    "    test_model = make_model(11, 11, 2)\n",
    "    test_model.eval()\n",
    "    src = torch.LongTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "    src_mask = torch.ones(1, 1, 10)\n",
    "\n",
    "    memory = test_model.encode(src, src_mask)\n",
    "    ys = torch.zeros(1, 1).type_as(src)\n",
    "\n",
    "    for i in range(9):\n",
    "        out = test_model.decode(\n",
    "            memory, src_mask, ys, subsequent_mask(ys.size(1)).type_as(src.data)\n",
    "        )\n",
    "        prob = test_model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat(\n",
    "            [ys, torch.empty(1, 1).type_as(src.data).fill_(next_word)], dim=1\n",
    "        )\n",
    "\n",
    "    print(\"Example Untrained Model Prediction:\", ys)\n",
    "\n",
    "\n",
    "def run_tests():\n",
    "    for _ in range(10):\n",
    "        inference_test()\n",
    "\n",
    "\n",
    "show_example(run_tests)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# # Part 2: Model Training\n",
    "\n",
    "# %% [markdown] id=\"05s6oT9fTsqI\"\n",
    "# # Training\n",
    "#\n",
    "# This section describes the training regime for our models.\n",
    "\n",
    "# %% [markdown] id=\"fTxlofs4TsqI\"\n",
    "#\n",
    "# > We stop for a quick interlude to introduce some of the tools\n",
    "# > needed to train a standard encoder decoder model. First we define a\n",
    "# > batch object that holds the src and target sentences for training,\n",
    "# > as well as constructing the masks.\n",
    "\n",
    "# %% [markdown] id=\"G7SkCenXTsqI\"\n",
    "# ## Batches and Masking\n",
    "\n",
    "# %%\n",
    "class Batch:\n",
    "    \"\"\"Object for holding a batch of data with mask during training.\"\"\"\n",
    "\n",
    "    def __init__(self, src, tgt=None, pad=2):  # 2 = <blank>\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        if tgt is not None:\n",
    "            self.tgt = tgt[:, :-1]\n",
    "            self.tgt_y = tgt[:, 1:]\n",
    "            self.tgt_mask = self.make_std_mask(self.tgt, pad)\n",
    "            self.ntokens = (self.tgt_y != pad).data.sum()\n",
    "\n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)).type_as(\n",
    "            tgt_mask.data\n",
    "        )\n",
    "        return tgt_mask\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"cKkw5GjLTsqI\"\n",
    "#\n",
    "# > Next we create a generic training and scoring function to keep\n",
    "# > track of loss. We pass in a generic loss compute function that\n",
    "# > also handles parameter updates.\n",
    "\n",
    "# %% [markdown] id=\"Q8zzeUc0TsqJ\"\n",
    "# ## Training Loop\n",
    "\n",
    "# %%\n",
    "class TrainState:\n",
    "    \"\"\"Track number of steps, examples, and tokens processed\"\"\"\n",
    "\n",
    "    step: int = 0  # Steps in the current epoch\n",
    "    accum_step: int = 0  # Number of gradient accumulation steps\n",
    "    samples: int = 0  # total # of examples used\n",
    "    tokens: int = 0  # total # of tokens processed\n",
    "\n",
    "\n",
    "# %% id=\"2HAZD3hiTsqJ\"\n",
    "def run_epoch(\n",
    "    data_iter,\n",
    "    model,\n",
    "    loss_compute,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    mode=\"train\",\n",
    "    accum_iter=1,\n",
    "    train_state=TrainState(),\n",
    "):\n",
    "    \"\"\"Train a single epoch\"\"\"\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    n_accum = 0\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        out = model.forward(\n",
    "            batch.src, batch.tgt, batch.src_mask, batch.tgt_mask\n",
    "        )\n",
    "        loss, loss_node = loss_compute(out, batch.tgt_y, batch.ntokens)\n",
    "        # loss_node = loss_node / accum_iter\n",
    "        if mode == \"train\" or mode == \"train+log\":\n",
    "            loss_node.backward()\n",
    "            train_state.step += 1\n",
    "            train_state.samples += batch.src.shape[0]\n",
    "            train_state.tokens += batch.ntokens\n",
    "            if i % accum_iter == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                n_accum += 1\n",
    "                train_state.accum_step += 1\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "        if i % 40 == 1 and (mode == \"train\" or mode == \"train+log\"):\n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            elapsed = time.time() - start\n",
    "            print(\n",
    "                (\n",
    "                    \"Epoch Step: %6d | Accumulation Step: %3d | Loss: %6.2f \"\n",
    "                    + \"| Tokens / Sec: %7.1f | Learning Rate: %6.1e\"\n",
    "                )\n",
    "                % (i, n_accum, loss / batch.ntokens, tokens / elapsed, lr)\n",
    "            )\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "        del loss\n",
    "        del loss_node\n",
    "    return total_loss / total_tokens, train_state\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"aB1IF0foTsqJ\"\n",
    "# ## Training Data and Batching\n",
    "#\n",
    "# We trained on the standard WMT 2014 English-German dataset\n",
    "# consisting of about 4.5 million sentence pairs.  Sentences were\n",
    "# encoded using byte-pair encoding, which has a shared source-target\n",
    "# vocabulary of about 37000 tokens. For English-French, we used the\n",
    "# significantly larger WMT 2014 English-French dataset consisting of\n",
    "# 36M sentences and split tokens into a 32000 word-piece vocabulary.\n",
    "#\n",
    "#\n",
    "# Sentence pairs were batched together by approximate sequence length.\n",
    "# Each training batch contained a set of sentence pairs containing\n",
    "# approximately 25000 source tokens and 25000 target tokens.\n",
    "\n",
    "# %% [markdown] id=\"F1mTQatiTsqJ\" jp-MarkdownHeadingCollapsed=true tags=[]\n",
    "# ## Hardware and Schedule\n",
    "#\n",
    "# We trained our models on one machine with 8 NVIDIA P100 GPUs.  For\n",
    "# our base models using the hyperparameters described throughout the\n",
    "# paper, each training step took about 0.4 seconds.  We trained the\n",
    "# base models for a total of 100,000 steps or 12 hours. For our big\n",
    "# models, step time was 1.0 seconds.  The big models were trained for\n",
    "# 300,000 steps (3.5 days).\n",
    "\n",
    "# %% [markdown] id=\"-utZeuGcTsqJ\"\n",
    "# ## Optimizer\n",
    "#\n",
    "# We used the Adam optimizer [(cite)](https://arxiv.org/abs/1412.6980)\n",
    "# with $\\beta_1=0.9$, $\\beta_2=0.98$ and $\\epsilon=10^{-9}$.  We\n",
    "# varied the learning rate over the course of training, according to\n",
    "# the formula:\n",
    "#\n",
    "# $$\n",
    "# lrate = d_{\\text{model}}^{-0.5} \\cdot\n",
    "#   \\min({step\\_num}^{-0.5},\n",
    "#     {step\\_num} \\cdot {warmup\\_steps}^{-1.5})\n",
    "# $$\n",
    "#\n",
    "# This corresponds to increasing the learning rate linearly for the\n",
    "# first $warmup\\_steps$ training steps, and decreasing it thereafter\n",
    "# proportionally to the inverse square root of the step number.  We\n",
    "# used $warmup\\_steps=4000$.\n",
    "\n",
    "# %% [markdown] id=\"39FbYnt-TsqJ\"\n",
    "#\n",
    "# > Note: This part is very important. Need to train with this setup\n",
    "# > of the model.\n",
    "\n",
    "# %% [markdown] id=\"hlbojFkjTsqJ\"\n",
    "#\n",
    "# > Example of the curves of this model for different model sizes and\n",
    "# > for optimization hyperparameters.\n",
    "\n",
    "# %% id=\"zUz3PdAnVg4o\"\n",
    "def rate(step, model_size, factor, warmup):\n",
    "    \"\"\"\n",
    "    we have to default the step to 1 for LambdaLR function\n",
    "    to avoid zero raising to negative power.\n",
    "    \"\"\"\n",
    "    if step == 0:\n",
    "        step = 1\n",
    "    return factor * (\n",
    "        model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5))\n",
    "    )\n",
    "\n",
    "\n",
    "# %% id=\"l1bnrlnSV8J5\" tags=[]\n",
    "def example_learning_schedule():\n",
    "    opts = [\n",
    "        [512, 1, 4000],  # example 1\n",
    "        [512, 1, 8000],  # example 2\n",
    "        [256, 1, 4000],  # example 3\n",
    "    ]\n",
    "\n",
    "    dummy_model = torch.nn.Linear(1, 1)\n",
    "    learning_rates = []\n",
    "\n",
    "    # we have 3 examples in opts list.\n",
    "    for idx, example in enumerate(opts):\n",
    "        # run 20000 epoch for each example\n",
    "        optimizer = torch.optim.Adam(\n",
    "            dummy_model.parameters(), lr=1, betas=(0.9, 0.98), eps=1e-9\n",
    "        )\n",
    "        lr_scheduler = LambdaLR(\n",
    "            optimizer=optimizer, lr_lambda=lambda step: rate(step, *example)\n",
    "        )\n",
    "        tmp = []\n",
    "        # take 20K dummy training steps, save the learning rate at each step\n",
    "        for step in range(20000):\n",
    "            tmp.append(optimizer.param_groups[0][\"lr\"])\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "        learning_rates.append(tmp)\n",
    "\n",
    "    learning_rates = torch.tensor(learning_rates)\n",
    "\n",
    "    # Enable altair to handle more than 5000 rows\n",
    "    alt.data_transformers.disable_max_rows()\n",
    "\n",
    "    opts_data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Learning Rate\": learning_rates[warmup_idx, :],\n",
    "                    \"model_size:warmup\": [\"512:4000\", \"512:8000\", \"256:4000\"][\n",
    "                        warmup_idx\n",
    "                    ],\n",
    "                    \"step\": range(20000),\n",
    "                }\n",
    "            )\n",
    "            for warmup_idx in [0, 1, 2]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        alt.Chart(opts_data)\n",
    "        .mark_line()\n",
    "        .properties(width=600)\n",
    "        .encode(x=\"step\", y=\"Learning Rate\", color=\"model_size:warmup:N\")\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "\n",
    "example_learning_schedule()\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"7T1uD15VTsqK\"\n",
    "# ## Regularization\n",
    "#\n",
    "# ### Label Smoothing\n",
    "#\n",
    "# During training, we employed label smoothing of value\n",
    "# $\\epsilon_{ls}=0.1$ [(cite)](https://arxiv.org/abs/1512.00567).\n",
    "# This hurts perplexity, as the model learns to be more unsure, but\n",
    "# improves accuracy and BLEU score.\n",
    "\n",
    "# %% [markdown] id=\"kNoAVD8bTsqK\"\n",
    "#\n",
    "# > We implement label smoothing using the KL div loss. Instead of\n",
    "# > using a one-hot target distribution, we create a distribution that\n",
    "# > has `confidence` of the correct word and the rest of the\n",
    "# > `smoothing` mass distributed throughout the vocabulary.\n",
    "\n",
    "# %% id=\"shU2GyiETsqK\"\n",
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(reduction=\"sum\")\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, true_dist.clone().detach())\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"jCxUrlUyTsqK\"\n",
    "#\n",
    "# > Here we can see an example of how the mass is distributed to the\n",
    "# > words based on confidence.\n",
    "\n",
    "# %% id=\"EZtKaaQNTsqK\"\n",
    "# Example of label smoothing.\n",
    "\n",
    "\n",
    "def example_label_smoothing():\n",
    "    crit = LabelSmoothing(5, 0, 0.4)\n",
    "    predict = torch.FloatTensor(\n",
    "        [\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "        ]\n",
    "    )\n",
    "    crit(x=predict.log(), target=torch.LongTensor([2, 1, 0, 3, 3]))\n",
    "    LS_data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"target distribution\": crit.true_dist[x, y].flatten(),\n",
    "                    \"columns\": y,\n",
    "                    \"rows\": x,\n",
    "                }\n",
    "            )\n",
    "            for y in range(5)\n",
    "            for x in range(5)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        alt.Chart(LS_data)\n",
    "        .mark_rect(color=\"Blue\", opacity=1)\n",
    "        .properties(height=200, width=200)\n",
    "        .encode(\n",
    "            alt.X(\"columns:O\", title=None),\n",
    "            alt.Y(\"rows:O\", title=None),\n",
    "            alt.Color(\n",
    "                \"target distribution:Q\", scale=alt.Scale(scheme=\"viridis\")\n",
    "            ),\n",
    "        )\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "\n",
    "show_example(example_label_smoothing)\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"CGM8J1veTsqK\"\n",
    "#\n",
    "# > Label smoothing actually starts to penalize the model if it gets\n",
    "# > very confident about a given choice.\n",
    "\n",
    "# %% id=\"78EHzLP7TsqK\"\n",
    "\n",
    "\n",
    "def loss(x, crit):\n",
    "    d = x + 3 * 1\n",
    "    predict = torch.FloatTensor([[0, x / d, 1 / d, 1 / d, 1 / d]])\n",
    "    return crit(predict.log(), torch.LongTensor([1])).data\n",
    "\n",
    "\n",
    "def penalization_visualization():\n",
    "    crit = LabelSmoothing(5, 0, 0.1)\n",
    "    loss_data = pd.DataFrame(\n",
    "        {\n",
    "            \"Loss\": [loss(x, crit) for x in range(1, 100)],\n",
    "            \"Steps\": list(range(99)),\n",
    "        }\n",
    "    ).astype(\"float\")\n",
    "\n",
    "    return (\n",
    "        alt.Chart(loss_data)\n",
    "        .mark_line()\n",
    "        .properties(width=350)\n",
    "        .encode(\n",
    "            x=\"Steps\",\n",
    "            y=\"Loss\",\n",
    "        )\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "\n",
    "show_example(penalization_visualization)\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"67lUqeLXTsqK\"\n",
    "# # A First  Example\n",
    "#\n",
    "# > We can begin by trying out a simple copy-task. Given a random set\n",
    "# > of input symbols from a small vocabulary, the goal is to generate\n",
    "# > back those same symbols.\n",
    "\n",
    "# %% [markdown] id=\"jJa-89_pTsqK\"\n",
    "# ## Synthetic Data\n",
    "\n",
    "# %% id=\"g1aTxeqqTsqK\"\n",
    "def data_gen(V, batch_size, nbatches):\n",
    "    \"Generate random data for a src-tgt copy task.\"\n",
    "    for i in range(nbatches):\n",
    "        data = torch.randint(1, V, size=(batch_size, 10))\n",
    "        data[:, 0] = 1\n",
    "        src = data.requires_grad_(False).clone().detach()\n",
    "        tgt = data.requires_grad_(False).clone().detach()\n",
    "        yield Batch(src, tgt, 0)\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"XTXwD9hUTsqK\"\n",
    "# ## Loss Computation\n",
    "\n",
    "# %% id=\"3J8EJm87TsqK\"\n",
    "class SimpleLossCompute:\n",
    "    \"A simple loss compute and train function.\"\n",
    "\n",
    "    def __init__(self, generator, criterion):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        sloss = (\n",
    "            self.criterion(\n",
    "                x.contiguous().view(-1, x.size(-1)), y.contiguous().view(-1)\n",
    "            )\n",
    "            / norm\n",
    "        )\n",
    "        return sloss.data * norm, sloss\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"eDAI7ELUTsqL\"\n",
    "# ## Greedy Decoding\n",
    "\n",
    "# %% [markdown] id=\"LFkWakplTsqL\" tags=[]\n",
    "# > This code predicts a translation using greedy decoding for simplicity.\n",
    "# %% id=\"N2UOpnT3bIyU\"\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.zeros(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len - 1):\n",
    "        out = model.decode(\n",
    "            memory, src_mask, ys, subsequent_mask(ys.size(1)).type_as(src.data)\n",
    "        )\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat(\n",
    "            [ys, torch.zeros(1, 1).type_as(src.data).fill_(next_word)], dim=1\n",
    "        )\n",
    "    return ys\n",
    "\n",
    "\n",
    "# %% id=\"qgIZ2yEtdYwe\" tags=[]\n",
    "# Train the simple copy task.\n",
    "\n",
    "\n",
    "def example_simple_model():\n",
    "    V = 11\n",
    "    criterion = LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)\n",
    "    model = make_model(V, V, N=2)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=0.5, betas=(0.9, 0.98), eps=1e-9\n",
    "    )\n",
    "    lr_scheduler = LambdaLR(\n",
    "        optimizer=optimizer,\n",
    "        lr_lambda=lambda step: rate(\n",
    "            step, model_size=model.src_embed[0].d_model, factor=1.0, warmup=400\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    batch_size = 80\n",
    "    for epoch in range(20):\n",
    "        model.train()\n",
    "        run_epoch(\n",
    "            data_gen(V, batch_size, 20),\n",
    "            model,\n",
    "            SimpleLossCompute(model.generator, criterion),\n",
    "            optimizer,\n",
    "            lr_scheduler,\n",
    "            mode=\"train\",\n",
    "        )\n",
    "        model.eval()\n",
    "        run_epoch(\n",
    "            data_gen(V, batch_size, 5),\n",
    "            model,\n",
    "            SimpleLossCompute(model.generator, criterion),\n",
    "            DummyOptimizer(),\n",
    "            DummyScheduler(),\n",
    "            mode=\"eval\",\n",
    "        )[0]\n",
    "\n",
    "    model.eval()\n",
    "    src = torch.LongTensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
    "    max_len = src.shape[1]\n",
    "    src_mask = torch.ones(1, 1, max_len)\n",
    "    print(greedy_decode(model, src, src_mask, max_len=max_len, start_symbol=0))\n",
    "\n",
    "\n",
    "# execute_example(example_simple_model)\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"OpuQv2GsTsqL\"\n",
    "# # Part 3: A Real World Example\n",
    "#\n",
    "# > Now we consider a real-world example using the Multi30k\n",
    "# > German-English Translation task. This task is much smaller than\n",
    "# > the WMT task considered in the paper, but it illustrates the whole\n",
    "# > system. We also show how to use multi-gpu processing to make it\n",
    "# > really fast.\n",
    "\n",
    "# %% [markdown] id=\"8y9dpfolTsqL\" tags=[]\n",
    "# ## Data Loading\n",
    "#\n",
    "# > We will load the dataset using torchtext and spacy for\n",
    "# > tokenization.\n",
    "\n",
    "# %%\n",
    "# Load spacy tokenizer models, download them if they haven't been\n",
    "# downloaded already\n",
    "\n",
    "\n",
    "def load_tokenizers():\n",
    "\n",
    "    try:\n",
    "        spacy_de = spacy.load(\"de_core_news_sm\")\n",
    "    except IOError:\n",
    "        os.system(\"python -m spacy download de_core_news_sm\")\n",
    "        spacy_de = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "    try:\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "    except IOError:\n",
    "        os.system(\"python -m spacy download en_core_web_sm\")\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    return spacy_de, spacy_en\n",
    "\n",
    "\n",
    "# %% id=\"t4BszXXJTsqL\" tags=[]\n",
    "def tokenize(text, tokenizer):\n",
    "    return [tok.text for tok in tokenizer.tokenizer(text)]\n",
    "\n",
    "\n",
    "def yield_tokens(data_iter, tokenizer, index):\n",
    "    for from_to_tuple in data_iter:\n",
    "        yield tokenizer(from_to_tuple[index])\n",
    "\n",
    "\n",
    "# %% id=\"jU3kVlV5okC-\" tags=[]\n",
    "\n",
    "\n",
    "def build_vocabulary(spacy_de, spacy_en):\n",
    "    def tokenize_de(text):\n",
    "        return tokenize(text, spacy_de)\n",
    "\n",
    "    def tokenize_en(text):\n",
    "        return tokenize(text, spacy_en)\n",
    "\n",
    "    print(\"Building German Vocabulary ...\")\n",
    "    train, val, test = datasets.Multi30k(language_pair=(\"de\", \"en\"))\n",
    "    vocab_src = build_vocab_from_iterator(\n",
    "        yield_tokens(train + val + test, tokenize_de, index=0),\n",
    "        min_freq=2,\n",
    "        specials=[\"<s>\", \"</s>\", \"<blank>\", \"<unk>\"],\n",
    "    )\n",
    "\n",
    "    print(\"Building English Vocabulary ...\")\n",
    "    train, val, test = datasets.Multi30k(language_pair=(\"de\", \"en\"))\n",
    "    vocab_tgt = build_vocab_from_iterator(\n",
    "        yield_tokens(train + val + test, tokenize_en, index=1),\n",
    "        min_freq=2,\n",
    "        specials=[\"<s>\", \"</s>\", \"<blank>\", \"<unk>\"],\n",
    "    )\n",
    "\n",
    "    vocab_src.set_default_index(vocab_src[\"<unk>\"])\n",
    "    vocab_tgt.set_default_index(vocab_tgt[\"<unk>\"])\n",
    "\n",
    "    return vocab_src, vocab_tgt\n",
    "\n",
    "\n",
    "def load_vocab(spacy_de, spacy_en):\n",
    "    if not exists(\"vocab.pt\"):\n",
    "        vocab_src, vocab_tgt = build_vocabulary(spacy_de, spacy_en)\n",
    "        torch.save((vocab_src, vocab_tgt), \"vocab.pt\")\n",
    "    else:\n",
    "        vocab_src, vocab_tgt = torch.load(\"vocab.pt\")\n",
    "    print(\"Finished.\\nVocabulary sizes:\")\n",
    "    print(len(vocab_src))\n",
    "    print(len(vocab_tgt))\n",
    "    return vocab_src, vocab_tgt\n",
    "\n",
    "\n",
    "if is_interactive_notebook():\n",
    "    # global variables used later in the script\n",
    "    spacy_de, spacy_en = show_example(load_tokenizers)\n",
    "    vocab_src, vocab_tgt = show_example(load_vocab, args=[spacy_de, spacy_en])\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"-l-TFwzfTsqL\"\n",
    "#\n",
    "# > Batching matters a ton for speed. We want to have very evenly\n",
    "# > divided batches, with absolutely minimal padding. To do this we\n",
    "# > have to hack a bit around the default torchtext batching. This\n",
    "# > code patches their default batching to make sure we search over\n",
    "# > enough sentences to find tight batches.\n",
    "\n",
    "# %% [markdown] id=\"kDEj-hCgokC-\" tags=[] jp-MarkdownHeadingCollapsed=true\n",
    "# ## Iterators\n",
    "\n",
    "# %% id=\"wGsIHFgOokC_\" tags=[]\n",
    "def collate_batch(\n",
    "    batch,\n",
    "    src_pipeline,\n",
    "    tgt_pipeline,\n",
    "    src_vocab,\n",
    "    tgt_vocab,\n",
    "    device,\n",
    "    max_padding=128,\n",
    "    pad_id=2,\n",
    "):\n",
    "    bs_id = torch.tensor([0], device=device)  # <s> token id\n",
    "    eos_id = torch.tensor([1], device=device)  # </s> token id\n",
    "    src_list, tgt_list = [], []\n",
    "    for (_src, _tgt) in batch:\n",
    "        processed_src = torch.cat(\n",
    "            [\n",
    "                bs_id,\n",
    "                torch.tensor(\n",
    "                    src_vocab(src_pipeline(_src)),\n",
    "                    dtype=torch.int64,\n",
    "                    device=device,\n",
    "                ),\n",
    "                eos_id,\n",
    "            ],\n",
    "            0,\n",
    "        )\n",
    "        processed_tgt = torch.cat(\n",
    "            [\n",
    "                bs_id,\n",
    "                torch.tensor(\n",
    "                    tgt_vocab(tgt_pipeline(_tgt)),\n",
    "                    dtype=torch.int64,\n",
    "                    device=device,\n",
    "                ),\n",
    "                eos_id,\n",
    "            ],\n",
    "            0,\n",
    "        )\n",
    "        src_list.append(\n",
    "            # warning - overwrites values for negative values of padding - len\n",
    "            pad(\n",
    "                processed_src,\n",
    "                (\n",
    "                    0,\n",
    "                    max_padding - len(processed_src),\n",
    "                ),\n",
    "                value=pad_id,\n",
    "            )\n",
    "        )\n",
    "        tgt_list.append(\n",
    "            pad(\n",
    "                processed_tgt,\n",
    "                (0, max_padding - len(processed_tgt)),\n",
    "                value=pad_id,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    src = torch.stack(src_list)\n",
    "    tgt = torch.stack(tgt_list)\n",
    "    return (src, tgt)\n",
    "\n",
    "\n",
    "# %% id=\"ka2Ce_WIokC_\" tags=[]\n",
    "def create_dataloaders(\n",
    "    device,\n",
    "    vocab_src,\n",
    "    vocab_tgt,\n",
    "    spacy_de,\n",
    "    spacy_en,\n",
    "    batch_size=12000,\n",
    "    max_padding=128,\n",
    "    is_distributed=True,\n",
    "):\n",
    "    # def create_dataloaders(batch_size=12000):\n",
    "    def tokenize_de(text):\n",
    "        return tokenize(text, spacy_de)\n",
    "\n",
    "    def tokenize_en(text):\n",
    "        return tokenize(text, spacy_en)\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        return collate_batch(\n",
    "            batch,\n",
    "            tokenize_de,\n",
    "            tokenize_en,\n",
    "            vocab_src,\n",
    "            vocab_tgt,\n",
    "            device,\n",
    "            max_padding=max_padding,\n",
    "            pad_id=vocab_src.get_stoi()[\"<blank>\"],\n",
    "        )\n",
    "\n",
    "    train_iter, valid_iter, test_iter = datasets.Multi30k(\n",
    "        language_pair=(\"de\", \"en\")\n",
    "    )\n",
    "\n",
    "    train_iter_map = to_map_style_dataset(\n",
    "        train_iter\n",
    "    )  # DistributedSampler needs a dataset len()\n",
    "    train_sampler = (\n",
    "        DistributedSampler(train_iter_map) if is_distributed else None\n",
    "    )\n",
    "    valid_iter_map = to_map_style_dataset(valid_iter)\n",
    "    valid_sampler = (\n",
    "        DistributedSampler(valid_iter_map) if is_distributed else None\n",
    "    )\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_iter_map,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(train_sampler is None),\n",
    "        sampler=train_sampler,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    valid_dataloader = DataLoader(\n",
    "        valid_iter_map,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(valid_sampler is None),\n",
    "        sampler=valid_sampler,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    return train_dataloader, valid_dataloader\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"90qM8RzCTsqM\"\n",
    "# ## Training the System\n",
    "\n",
    "# %%\n",
    "def train_worker(\n",
    "    gpu,\n",
    "    ngpus_per_node,\n",
    "    vocab_src,\n",
    "    vocab_tgt,\n",
    "    spacy_de,\n",
    "    spacy_en,\n",
    "    config,\n",
    "    is_distributed=False,\n",
    "):\n",
    "    print(f\"Train worker process using GPU: {gpu} for training\", flush=True)\n",
    "    torch.cuda.set_device(gpu)\n",
    "\n",
    "    pad_idx = vocab_tgt[\"<blank>\"]\n",
    "    d_model = 512\n",
    "    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n",
    "    model.cuda(gpu)\n",
    "    module = model\n",
    "    is_main_process = True\n",
    "    if is_distributed:\n",
    "        dist.init_process_group(\n",
    "            \"nccl\", init_method=\"env://\", rank=gpu, world_size=ngpus_per_node\n",
    "        )\n",
    "        model = DDP(model, device_ids=[gpu])\n",
    "        module = model.module\n",
    "        is_main_process = gpu == 0\n",
    "\n",
    "    criterion = LabelSmoothing(\n",
    "        size=len(vocab_tgt), padding_idx=pad_idx, smoothing=0.1\n",
    "    )\n",
    "    criterion.cuda(gpu)\n",
    "\n",
    "    train_dataloader, valid_dataloader = create_dataloaders(\n",
    "        gpu,\n",
    "        vocab_src,\n",
    "        vocab_tgt,\n",
    "        spacy_de,\n",
    "        spacy_en,\n",
    "        batch_size=config[\"batch_size\"] // ngpus_per_node,\n",
    "        max_padding=config[\"max_padding\"],\n",
    "        is_distributed=is_distributed,\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=config[\"base_lr\"], betas=(0.9, 0.98), eps=1e-9\n",
    "    )\n",
    "    lr_scheduler = LambdaLR(\n",
    "        optimizer=optimizer,\n",
    "        lr_lambda=lambda step: rate(\n",
    "            step, d_model, factor=1, warmup=config[\"warmup\"]\n",
    "        ),\n",
    "    )\n",
    "    train_state = TrainState()\n",
    "\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        if is_distributed:\n",
    "            train_dataloader.sampler.set_epoch(epoch)\n",
    "            valid_dataloader.sampler.set_epoch(epoch)\n",
    "\n",
    "        model.train()\n",
    "        print(f\"[GPU{gpu}] Epoch {epoch} Training ====\", flush=True)\n",
    "        _, train_state = run_epoch(\n",
    "            (Batch(b[0], b[1], pad_idx) for b in train_dataloader),\n",
    "            model,\n",
    "            SimpleLossCompute(module.generator, criterion),\n",
    "            optimizer,\n",
    "            lr_scheduler,\n",
    "            mode=\"train+log\",\n",
    "            accum_iter=config[\"accum_iter\"],\n",
    "            train_state=train_state,\n",
    "        )\n",
    "\n",
    "        GPUtil.showUtilization()\n",
    "        if is_main_process:\n",
    "            file_path = \"%s%.2d.pt\" % (config[\"file_prefix\"], epoch)\n",
    "            torch.save(module.state_dict(), file_path)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        print(f\"[GPU{gpu}] Epoch {epoch} Validation ====\", flush=True)\n",
    "        model.eval()\n",
    "        sloss = run_epoch(\n",
    "            (Batch(b[0], b[1], pad_idx) for b in valid_dataloader),\n",
    "            model,\n",
    "            SimpleLossCompute(module.generator, criterion),\n",
    "            DummyOptimizer(),\n",
    "            DummyScheduler(),\n",
    "            mode=\"eval\",\n",
    "        )\n",
    "        print(sloss)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    if is_main_process:\n",
    "        file_path = \"%sfinal.pt\" % config[\"file_prefix\"]\n",
    "        torch.save(module.state_dict(), file_path)\n",
    "\n",
    "\n",
    "# %% tags=[]\n",
    "def train_distributed_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config):\n",
    "    from the_annotated_transformer import train_worker\n",
    "\n",
    "    ngpus = torch.cuda.device_count()\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"12356\"\n",
    "    print(f\"Number of GPUs detected: {ngpus}\")\n",
    "    print(\"Spawning training processes ...\")\n",
    "    mp.spawn(\n",
    "        train_worker,\n",
    "        nprocs=ngpus,\n",
    "        args=(ngpus, vocab_src, vocab_tgt, spacy_de, spacy_en, config, True),\n",
    "    )\n",
    "\n",
    "\n",
    "def train_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config):\n",
    "    if config[\"distributed\"]:\n",
    "        train_distributed_model(\n",
    "            vocab_src, vocab_tgt, spacy_de, spacy_en, config\n",
    "        )\n",
    "    else:\n",
    "        train_worker(\n",
    "            0, 1, vocab_src, vocab_tgt, spacy_de, spacy_en, config, False\n",
    "        )\n",
    "\n",
    "\n",
    "def load_trained_model():\n",
    "    config = {\n",
    "        \"batch_size\": 32,\n",
    "        \"distributed\": False,\n",
    "        \"num_epochs\": 8,\n",
    "        \"accum_iter\": 10,\n",
    "        \"base_lr\": 1.0,\n",
    "        \"max_padding\": 72,\n",
    "        \"warmup\": 3000,\n",
    "        \"file_prefix\": \"multi30k_model_\",\n",
    "    }\n",
    "    model_path = \"multi30k_model_final.pt\"\n",
    "    if not exists(model_path):\n",
    "        train_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config)\n",
    "\n",
    "    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n",
    "    model.load_state_dict(torch.load(\"multi30k_model_final.pt\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "if is_interactive_notebook():\n",
    "    model = load_trained_model()\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"RZK_VjDPTsqN\"\n",
    "#\n",
    "# > Once trained we can decode the model to produce a set of\n",
    "# > translations. Here we simply translate the first sentence in the\n",
    "# > validation set. This dataset is pretty small so the translations\n",
    "# > with greedy search are reasonably accurate.\n",
    "\n",
    "# %% [markdown] id=\"L50i0iEXTsqN\"\n",
    "# # Additional Components: BPE, Search, Averaging\n",
    "\n",
    "# %% [markdown] id=\"NBx1C2_NTsqN\"\n",
    "#\n",
    "# > So this mostly covers the transformer model itself. There are four\n",
    "# > aspects that we didn't cover explicitly. We also have all these\n",
    "# > additional features implemented in\n",
    "# > [OpenNMT-py](https://github.com/opennmt/opennmt-py).\n",
    "#\n",
    "#\n",
    "\n",
    "# %% [markdown] id=\"UpqV1mWnTsqN\"\n",
    "#\n",
    "# > 1) BPE/ Word-piece: We can use a library to first preprocess the\n",
    "# > data into subword units. See Rico Sennrich's\n",
    "# > [subword-nmt](https://github.com/rsennrich/subword-nmt)\n",
    "# > implementation. These models will transform the training data to\n",
    "# > look like this:\n",
    "\n",
    "# %% [markdown] id=\"hwJ_9J0BTsqN\"\n",
    "# Die Protokoll datei kann  heimlich per E - Mail oder FTP\n",
    "# an einen bestimmte n Empfnger gesendet werden .\n",
    "\n",
    "# %% [markdown] id=\"9HwejYkpTsqN\"\n",
    "#\n",
    "# > 2) Shared Embeddings: When using BPE with shared vocabulary we can\n",
    "# > share the same weight vectors between the source / target /\n",
    "# > generator. See the [(cite)](https://arxiv.org/abs/1608.05859) for\n",
    "# > details. To add this to the model simply do this:\n",
    "\n",
    "# %% id=\"tb3j3CYLTsqN\" tags=[]\n",
    "if False:\n",
    "    model.src_embed[0].lut.weight = model.tgt_embeddings[0].lut.weight\n",
    "    model.generator.lut.weight = model.tgt_embed[0].lut.weight\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"xDKJsSwRTsqN\"\n",
    "#\n",
    "# > 3) Beam Search: This is a bit too complicated to cover here. See the\n",
    "# > [OpenNMT-py](https://github.com/OpenNMT/OpenNMT-py/)\n",
    "# > for a pytorch implementation.\n",
    "# >\n",
    "#\n",
    "\n",
    "# %% [markdown] id=\"wf3vVYGZTsqN\"\n",
    "#\n",
    "# > 4) Model Averaging: The paper averages the last k checkpoints to\n",
    "# > create an ensembling effect. We can do this after the fact if we\n",
    "# > have a bunch of models:\n",
    "\n",
    "# %% id=\"hAFEa78JokDB\"\n",
    "def average(model, models):\n",
    "    \"Average models into model\"\n",
    "    for ps in zip(*[m.params() for m in [model] + models]):\n",
    "        ps[0].copy_(torch.sum(*ps[1:]) / len(ps[1:]))\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"Kz5BYJ9sTsqO\"\n",
    "# # Results\n",
    "#\n",
    "# On the WMT 2014 English-to-German translation task, the big\n",
    "# transformer model (Transformer (big) in Table 2) outperforms the\n",
    "# best previously reported models (including ensembles) by more than\n",
    "# 2.0 BLEU, establishing a new state-of-the-art BLEU score of\n",
    "# 28.4. The configuration of this model is listed in the bottom line\n",
    "# of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base\n",
    "# model surpasses all previously published models and ensembles, at a\n",
    "# fraction of the training cost of any of the competitive models.\n",
    "#\n",
    "# On the WMT 2014 English-to-French translation task, our big model\n",
    "# achieves a BLEU score of 41.0, outperforming all of the previously\n",
    "# published single models, at less than 1/4 the training cost of the\n",
    "# previous state-of-the-art model. The Transformer (big) model trained\n",
    "# for English-to-French used dropout rate Pdrop = 0.1, instead of 0.3.\n",
    "#\n",
    "\n",
    "# %% [markdown]\n",
    "# ![](images/results.png)\n",
    "\n",
    "# %% [markdown] id=\"cPcnsHvQTsqO\"\n",
    "#\n",
    "#\n",
    "# > With the addtional extensions in the last section, the OpenNMT-py\n",
    "# > replication gets to 26.9 on EN-DE WMT. Here I have loaded in those\n",
    "# > parameters to our reimplemenation.\n",
    "\n",
    "# %%\n",
    "# Load data and model for output checks\n",
    "\n",
    "\n",
    "# %%\n",
    "def check_outputs(\n",
    "    valid_dataloader,\n",
    "    model,\n",
    "    vocab_src,\n",
    "    vocab_tgt,\n",
    "    n_examples=15,\n",
    "    pad_idx=2,\n",
    "    eos_string=\"</s>\",\n",
    "):\n",
    "    results = [()] * n_examples\n",
    "    for idx in range(n_examples):\n",
    "        print(\"\\nExample %d ========\\n\" % idx)\n",
    "        b = next(iter(valid_dataloader))\n",
    "        rb = Batch(b[0], b[1], pad_idx)\n",
    "        greedy_decode(model, rb.src, rb.src_mask, 64, 0)[0]\n",
    "\n",
    "        src_tokens = [\n",
    "            vocab_src.get_itos()[x] for x in rb.src[0] if x != pad_idx\n",
    "        ]\n",
    "        tgt_tokens = [\n",
    "            vocab_tgt.get_itos()[x] for x in rb.tgt[0] if x != pad_idx\n",
    "        ]\n",
    "\n",
    "        print(\n",
    "            \"Source Text (Input)        : \"\n",
    "            + \" \".join(src_tokens).replace(\"\\n\", \"\")\n",
    "        )\n",
    "        print(\n",
    "            \"Target Text (Ground Truth) : \"\n",
    "            + \" \".join(tgt_tokens).replace(\"\\n\", \"\")\n",
    "        )\n",
    "        model_out = greedy_decode(model, rb.src, rb.src_mask, 72, 0)[0]\n",
    "        model_txt = (\n",
    "            \" \".join(\n",
    "                [vocab_tgt.get_itos()[x] for x in model_out if x != pad_idx]\n",
    "            ).split(eos_string, 1)[0]\n",
    "            + eos_string\n",
    "        )\n",
    "        print(\"Model Output               : \" + model_txt.replace(\"\\n\", \"\"))\n",
    "        results[idx] = (rb, src_tokens, tgt_tokens, model_out, model_txt)\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_model_example(n_examples=5):\n",
    "    global vocab_src, vocab_tgt, spacy_de, spacy_en\n",
    "\n",
    "    print(\"Preparing Data ...\")\n",
    "    _, valid_dataloader = create_dataloaders(\n",
    "        torch.device(\"cpu\"),\n",
    "        vocab_src,\n",
    "        vocab_tgt,\n",
    "        spacy_de,\n",
    "        spacy_en,\n",
    "        batch_size=1,\n",
    "        is_distributed=False,\n",
    "    )\n",
    "\n",
    "    print(\"Loading Trained Model ...\")\n",
    "\n",
    "    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n",
    "    model.load_state_dict(\n",
    "        torch.load(\"multi30k_model_final.pt\", map_location=torch.device(\"cpu\"))\n",
    "    )\n",
    "\n",
    "    print(\"Checking Model Outputs:\")\n",
    "    example_data = check_outputs(\n",
    "        valid_dataloader, model, vocab_src, vocab_tgt, n_examples=n_examples\n",
    "    )\n",
    "    return model, example_data\n",
    "\n",
    "\n",
    "# execute_example(run_model_example)\n",
    "\n",
    "\n",
    "# %% [markdown] id=\"0ZkkNTKLTsqO\"\n",
    "# ## Attention Visualization\n",
    "#\n",
    "# > Even with a greedy decoder the translation looks pretty good. We\n",
    "# > can further visualize it to see what is happening at each layer of\n",
    "# > the attention\n",
    "\n",
    "# %%\n",
    "def mtx2df(m, max_row, max_col, row_tokens, col_tokens):\n",
    "    \"convert a dense matrix to a data frame with row and column indices\"\n",
    "    return pd.DataFrame(\n",
    "        [\n",
    "            (\n",
    "                r,\n",
    "                c,\n",
    "                float(m[r, c]),\n",
    "                \"%.3d %s\"\n",
    "                % (r, row_tokens[r] if len(row_tokens) > r else \"<blank>\"),\n",
    "                \"%.3d %s\"\n",
    "                % (c, col_tokens[c] if len(col_tokens) > c else \"<blank>\"),\n",
    "            )\n",
    "            for r in range(m.shape[0])\n",
    "            for c in range(m.shape[1])\n",
    "            if r < max_row and c < max_col\n",
    "        ],\n",
    "        # if float(m[r,c]) != 0 and r < max_row and c < max_col],\n",
    "        columns=[\"row\", \"column\", \"value\", \"row_token\", \"col_token\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def attn_map(attn, layer, head, row_tokens, col_tokens, max_dim=30):\n",
    "    df = mtx2df(\n",
    "        attn[0, head].data,\n",
    "        max_dim,\n",
    "        max_dim,\n",
    "        row_tokens,\n",
    "        col_tokens,\n",
    "    )\n",
    "    return (\n",
    "        alt.Chart(data=df)\n",
    "        .mark_rect()\n",
    "        .encode(\n",
    "            x=alt.X(\"col_token\", axis=alt.Axis(title=\"\")),\n",
    "            y=alt.Y(\"row_token\", axis=alt.Axis(title=\"\")),\n",
    "            color=\"value\",\n",
    "            tooltip=[\"row\", \"column\", \"value\", \"row_token\", \"col_token\"],\n",
    "        )\n",
    "        .properties(height=400, width=400)\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "\n",
    "# %% tags=[]\n",
    "def get_encoder(model, layer):\n",
    "    return model.encoder.layers[layer].self_attn.attn\n",
    "\n",
    "\n",
    "def get_decoder_self(model, layer):\n",
    "    return model.decoder.layers[layer].self_attn.attn\n",
    "\n",
    "\n",
    "def get_decoder_src(model, layer):\n",
    "    return model.decoder.layers[layer].src_attn.attn\n",
    "\n",
    "\n",
    "def visualize_layer(model, layer, getter_fn, ntokens, row_tokens, col_tokens):\n",
    "    # ntokens = last_example[0].ntokens\n",
    "    attn = getter_fn(model, layer)\n",
    "    n_heads = attn.shape[1]\n",
    "    charts = [\n",
    "        attn_map(\n",
    "            attn,\n",
    "            0,\n",
    "            h,\n",
    "            row_tokens=row_tokens,\n",
    "            col_tokens=col_tokens,\n",
    "            max_dim=ntokens,\n",
    "        )\n",
    "        for h in range(n_heads)\n",
    "    ]\n",
    "    assert n_heads == 8\n",
    "    return alt.vconcat(\n",
    "        charts[0]\n",
    "        # | charts[1]\n",
    "        | charts[2]\n",
    "        # | charts[3]\n",
    "        | charts[4]\n",
    "        # | charts[5]\n",
    "        | charts[6]\n",
    "        # | charts[7]\n",
    "        # layer + 1 due to 0-indexing\n",
    "    ).properties(title=\"Layer %d\" % (layer + 1))\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Encoder Self Attention\n",
    "\n",
    "# %% tags=[]\n",
    "def viz_encoder_self():\n",
    "    model, example_data = run_model_example(n_examples=1)\n",
    "    example = example_data[\n",
    "        len(example_data) - 1\n",
    "    ]  # batch object for the final example\n",
    "\n",
    "    layer_viz = [\n",
    "        visualize_layer(\n",
    "            model, layer, get_encoder, len(example[1]), example[1], example[1]\n",
    "        )\n",
    "        for layer in range(6)\n",
    "    ]\n",
    "    return alt.hconcat(\n",
    "        layer_viz[0]\n",
    "        # & layer_viz[1]\n",
    "        & layer_viz[2]\n",
    "        # & layer_viz[3]\n",
    "        & layer_viz[4]\n",
    "        # & layer_viz[5]\n",
    "    )\n",
    "\n",
    "\n",
    "show_example(viz_encoder_self)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Decoder Self Attention\n",
    "\n",
    "# %% tags=[]\n",
    "def viz_decoder_self():\n",
    "    model, example_data = run_model_example(n_examples=1)\n",
    "    example = example_data[len(example_data) - 1]\n",
    "\n",
    "    layer_viz = [\n",
    "        visualize_layer(\n",
    "            model,\n",
    "            layer,\n",
    "            get_decoder_self,\n",
    "            len(example[1]),\n",
    "            example[1],\n",
    "            example[1],\n",
    "        )\n",
    "        for layer in range(6)\n",
    "    ]\n",
    "    return alt.hconcat(\n",
    "        layer_viz[0]\n",
    "        & layer_viz[1]\n",
    "        & layer_viz[2]\n",
    "        & layer_viz[3]\n",
    "        & layer_viz[4]\n",
    "        & layer_viz[5]\n",
    "    )\n",
    "\n",
    "\n",
    "show_example(viz_decoder_self)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Decoder Src Attention\n",
    "\n",
    "# %% tags=[]\n",
    "def viz_decoder_src():\n",
    "    model, example_data = run_model_example(n_examples=1)\n",
    "    example = example_data[len(example_data) - 1]\n",
    "\n",
    "    layer_viz = [\n",
    "        visualize_layer(\n",
    "            model,\n",
    "            layer,\n",
    "            get_decoder_src,\n",
    "            max(len(example[1]), len(example[2])),\n",
    "            example[1],\n",
    "            example[2],\n",
    "        )\n",
    "        for layer in range(6)\n",
    "    ]\n",
    "    return alt.hconcat(\n",
    "        layer_viz[0]\n",
    "        & layer_viz[1]\n",
    "        & layer_viz[2]\n",
    "        & layer_viz[3]\n",
    "        & layer_viz[4]\n",
    "        & layer_viz[5]\n",
    "    )\n",
    "\n",
    "\n",
    "show_example(viz_decoder_src)\n",
    "\n",
    "# %% [markdown] id=\"nSseuCcATsqO\"\n",
    "# # Conclusion\n",
    "#\n",
    "#  Hopefully this code is useful for future research. Please reach\n",
    "#  out if you have any issues.\n",
    "#\n",
    "#\n",
    "#  Cheers,\n",
    "#  Sasha Rush, Austin Huang, Suraj Subramanian, Jonathan Sum, Khalid Almubarak,\n",
    "#  Stella Biderman\n"
   ]
  },
  {
   "attachments": {
    "815012f1-e052-4514-a18c-db31f235d612": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "d5393d47",
   "metadata": {},
   "source": [
    "## Transformer Architecture\n",
    "![pasted_image_815012f1-e052-4514-a18c-db31f235d612.png](attachment:815012f1-e052-4514-a18c-db31f235d612)\n"
   ]
  },
  {
   "attachments": {
    "670cb52c-fedb-4185-bb81-749fd2bffd33": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "3aa6dc75",
   "metadata": {},
   "source": [
    "### Architecture Details\n",
    "\n",
    "\n",
    "![pasted_image_670cb52c-fedb-4185-bb81-749fd2bffd33.png](attachment:670cb52c-fedb-4185-bb81-749fd2bffd33)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ed3f22",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b056de3d",
   "metadata": {},
   "source": [
    "I have given you enough context to implement a transformer from scratch. I want to learn how to implement transformers without cheating. What should I start from first? I also included the code from Annotated Transformer by Harvard NLP. I want to follow this as the benchmark tutorial, but I am not going to see any of the code. I want to do it from scratch. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "That's an excellent learning goal! Implementing a transformer from scratch is one of the best ways to deeply understand how they work. Let me help you get started with a structured approach.\n",
    "\n",
    "First, let me understand your background better:\n",
    "\n",
    "1. How comfortable are you with PyTorch (or your preferred deep learning framework)?\n",
    "2. Do you understand the core concepts from the \"Attention is All You Need\" paper - like self-attention, multi-head attention, and positional encoding?\n",
    "3. Would you prefer to build this incrementally (starting with the smallest components) or tackle one complete module at a time?\n",
    "\n",
    "For a from-scratch implementation, I'd suggest starting with the **attention mechanism** itself, since it's the heart of the transformer. Specifically, you could begin by implementing:\n",
    "\n",
    "**Scaled Dot-Product Attention** - the most fundamental building block.\n",
    "\n",
    "This involves:\n",
    "- Taking query (Q), key (K), and value (V) matrices as input\n",
    "- Computing attention scores\n",
    "- Applying the scaling factor\n",
    "- Using softmax to get attention weights\n",
    "- Returning the weighted sum of values\n",
    "\n",
    "Would you like me to explain what this function should do conceptually (inputs, outputs, and the mathematical operations), so you can try implementing it yourself? Or would you prefer to start with an even simpler piece, like understanding the data structures you'll need?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b9a78",
   "metadata": {},
   "source": [
    "Q * K^T / sqrt(D_K)* V \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! You've got the formula down. That's the core of scaled dot-product attention.\n",
    "\n",
    "Let me make sure you understand each part:\n",
    "\n",
    "- **Q  K^T**: This gives you attention scores (how much each query should \"attend to\" each key)\n",
    "- **/ sqrt(d_k)**: The scaling factor prevents the dot products from getting too large\n",
    "- **Then softmax** (you didn't write it, but it goes here!) converts scores to probabilities\n",
    "- ** V**: Finally, use those probabilities as weights for the values\n",
    "\n",
    "A couple of questions to check your understanding:\n",
    "\n",
    "1. What are the dimensions/shapes of Q, K, and V?\n",
    "2. Where does the softmax operation fit in that formula you wrote?\n",
    "\n",
    "Once you're clear on these, you can start coding the attention function. Want to clarify these points first, or are you ready to start implementing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f0001b",
   "metadata": {},
   "source": [
    "It makes sure that the outputs add up to one. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Exactly! Softmax normalizes the scores so they sum to 1, turning them into a proper probability distribution over the values.\n",
    "\n",
    "So the complete formula is:\n",
    "\n",
    "**Attention(Q, K, V) = softmax(Q  K^T / sqrt(d_k))  V**\n",
    "\n",
    "Now, before you start coding, let's think about one more important detail: **masking**. \n",
    "\n",
    "In the decoder, you need to prevent positions from \"looking ahead\" at future tokens. This is done by setting certain attention scores to negative infinity before the softmax.\n",
    "\n",
    "Do you understand why masking is needed and where it fits into the formula? Or should I clarify that first?\n",
    "\n",
    "Once you're comfortable with the concept, you can start implementing the `attention()` function!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21abbec7",
   "metadata": {},
   "source": [
    "Well, it makes sure that the outputs add up to one. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Exactly! The softmax converts the raw similarity scores into a probability distribution - all values between 0 and 1 that sum to 1.\n",
    "\n",
    "This is important because it tells us \"how much attention\" to pay to each value. If one key is very similar to the query, it gets a high weight (close to 1), and we focus mostly on its corresponding value.\n",
    "\n",
    "Now you're ready to implement it! Try coding the `attention()` function. It should:\n",
    "- Take `query`, `key`, `value` as inputs (and optionally `mask` and `dropout`)\n",
    "- Return the attention output (and optionally the attention weights for visualization)\n",
    "\n",
    "Don't worry about getting it perfect - just give it a try and let me know what you come up with or if you get stuck on any part!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1bcceb",
   "metadata": {},
   "source": [
    "def attention(Q, K, V, dropout, mask):\n",
    "    Q@K.T\n",
    "Am I doing the correct thing? I am not sure what I am doing. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "You're on the right track! You've started with the Q @ K.T part, which is correct.\n",
    "\n",
    "Let me help clarify what you need to do step by step:\n",
    "\n",
    "1. **Q @ K.T**  (you have this!)\n",
    "2. **Divide by sqrt(d_k)** - you need to scale the scores. What is d_k? (Hint: it's related to the dimension of your key vectors)\n",
    "3. **Apply mask** (if provided) - set certain positions to a very negative number\n",
    "4. **Apply softmax** - convert scores to probabilities\n",
    "5. **Multiply by V** - get the weighted sum\n",
    "6. **Apply dropout** (if provided) - for regularization\n",
    "\n",
    "Try adding step 2 next - how would you get d_k from your inputs, and how would you scale the scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602bcf63",
   "metadata": {},
   "source": [
    "is it K.shape(0)? also give me code written till now\n",
    "\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Not quite! `d_k` is the dimension of each key vector, which is the **last dimension** of K.\n",
    "\n",
    "So it would be: `K.shape[-1]` (or `K.size(-1)` in PyTorch)\n",
    "\n",
    "For the code so far, I want to make sure you're building this yourself to really learn it. Here's what you have:\n",
    "\n",
    "```python\n",
    "def attention(Q, K, V, dropout, mask):\n",
    "    Q @ K.T\n",
    "```\n",
    "\n",
    "Now try adding:\n",
    "1. Store that result in a variable (maybe call it `scores`)\n",
    "2. Get `d_k` from the key dimension\n",
    "3. Divide scores by `sqrt(d_k)` (you'll need to import `math` for `math.sqrt`)\n",
    "\n",
    "Give it a try and show me what you get!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0109751",
   "metadata": {
    "time_run": "2025-11-30T18:10:20.947962+00:00"
   },
   "outputs": [],
   "source": [
    "def attention(Q, K, V, dropout, mask):\n",
    "    sqrt_d_k = math.sqrt(K.size(-1))\n",
    "    attention = torch.softmax(Q @ K.T / sqrt_d_k)*V\n",
    "    return attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0c66d6",
   "metadata": {},
   "source": [
    "How am I doing now? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "You're doing great! You've got most of the core pieces in place. A few things to adjust:\n",
    "\n",
    "1. **Transpose operation**: In PyTorch, use `.transpose(-2, -1)` instead of `.T` to handle batched matrices correctly\n",
    "\n",
    "2. **Softmax dimension**: You need to specify which dimension to apply softmax over - it should be the last dimension: `torch.softmax(..., dim=-1)`\n",
    "\n",
    "3. **Missing pieces**: You haven't used `mask` or `dropout` yet. The mask needs to be applied *before* the softmax (by setting masked positions to a very negative number like -1e9)\n",
    "\n",
    "4. **Parentheses**: The multiplication by V should happen *after* the softmax, so make sure your parentheses are right\n",
    "\n",
    "Try fixing the transpose and softmax dimension first. Does that make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a93f91",
   "metadata": {},
   "source": [
    "What is transpose - 2 - 1? I don't understand what he's saying. What do you mean applying softmax to the last dimension? I don't understand. I think I'm weak at all this dimension kind of stuff. Please help me. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "No worries! Let's break this down - dimensions can be tricky at first.\n",
    "\n",
    "**Understanding dimensions/axes:**\n",
    "\n",
    "When you have a tensor (multi-dimensional array), each \"direction\" is called a dimension or axis. For example:\n",
    "- A vector has 1 dimension: `[1, 2, 3]` has shape `(3,)`\n",
    "- A matrix has 2 dimensions: rows and columns, shape `(rows, cols)`\n",
    "- A batch of matrices has 3 dimensions: `(batch_size, rows, cols)`\n",
    "\n",
    "**What is `.transpose(-2, -1)`?**\n",
    "\n",
    "This swaps the last two dimensions. The `-1` means \"last dimension\" and `-2` means \"second-to-last\".\n",
    "\n",
    "For a matrix with shape `(rows, cols)`, transposing swaps them to `(cols, rows)`.\n",
    "\n",
    "For example, if K has shape `(batch, seq_len, d_k)`, then `K.transpose(-2, -1)` gives you `(batch, d_k, seq_len)`.\n",
    "\n",
    "**What does `dim=-1` in softmax mean?**\n",
    "\n",
    "It tells PyTorch which dimension to apply softmax across. `dim=-1` means \"apply softmax across the last dimension\" - so each row will sum to 1.\n",
    "\n",
    "Does this help clarify things? Want to try updating your code with these changes, or do you need more explanation on any part?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d546bd",
   "metadata": {},
   "source": [
    "Okay, I'll update the code. But after I update the code and the code is proper, let's pass to an example through it so that I understand better. Give me the code so far. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "I want you to try updating it yourself first - that's how you'll learn best! \n",
    "\n",
    "Take your current code:\n",
    "```python\n",
    "def attention(Q, K, V, dropout, mask):\n",
    "    sqrt_d_k = math.sqrt(K.size(-1))\n",
    "    attention = torch.softmax(Q @ K.T / sqrt_d_k)*V\n",
    "    return attention\n",
    "```\n",
    "\n",
    "And make these changes:\n",
    "1. Change `K.T` to `K.transpose(-2, -1)`\n",
    "2. Add `dim=-1` to the softmax\n",
    "\n",
    "Give it a try! Once you've updated it, we'll absolutely run an example through it to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f84583",
   "metadata": {
    "time_run": "2025-11-30T18:10:21.482479+00:00"
   },
   "outputs": [],
   "source": [
    "def attention(Q, K, V, dropout, mask):\n",
    "    sqrt_d_k = math.sqrt(K.size(-1))\n",
    "    dropout = torch.nn.Dropout(p=dropout)\n",
    "    attention = torch.softmax(Q @ K.transpose(-2,-1) / sqrt_d_k, dim=-1)@V\n",
    "    return dropout(attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee9a0e6",
   "metadata": {},
   "source": [
    "Okay, am I done? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "\n",
    "\n",
    "Almost there! Two things to fix:\n",
    "\n",
    "1. **Mask is not used**: You need to apply the mask to the scores *before* the softmax. The typical approach is:\n",
    "   ```python\n",
    "   scores = scores.masked_fill(mask == 0, -1e9)\n",
    "   ```\n",
    "   This sets masked positions to a very negative number, so after softmax they become ~0.\n",
    "\n",
    "2. **Dropout placement**: Dropout should be applied to the attention weights (after softmax, before multiplying by V), not to the final output.\n",
    "\n",
    "Can you restructure your code to:\n",
    "- Compute scores first (Q @ K.transpose...)\n",
    "- Apply mask to scores (if mask is provided)\n",
    "- Apply softmax to get attention weights\n",
    "- Apply dropout to attention weights (if dropout is provided)\n",
    "- Multiply by V\n",
    "- Return the result\n",
    "\n",
    "Try breaking it into separate lines - it'll be clearer and easier to debug!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ef143c",
   "metadata": {},
   "source": [
    "I don't understand why we need masks for laser clean. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question! Let me explain why masking is needed.\n",
    "\n",
    "**Why do we need masks?**\n",
    "\n",
    "There are two main reasons:\n",
    "\n",
    "1. **Padding mask**: When you batch sentences together, they're often different lengths. You pad shorter sentences with special tokens (like `<pad>`). You don't want the model to pay attention to these padding tokens because they're meaningless. So you mask them out.\n",
    "\n",
    "2. **Look-ahead mask (for decoder)**: In the decoder during training, when predicting word 3, the model should only see words 1 and 2, not words 4, 5, 6 (the future). This prevents \"cheating\" - the model can't look at future words it's supposed to predict. This is called a \"causal mask\" or \"subsequent mask\".\n",
    "\n",
    "**What does masking do?**\n",
    "\n",
    "By setting masked positions to -1e9 (very negative) before softmax, those positions become ~0 after softmax. This means \"don't pay attention to these positions at all.\"\n",
    "\n",
    "Does this make sense? Do you want to see a simple example of how masking works with numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe0677a",
   "metadata": {},
   "source": [
    "Yes, give me a simple example. I don't understand what this command is doing. And where exactly is the mask applied? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! Let me show you a simple numerical example.\n",
    "\n",
    "**Simple masking example:**\n",
    "\n",
    "Let's say you have attention scores (before softmax):\n",
    "```\n",
    "scores = [2.0, 3.0, 1.0, 4.0]\n",
    "```\n",
    "\n",
    "And a mask that says \"ignore positions 2 and 3\":\n",
    "```\n",
    "mask = [1, 1, 0, 0]  # 1 = keep, 0 = ignore\n",
    "```\n",
    "\n",
    "**Step 1: Apply mask** (this is where `scores.masked_fill(mask == 0, -1e9)` happens)\n",
    "```\n",
    "scores = [2.0, 3.0, -1e9, -1e9]\n",
    "```\n",
    "\n",
    "**Step 2: Apply softmax**\n",
    "```\n",
    "After softmax: [0.27, 0.73, ~0.0, ~0.0]\n",
    "```\n",
    "\n",
    "See? The masked positions become essentially 0 after softmax!\n",
    "\n",
    "**Where is the mask applied?**\n",
    "\n",
    "In your code, it should go right after you compute the scores and BEFORE softmax:\n",
    "\n",
    "```python\n",
    "scores = Q @ K.transpose(-2, -1) / sqrt_d_k\n",
    "if mask is not None:\n",
    "    scores = scores.masked_fill(mask == 0, -1e9)\n",
    "attention_weights = torch.softmax(scores, dim=-1)\n",
    "```\n",
    "\n",
    "Does this clarify it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf2e5ad",
   "metadata": {},
   "source": [
    "### Final Attention Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e1154",
   "metadata": {
    "time_run": "2025-12-01T07:13:22.153086+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def attention(Q, K, V, dropout, mask):\n",
    "    sqrt_d_k = math.sqrt(K.size(-1))\n",
    "    scores = Q @ K.transpose(-2,-1) / sqrt_d_k\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask==0, -1e9)\n",
    "    attention_weights = torch.softmax(scores, dim=-1)\n",
    "    attention_weights = dropout(attention_weights)\n",
    "    output = attention_weights @ V\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8be82e",
   "metadata": {},
   "source": [
    "Cool, is this correct? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent! Your attention function looks correct now! \n",
    "\n",
    "You've got all the key pieces:\n",
    "-  Compute scores with proper transpose\n",
    "-  Scale by sqrt(d_k)\n",
    "-  Apply mask before softmax\n",
    "-  Apply softmax on the right dimension\n",
    "-  Apply dropout to attention weights\n",
    "-  Multiply by V\n",
    "\n",
    "One small improvement: it's common to also return the `attention_weights` for visualization purposes (optional, but helpful for debugging). But for now, this works!\n",
    "\n",
    "Want to test it with a simple example to see it in action? Or are you ready to move on to the next component (Multi-Head Attention)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac38ac7",
   "metadata": {},
   "source": [
    "Let us test it. give simple vectors i can hand calc\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Let's test with super simple numbers you can calculate by hand.\n",
    "\n",
    "```python\n",
    "# Simple 2x2 example\n",
    "Q = torch.tensor([[1.0, 0.0], \n",
    "                  [0.0, 1.0]])  # 2 queries, d_k=2\n",
    "\n",
    "K = torch.tensor([[1.0, 0.0],\n",
    "                  [0.0, 1.0]])  # 2 keys, d_k=2\n",
    "\n",
    "V = torch.tensor([[2.0, 0.0],\n",
    "                  [0.0, 3.0]])  # 2 values, d_v=2\n",
    "\n",
    "# Test without mask or dropout first\n",
    "result = attention(Q, K, V, dropout=0.0, mask=None)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Before you run it, try to predict:\n",
    "1. What will Q @ K.T give you?\n",
    "2. After dividing by sqrt(2), what are the scores?\n",
    "3. What happens after softmax?\n",
    "4. What's the final result after multiplying by V?\n",
    "\n",
    "Try working through it on paper, then run the code to check!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272e4827",
   "metadata": {},
   "source": [
    "not that simple. too many 1 and 0 lol\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Haha, fair enough! Let me make it even simpler with different numbers:\n",
    "\n",
    "```python\n",
    "# Super simple example - just 1 query and 2 keys/values\n",
    "Q = torch.tensor([[2.0, 2.0]])  # 1 query, d_k=2\n",
    "\n",
    "K = torch.tensor([[1.0, 1.0],   # key 1\n",
    "                  [1.0, 0.0]])  # key 2\n",
    "\n",
    "V = torch.tensor([[10.0],       # value 1\n",
    "                  [20.0]])      # value 2\n",
    "\n",
    "result = attention(Q, K, V, dropout=0.0, mask=None)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Now try by hand:\n",
    "1. Q @ K.T = ? (just dot products: [2,2][1,1] and [2,2][1,0])\n",
    "2. Divide by sqrt(2)  1.41\n",
    "3. Apply softmax (which one is bigger?)\n",
    "4. Weighted sum of values [10] and [20]\n",
    "\n",
    "Give it a shot!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675e247f",
   "metadata": {},
   "source": [
    "Q ( 1x2) K_T (2x2)\n",
    "Q@K_t = [4 2]\n",
    "div by sqrt2 = [2sqr(2) sqrt(2)]\n",
    "softmax approx [1 0]\n",
    "result = [10 0[\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great work! You're very close! Let me check your steps:\n",
    "\n",
    "1. **Q @ K.T**:  Correct! `[4, 2]`\n",
    "2. **Divide by sqrt(2)**:  Correct! `[22, 2]` which is approximately `[2.83, 1.41]`\n",
    "3. **Softmax**: Almost! It won't be exactly `[1, 0]`. Since 2.83 is bigger than 1.41, the first position will have higher weight, but not exactly 1. It'll be something like `[0.8, 0.2]` (the exact values depend on the exponentials)\n",
    "4. **Result**: Because of softmax, it's a weighted average: `0.8 * 10 + 0.2 * 20 = 8 + 4 = 12`\n",
    "\n",
    "So the result should be around `[[12]]` (a weighted average closer to 10 than 20).\n",
    "\n",
    "Want to run the code now to see the actual numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b3a7ee",
   "metadata": {},
   "source": [
    "ya gimme code\n",
    "\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "```python\n",
    "# Super simple example - just 1 query and 2 keys/values\n",
    "Q = torch.tensor([[2.0, 2.0]])  # 1 query, d_k=2\n",
    "\n",
    "K = torch.tensor([[1.0, 1.0],   # key 1\n",
    "                  [1.0, 0.0]])  # key 2\n",
    "\n",
    "V = torch.tensor([[10.0],       # value 1\n",
    "                  [20.0]])      # value 2\n",
    "\n",
    "result = attention(Q, K, V, dropout=0.0, mask=None)\n",
    "print(\"Result:\", result)\n",
    "print(\"Shape:\", result.shape)\n",
    "```\n",
    "\n",
    "Run this and see what you get! Does it match your hand calculation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffdf478",
   "metadata": {
    "time_run": "2025-11-30T18:10:21.684159+00:00"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m",
      "\u001b[32m      4\u001b[39m K = torch.tensor([[\u001b[32m1.0\u001b[39m, \u001b[32m1.0\u001b[39m],   \u001b[38;5;66;03m# key 1\u001b[39;00m",
      "\u001b[32m      5\u001b[39m                   [\u001b[32m1.0\u001b[39m, \u001b[32m0.0\u001b[39m]])  \u001b[38;5;66;03m# key 2\u001b[39;00m",
      "\u001b[32m      7\u001b[39m V = torch.tensor([[\u001b[32m10.0\u001b[39m],       \u001b[38;5;66;03m# value 1\u001b[39;00m",
      "\u001b[32m      8\u001b[39m                   [\u001b[32m20.0\u001b[39m]])      \u001b[38;5;66;03m# value 2\u001b[39;00m",
      "\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m result = \u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m",
      "\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mResult:\u001b[39m\u001b[33m\"\u001b[39m, result)",
      "\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mShape:\u001b[39m\u001b[33m\"\u001b[39m, result.shape)",
      "",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mattention\u001b[39m\u001b[34m(Q, K, V, dropout, mask)\u001b[39m",
      "\u001b[32m      5\u001b[39m     scores = scores.masked_fill(mask==\u001b[32m0\u001b[39m, -\u001b[32m1e9\u001b[39m)",
      "\u001b[32m      6\u001b[39m attention_weights = torch.softmax(scores, dim=-\u001b[32m1\u001b[39m)",
      "\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m attention_weights = \u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_weights\u001b[49m\u001b[43m)\u001b[49m",
      "\u001b[32m      8\u001b[39m output = attention_weights @ V",
      "\u001b[32m      9\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output",
      "",
      "\u001b[31mTypeError\u001b[39m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "# Super simple example - just 1 query and 2 keys/values\n",
    "Q = torch.tensor([[2.0, 2.0]])  # 1 query, d_k=2\n",
    "\n",
    "K = torch.tensor([[1.0, 1.0],   # key 1\n",
    "                  [1.0, 0.0]])  # key 2\n",
    "\n",
    "V = torch.tensor([[10.0],       # value 1\n",
    "                  [20.0]])      # value 2\n",
    "\n",
    "result = attention(Q, K, V, dropout=0.0, mask=None)\n",
    "print(\"Result:\", result)\n",
    "print(\"Shape:\", result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e375f7de",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Convert this into a unit as. Assume I'm writing an NB Dev Notebook. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "I'll help you convert your attention function into a unit test for an nbdev notebook. Here's how you can structure it:\n",
    "\n",
    "```python\n",
    "#| export\n",
    "def attention(Q, K, V, dropout=None, mask=None):\n",
    "    \"Compute Scaled Dot-Product Attention\"\n",
    "    sqrt_d_k = math.sqrt(K.size(-1))\n",
    "    scores = Q @ K.transpose(-2,-1) / sqrt_d_k\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask==0, -1e9)\n",
    "    attention_weights = torch.softmax(scores, dim=-1)\n",
    "    if dropout is not None:\n",
    "        attention_weights = dropout(attention_weights)\n",
    "    output = attention_weights @ V\n",
    "    return output\n",
    "```\n",
    "\n",
    "```python\n",
    "#| test\n",
    "def test_attention_basic():\n",
    "    \"Test attention with simple hand-calculable example\"\n",
    "    Q = torch.tensor([[2.0, 2.0]])  # 1 query, d_k=2\n",
    "    K = torch.tensor([[1.0, 1.0],   # key 1\n",
    "                      [1.0, 0.0]])  # key 2\n",
    "    V = torch.tensor([[10.0],       # value 1\n",
    "                      [20.0]])      # value 2\n",
    "    \n",
    "    result = attention(Q, K, V, dropout=None, mask=None)\n",
    "    \n",
    "    # Result should be weighted average closer to 10 than 20\n",
    "    assert result.shape == torch.Size([1, 1])\n",
    "    assert 11.0 < result.item() < 13.0  # approximately 11.96\n",
    "```\n",
    "\n",
    "A couple of notes:\n",
    "1. I made `dropout` and `mask` optional parameters with default `None`\n",
    "2. The `#| export` directive marks the function for export to your module\n",
    "3. The `#| test` directive marks the test function\n",
    "\n",
    "Would you like me to add more test cases (e.g., testing with masks, or with batched inputs)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0227a8d9",
   "metadata": {},
   "source": [
    "#### Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049891c0",
   "metadata": {
    "time_run": "2025-11-30T18:10:21.761775+00:00"
   },
   "outputs": [],
   "source": [
    "#| test\n",
    "def test_attention_basic():\n",
    "    \"Test attention with simple hand-calculable example\"\n",
    "    Q = torch.tensor([[2.0, 2.0]])  # 1 query, d_k=2\n",
    "    K = torch.tensor([[1.0, 1.0],   # key 1\n",
    "                      [1.0, 0.0]])  # key 2\n",
    "    V = torch.tensor([[10.0],       # value 1\n",
    "                      [20.0]])      # value 2\n",
    "    \n",
    "    result = attention(Q, K, V, dropout=None, mask=None)\n",
    "    \n",
    "    # Result should be weighted average closer to 10 than 20\n",
    "    assert result.shape == torch.Size([1, 1])\n",
    "    assert 11.0 < result.item() < 13.0  # approximately 11.96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f11d7e",
   "metadata": {},
   "source": [
    "noice But are the dimensions of q, k, v you have given realistic? What are the real ones? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question! The dimensions I gave you were simplified for hand calculation. Let me show you realistic dimensions:\n",
    "\n",
    "**In a real transformer:**\n",
    "\n",
    "- **Batch size (B)**: typically 8, 16, 32, etc.\n",
    "- **Sequence length (S)**: how many tokens (words/subwords) - could be 10, 50, 512, etc.\n",
    "- **d_model**: the model dimension - typically 512 (base model) or 1024 (large model)\n",
    "- **d_k** (key/query dimension): typically d_model / num_heads. For 8 heads and d_model=512, d_k = 64\n",
    "\n",
    "**Realistic shapes:**\n",
    "```\n",
    "Q: (batch_size, seq_len, d_k)     e.g., (32, 50, 64)\n",
    "K: (batch_size, seq_len, d_k)     e.g., (32, 50, 64)\n",
    "V: (batch_size, seq_len, d_v)     e.g., (32, 50, 64)\n",
    "```\n",
    "\n",
    "Note: usually d_k = d_v = 64 when using 8 attention heads.\n",
    "\n",
    "Want to test your attention function with more realistic dimensions to make sure it handles batches correctly?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33545c89",
   "metadata": {},
   "source": [
    "ya\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Try this:\n",
    "\n",
    "```python\n",
    "# Realistic dimensions\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "d_k = 8\n",
    "\n",
    "Q = torch.randn(batch_size, seq_len, d_k)\n",
    "K = torch.randn(batch_size, seq_len, d_k)\n",
    "V = torch.randn(batch_size, seq_len, d_k)\n",
    "\n",
    "result = attention(Q, K, V, dropout=0.0, mask=None)\n",
    "print(\"Result shape:\", result.shape)\n",
    "print(\"Expected shape:\", (batch_size, seq_len, d_k))\n",
    "```\n",
    "\n",
    "Run this and check if the output shape matches what you expect. Does it work correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a66bde",
   "metadata": {
    "time_run": "2025-11-30T18:10:21.807686+00:00"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m",
      "\u001b[32m      7\u001b[39m K = torch.randn(batch_size, seq_len, d_k)",
      "\u001b[32m      8\u001b[39m V = torch.randn(batch_size, seq_len, d_k)",
      "\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m result = \u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m",
      "\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mResult shape:\u001b[39m\u001b[33m\"\u001b[39m, result.shape)",
      "\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExpected shape:\u001b[39m\u001b[33m\"\u001b[39m, (batch_size, seq_len, d_k))",
      "",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mattention\u001b[39m\u001b[34m(Q, K, V, dropout, mask)\u001b[39m",
      "\u001b[32m      5\u001b[39m     scores = scores.masked_fill(mask==\u001b[32m0\u001b[39m, -\u001b[32m1e9\u001b[39m)",
      "\u001b[32m      6\u001b[39m attention_weights = torch.softmax(scores, dim=-\u001b[32m1\u001b[39m)",
      "\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m attention_weights = \u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_weights\u001b[49m\u001b[43m)\u001b[49m",
      "\u001b[32m      8\u001b[39m output = attention_weights @ V",
      "\u001b[32m      9\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output",
      "",
      "\u001b[31mTypeError\u001b[39m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "# Realistic dimensions\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "d_k = 8\n",
    "\n",
    "Q = torch.randn(batch_size, seq_len, d_k)\n",
    "K = torch.randn(batch_size, seq_len, d_k)\n",
    "V = torch.randn(batch_size, seq_len, d_k)\n",
    "\n",
    "result = attention(Q, K, V, dropout=0.0, mask=None)\n",
    "print(\"Result shape:\", result.shape)\n",
    "print(\"Expected shape:\", (batch_size, seq_len, d_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022310a2",
   "metadata": {},
   "source": [
    "What is the philosophy behind attention? What is Q, what is K, what is V? Give a proper analogy. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question! Let me give you an intuitive analogy.\n",
    "\n",
    "**The Library Analogy:**\n",
    "\n",
    "Imagine you're in a library looking for information about \"transformers in NLP\":\n",
    "\n",
    "- **Query (Q)**: Your question/search term - \"What are transformers?\"\n",
    "- **Keys (K)**: The titles/keywords of all books on the shelves\n",
    "- **Values (V)**: The actual content of those books\n",
    "\n",
    "**How attention works:**\n",
    "\n",
    "1. You compare your query against all the book titles (Q  K^T) - which books are most relevant?\n",
    "2. You get similarity scores - \"Deep Learning\" book scores high, \"Cooking 101\" scores low\n",
    "3. Softmax turns these into weights - how much to focus on each book\n",
    "4. You read a weighted combination of the books (weights  V) - paying more attention to relevant ones\n",
    "\n",
    "**In transformers:**\n",
    "\n",
    "- Each word creates its own Query: \"What information do I need?\"\n",
    "- Each word provides a Key: \"I have this type of information\"\n",
    "- Each word provides a Value: \"Here's my actual information\"\n",
    "\n",
    "The word \"bank\" (query) might attend strongly to \"river\" (high attention weight) vs \"money\" depending on context!\n",
    "\n",
    "Does this help clarify the philosophy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300e634f",
   "metadata": {},
   "source": [
    "Okay, so I get that, but how does query, and the key, and the value relate to attention overall? Isn't that just multiplying inputs with WQ and WK? How is that converting to query and key? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent question! You're getting to the heart of how attention actually works.\n",
    "\n",
    "**You're absolutely right!** Q, K, and V are created by multiplying the input with learned weight matrices:\n",
    "\n",
    "```\n",
    "Q = Input @ W_Q\n",
    "K = Input @ W_K  \n",
    "V = Input @ W_V\n",
    "```\n",
    "\n",
    "**Why do we do this?**\n",
    "\n",
    "The input embeddings are just generic word representations. By multiplying with W_Q, W_K, W_V, we're **learning to transform** the input into three different \"views\":\n",
    "\n",
    "- **W_Q learns**: \"How should I ask questions?\" (what to look for)\n",
    "- **W_K learns**: \"How should I advertise what I have?\" (what I can provide)\n",
    "- **W_V learns**: \"What information should I actually pass along?\" (the content to share)\n",
    "\n",
    "**Example:**\n",
    "The word \"bank\" has one embedding. But:\n",
    "- As a Query (W_Q): it might learn to ask \"what's nearby?\" \n",
    "- As a Key (W_K): it might learn to signal \"I'm a noun\"\n",
    "- As a Value (W_V): it might learn to pass along semantic meaning\n",
    "\n",
    "The magic is that W_Q, W_K, W_V are **learned during training** to make attention useful!\n",
    "\n",
    "Does this connection make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4627772e",
   "metadata": {},
   "source": [
    "Excellent. Let's move on. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! You've successfully implemented the core attention mechanism. \n",
    "\n",
    "Now the next step is **Multi-Head Attention**. This is where we run multiple attention operations in parallel (multiple \"heads\"), each learning different patterns.\n",
    "\n",
    "The key idea: instead of one attention, we have `h` heads (typically 8), each with its own W_Q, W_K, W_V matrices. Then we concatenate all the outputs and project them back.\n",
    "\n",
    "Before we start coding, do you understand conceptually:\n",
    "1. Why we'd want multiple attention heads instead of just one?\n",
    "2. How the dimensions change when we split into multiple heads?\n",
    "\n",
    "Or should I explain the intuition first?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e096d02",
   "metadata": {},
   "source": [
    "We need multiple attention heads because we want to see:\n",
    "- One word can have a correlation with other words\n",
    "- Another attention head can give another perspective\n",
    "\n",
    "How the dimension changes when we split into multiple heads? Maybe the input dimensions is divided by the number of tangent heads. That's how it splits. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Exactly right on both points! \n",
    "\n",
    "**Why multiple heads:** Each head can learn different relationships - one might focus on syntactic patterns (subject-verb), another on semantic similarity, another on positional relationships, etc.\n",
    "\n",
    "**Dimension splitting:** Yes! If d_model = 512 and we have 8 heads, each head works with d_k = 512/8 = 64 dimensions. This keeps the total computation roughly the same as single-head attention.\n",
    "\n",
    "**The process:**\n",
    "1. Start with input of shape (batch, seq_len, d_model=512)\n",
    "2. Project to Q, K, V using W_Q, W_K, W_V\n",
    "3. **Reshape/split** into h heads: (batch, seq_len, h=8, d_k=64)\n",
    "4. Run attention on each head in parallel\n",
    "5. **Concatenate** heads back together: (batch, seq_len, d_model=512)\n",
    "6. Final linear projection with W_O\n",
    "\n",
    "Ready to start implementing? What should we build first - the reshaping logic or the overall MultiHeadAttention class structure?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089da9bb",
   "metadata": {},
   "source": [
    "I don't know what's easier to start with. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let's start with the **overall class structure** first - it's easier to see the big picture, then fill in the details.\n",
    "\n",
    "A MultiHeadedAttention class needs:\n",
    "- `__init__`: store hyperparameters (h, d_model) and create the weight matrices\n",
    "- `forward`: take input, split into heads, run attention, concatenate, project\n",
    "\n",
    "Try writing just the skeleton:\n",
    "\n",
    "```python\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # What do we need to store here?\n",
    "        # What layers/parameters do we need?\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        # What steps go here?\n",
    "```\n",
    "\n",
    "Think about: what parameters does this class need to store? (Hint: you need 4 linear layers - why 4?)\n",
    "\n",
    "Give it a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9e274c",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "i havent a clu where to start\n",
    "\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "No worries! Let me break it down into smaller pieces.\n",
    "\n",
    "**What does MultiHeadedAttention need to do?**\n",
    "\n",
    "Remember: we need to project Q, K, V, then split into heads, run attention, concatenate, and project again.\n",
    "\n",
    "**Start with the `__init__` method. You need:**\n",
    "\n",
    "1. Store `h` (number of heads) and `d_k` (dimension per head)\n",
    "2. Create **4 linear layers**:\n",
    "   - One for projecting to Q\n",
    "   - One for projecting to K  \n",
    "   - One for projecting to V\n",
    "   - One for the final output projection (after concatenating heads)\n",
    "\n",
    "Try writing just the `__init__` method:\n",
    "\n",
    "```python\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.h = h\n",
    "        self.d_k = d_model // h  # dimension per head\n",
    "        \n",
    "        # Create 4 linear layers here\n",
    "        # Each should be nn.Linear(d_model, d_model)\n",
    "```\n",
    "\n",
    "Can you add the 4 linear layers? Maybe store them in a list or as separate attributes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d55d88",
   "metadata": {
    "solveit_ai": true,
    "use_thinking": true
   },
   "source": [
    "So, bro, instead of doing all this guesswork, should I read the paper first and then come back to this notebook? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "\n",
    "\n",
    "That's a totally fair question! There's no single right answer - it depends on how you learn best.\n",
    "\n",
    "**Option A: Read the paper first**\n",
    "- Pros: You'll understand the \"why\" behind each component, the math notation, and the full architecture before coding\n",
    "- Cons: The paper can be dense; some parts might not click until you actually implement them\n",
    "\n",
    "**Option B: Keep coding, refer to paper as needed**\n",
    "- Pros: Hands-on learning, immediate feedback, you discover the \"why\" as you hit roadblocks\n",
    "- Cons: Can feel like guesswork (which is what you're feeling now!)\n",
    "\n",
    "**Option C: Hybrid approach** (my suggestion)\n",
    "- Read just the **Section 3.2 (Attention)** of the paper - it's only ~1.5 pages\n",
    "- It explains Multi-Head Attention with diagrams and equations\n",
    "- Then come back and implement with that understanding\n",
    "\n",
    "The paper is here: https://arxiv.org/pdf/1706.03762 - Section 3.2 starts around page 3.\n",
    "\n",
    "What sounds best to you? Would you like to take a break and read that section, or would you prefer I explain the Multi-Head Attention concept more thoroughly here first?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c2ee2",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "ill read the architecture part first i guess. all the misc experiments i can see later\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great plan! Reading the architecture section first will give you the foundation you need.\n",
    "\n",
    "**What to focus on:**\n",
    "\n",
    "- **Section 3**: Model Architecture (pages 3-5)\n",
    "  - 3.1: Overall encoder-decoder structure\n",
    "  - 3.2: Attention mechanisms (especially Multi-Head Attention)\n",
    "  - 3.3: Position-wise Feed-Forward Networks\n",
    "  - 3.4: Embeddings and Positional Encoding\n",
    "\n",
    "You can skip sections 4 (training details) and 5-6 (experiments/results) for now.\n",
    "\n",
    "Take your time reading, and when you come back, let me know:\n",
    "1. What clicked for you?\n",
    "2. What's still confusing?\n",
    "3. Whether you're ready to continue implementing Multi-Head Attention!\n",
    "\n",
    "See you when you're back! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b95be",
   "metadata": {},
   "source": [
    "## Reading Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9128c347",
   "metadata": {
    "time_run": "2025-11-30T18:10:21.884266+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf2 in /app/data/.local/lib/python3.12/site-packages (3.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf2\n",
    "from PyPDF2 import PdfReader\n",
    "reader = PdfReader('../Attention.pdf')\n",
    "text = '\\n'.join([page.extract_text() for page in reader.pages])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679c84be",
   "metadata": {},
   "source": [
    "Attention Paper Text $`text`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea87da74",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "is the attention paper in context now?\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes! I can see you've loaded the Attention paper PDF and extracted the text into the `text` variable. The paper content is now available in your context.\n",
    "\n",
    "Would you like me to help you:\n",
    "1. Find specific sections (like Section 3.2 on Multi-Head Attention)?\n",
    "2. Explain parts that are confusing as you read?\n",
    "3. Answer questions about what you've read so far?\n",
    "\n",
    "Or are you still reading through it on your own first?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1c4264",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "What does transduction mean? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good question! **Transduction** in the context of this paper means **transforming one sequence into another sequence**.\n",
    "\n",
    "**Examples of transduction tasks:**\n",
    "- **Machine translation**: English sentence  French sentence\n",
    "- **Text summarization**: Long article  Short summary  \n",
    "- **Speech recognition**: Audio sequence  Text sequence\n",
    "\n",
    "It's basically any task where you take an input sequence and produce an output sequence, which might be in a different \"form\" or language.\n",
    "\n",
    "The paper calls the Transformer a \"transduction model\" because it takes a source sequence (e.g., English) and produces a target sequence (e.g., German).\n",
    "\n",
    "Does that make sense? What section are you reading now?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb40f33",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "The encoder transforms the sequence X to sequence Z. What are they referring to? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question! Let me clarify what X and Z represent:\n",
    "\n",
    "**X (input sequence)**: The original input to the encoder\n",
    "- Example: The English sentence \"Hello world\" \n",
    "- Represented as token embeddings: (x, x, ..., x)\n",
    "- These are discrete tokens converted to vectors\n",
    "\n",
    "**Z (continuous representations)**: The encoder's output\n",
    "- A sequence of continuous vector representations: (z, z, ..., z)\n",
    "- Same length as input, but now \"enriched\" with context from the whole sentence\n",
    "- Each z contains information about x AND its relationship to all other tokens\n",
    "\n",
    "**The transformation**: X  Z\n",
    "- X is the \"raw\" embedded input\n",
    "- Z is the contextualized representation after all the encoder layers process it\n",
    "- Z captures meaning, relationships, and context\n",
    "\n",
    "Then the decoder uses Z (along with previous outputs) to generate the target sequence Y.\n",
    "\n",
    "Does that clarify it? What part of the architecture are you reading about now?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fde77f",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I'm reading Section 3.1. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Section 3.1 covers the overall encoder-decoder structure.\n",
    "\n",
    "**Key points in 3.1:**\n",
    "\n",
    "- **Encoder**: Takes input sequence, produces contextualized representations (the Z we just discussed)\n",
    "- **Decoder**: Takes Z + previously generated outputs, produces next token (auto-regressive)\n",
    "- Both encoder and decoder are stacks of N=6 identical layers\n",
    "- Each layer has sub-layers with residual connections and layer normalization\n",
    "\n",
    "As you read through, are the concepts of:\n",
    "1. **Stacked layers** (N=6 identical layers on top of each other) clear?\n",
    "2. **Auto-regressive generation** (decoder generates one token at a time, using previous outputs) making sense?\n",
    "\n",
    "Let me know what questions come up or when you're ready to move to Section 3.2 (the attention mechanisms)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831d7cc6",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Why do we divide by square root of dk? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent question! This is one of the key insights in the attention mechanism.\n",
    "\n",
    "**The problem without scaling:**\n",
    "\n",
    "When d_k (the dimension) is large, the dot products QK^T can get very large in magnitude. \n",
    "\n",
    "**Why is this bad?**\n",
    "\n",
    "Large dot products  softmax gets pushed into regions with extremely small gradients  model can't learn well (vanishing gradients)\n",
    "\n",
    "**The math intuition:**\n",
    "\n",
    "If Q and K have components that are random variables with mean 0 and variance 1, then their dot product has:\n",
    "- Mean: 0\n",
    "- Variance: d_k (grows with dimension!)\n",
    "\n",
    "By dividing by d_k, we scale the variance back down to ~1, keeping the values in a reasonable range for softmax.\n",
    "\n",
    "**In simple terms:** It prevents the attention scores from getting too extreme, which keeps the softmax working properly and gradients flowing during training.\n",
    "\n",
    "Does this make sense? Have you gotten to Section 3.2.1 yet where they explain this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293255d1",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Give me an actual numerical example. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Let me show you with actual numbers.\n",
    "\n",
    "**Without scaling (d_k = 64):**\n",
    "\n",
    "Say Q and K are random vectors with values around -1 to 1:\n",
    "```\n",
    "Q = [0.5, -0.3, 0.8, ..., 0.2]  (64 dimensions)\n",
    "K = [0.4, 0.6, -0.5, ..., 0.7]  (64 dimensions)\n",
    "\n",
    "QK = 0.5*0.4 + (-0.3)*0.6 + ... (64 terms)\n",
    "     25.3  (large number!)\n",
    "```\n",
    "\n",
    "**After softmax on large scores:**\n",
    "```\n",
    "scores = [25.3, 18.7, 30.1, 12.4]\n",
    "softmax = [0.82, 0.001, 0.999, 0.0001]   Very extreme! Almost one-hot\n",
    "```\n",
    "\n",
    "**With scaling (divide by 64 = 8):**\n",
    "```\n",
    "scaled_scores = [3.16, 2.34, 3.76, 1.55]\n",
    "softmax = [0.35, 0.15, 0.45, 0.05]   Much smoother distribution\n",
    "```\n",
    "\n",
    "See the difference? Without scaling, softmax becomes too \"confident\" (almost all weight on one item). With scaling, you get a more balanced attention distribution.\n",
    "\n",
    "Does this numerical example clarify why we need the d_k scaling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26253f6",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "So, these scores are what for each sequence length? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question! Let me clarify what these scores represent.\n",
    "\n",
    "**The scores are for each pair of positions in the sequence.**\n",
    "\n",
    "If you have a sequence of length 4 (e.g., 4 words), you get a **44 matrix** of scores:\n",
    "\n",
    "```\n",
    "        word1  word2  word3  word4\n",
    "word1   [25.3  18.7  30.1  12.4]   how much word1 attends to each word\n",
    "word2   [20.1  22.5  15.3  28.7]   how much word2 attends to each word\n",
    "word3   [19.2  31.4  21.8  16.5]   how much word3 attends to each word\n",
    "word4   [27.6  14.2  23.1  19.8]   how much word4 attends to each word\n",
    "```\n",
    "\n",
    "Each **row** is one query asking \"how much should I attend to each position?\"\n",
    "\n",
    "Each **column** is one key saying \"here's how relevant I am to each query\"\n",
    "\n",
    "So for a sequence of length n, you get an **nn attention score matrix**.\n",
    "\n",
    "Does that clarify what the scores represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d2b2a3",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "The paper we mentioned, \"Additive Attention\", what the heck is that? Give some examples with numbers as well. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good question! **Additive attention** is an older attention mechanism that came before the dot-product attention used in Transformers.\n",
    "\n",
    "**Additive Attention (Bahdanau attention):**\n",
    "\n",
    "Instead of QK^T, it uses a small neural network:\n",
    "\n",
    "```\n",
    "score = v^T  tanh(WQ + WK)\n",
    "```\n",
    "\n",
    "Where v, W, W are learned parameters.\n",
    "\n",
    "**Numerical example:**\n",
    "\n",
    "Say d_k = 3, and we have:\n",
    "```\n",
    "Q = [1, 2, 1]\n",
    "K = [2, 0, 1]\n",
    "\n",
    "Step 1: Linear transformations\n",
    "WQ = [0.5, 1.5]  (project to hidden dim=2)\n",
    "WK = [1.0, 0.5]\n",
    "\n",
    "Step 2: Add and apply tanh\n",
    "tanh([0.5+1.0, 1.5+0.5]) = tanh([1.5, 2.0]) = [0.91, 0.96]\n",
    "\n",
    "Step 3: Project to scalar\n",
    "v^T  [0.91, 0.96] = [0.5, 0.6]  [0.91, 0.96] = 1.03\n",
    "```\n",
    "\n",
    "**Key difference:** Additive uses a feedforward network, dot-product just multiplies. Dot-product is faster (just matrix multiplication) which is why Transformers use it.\n",
    "\n",
    "Does this comparison make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d068601",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "The paper says it works better for larger values of decay. So do we use additive attention for larger values of decay? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good catch reading carefully! Let me clarify what the paper actually says:\n",
    "\n",
    "The paper says **additive attention outperforms dot-product attention WITHOUT scaling** for larger values of d_k.\n",
    "\n",
    "But then they add the scaling factor (dividing by d_k), which **fixes the problem**. So with scaling, dot-product attention works well even for large d_k.\n",
    "\n",
    "**In practice:**\n",
    "- Transformers use **scaled dot-product attention** (what you implemented)\n",
    "- Additive attention is rarely used anymore because scaled dot-product is:\n",
    "  - Faster (just matrix multiplication, highly optimized)\n",
    "  - More space-efficient\n",
    "  - Works just as well with the scaling fix\n",
    "\n",
    "So no, we don't switch to additive attention for large d_k. We just use the d_k scaling to keep dot-product working well!\n",
    "\n",
    "Does that clear up the confusion?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7021648",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "So, in practise, we are never using additive attention, am I correct? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Exactly correct! \n",
    "\n",
    "In modern practice, **we don't use additive attention**. The Transformer paper mentions it mainly for historical context and to explain why they chose scaled dot-product attention.\n",
    "\n",
    "**What we actually use:**\n",
    "- Scaled dot-product attention (what you've already implemented!)\n",
    "- It's faster, simpler, and works great with the d_k scaling\n",
    "\n",
    "The paper just wanted to acknowledge that additive attention exists and explain why dot-product + scaling is the better choice.\n",
    "\n",
    "Are you ready to move on to Section 3.2.2 about Multi-Head Attention, or do you have more questions about the attention mechanism itself?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a088678",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Okay, I'm reading this. I'm kind of lost. We take q, k, and v as inputs and project them using wiq, wiv, and wik. Am I correct? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes, you're on the right track! Let me clarify the flow:\n",
    "\n",
    "**In Multi-Head Attention:**\n",
    "\n",
    "1. You start with the **same input** (let's call it X)\n",
    "2. You project it to get Q, K, V: \n",
    "   - Q = X @ W^Q\n",
    "   - K = X @ W^K  \n",
    "   - V = X @ W^V\n",
    "\n",
    "3. **Then for multi-head**, each head has its own projection matrices:\n",
    "   - Head i uses: W^Q_i, W^K_i, W^V_i\n",
    "   - So you get Q_i, K_i, V_i for each head\n",
    "\n",
    "4. Run attention on each head separately\n",
    "5. Concatenate all head outputs\n",
    "6. Final projection with W^O\n",
    "\n",
    "**Key point:** You're projecting the input X multiple times (once per head), not projecting Q, K, V again.\n",
    "\n",
    "Does this clarify the flow? Or are you still confused about which projections happen when?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed63898f",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Oh, so the outputs are D_K. Which is basically the input length divided by the number of heads. Am I correct? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Not quite! Let me clarify the dimensions:\n",
    "\n",
    "**d_k is NOT the input length.** It's the **dimension per head**.\n",
    "\n",
    "Here's the breakdown:\n",
    "\n",
    "- **d_model**: The full model dimension (e.g., 512)\n",
    "- **h**: Number of heads (e.g., 8)\n",
    "- **d_k**: Dimension per head = d_model / h (e.g., 512/8 = 64)\n",
    "\n",
    "**The shapes:**\n",
    "```\n",
    "Input X: (batch, seq_len, d_model)\n",
    "         e.g., (32, 50, 512)\n",
    "\n",
    "After projecting and splitting into heads:\n",
    "Q, K, V: (batch, h, seq_len, d_k)\n",
    "         e.g., (32, 8, 50, 64)\n",
    "```\n",
    "\n",
    "So **seq_len** (input length) stays the same. We're splitting the **feature dimension** (d_model) across heads, not the sequence length!\n",
    "\n",
    "Does this distinction make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5959be11",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "But we are basically multiplying the whole d_model input with the W to make projections of size d_k. Am I correct? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Almost! Let me clarify the projection step:\n",
    "\n",
    "**What actually happens:**\n",
    "\n",
    "You multiply the input (d_model) with W to get an output that's **still d_model size**, then you **reshape/split** it into h heads of size d_k each.\n",
    "\n",
    "```\n",
    "Input: (batch, seq_len, d_model=512)\n",
    "       \n",
    "W^Q projection: (d_model=512, d_model=512)\n",
    "       \n",
    "Q: (batch, seq_len, d_model=512)\n",
    "       \n",
    "Reshape/split into heads: (batch, h=8, seq_len, d_k=64)\n",
    "```\n",
    "\n",
    "So the projection matrix W^Q is **512512**, not 51264. You get the full d_model output, then split it into heads.\n",
    "\n",
    "**Alternative approach** (mathematically equivalent):\n",
    "Some implementations do use h separate smaller matrices (d_model  d_k), but conceptually it's the same.\n",
    "\n",
    "Does this clarify the projection dimensions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10c614b",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Okay, I'm pretty much saying the same thing because the paper talks about WI. Which means the weight for each head. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Ah yes, you're absolutely right! I apologize for the confusion.\n",
    "\n",
    "You're correct - the paper uses **W^Q_i, W^K_i, W^V_i** for each head i, which are the **individual projection matrices for that specific head**.\n",
    "\n",
    "So yes, each head has its own:\n",
    "- W^Q_i: projects from d_model to d_k\n",
    "- W^K_i: projects from d_model to d_k  \n",
    "- W^V_i: projects from d_model to d_k\n",
    "\n",
    "Then you run attention separately on each head's Q_i, K_i, V_i.\n",
    "\n",
    "You had it right! The paper does describe it with separate weight matrices per head (the subscript i indicates which head).\n",
    "\n",
    "So to confirm: you multiply the d_model input with W_i to get projections of size d_k for each head. \n",
    "\n",
    "Ready to keep reading, or want to clarify anything else about multi-head attention?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d371ca",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Well, I understand your point too that in application, you just have a consolidated W. Am I correct? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Exactly! You've got it!\n",
    "\n",
    "**In practice (implementation):**\n",
    "- You often have one big consolidated W^Q matrix (d_model  d_model)\n",
    "- Then you reshape/split the output into h heads of d_k each\n",
    "- This is computationally more efficient (one big matrix multiply vs. h small ones)\n",
    "\n",
    "**Conceptually (in the paper):**\n",
    "- They describe it as h separate W^Q_i matrices (d_model  d_k)\n",
    "- This makes the math clearer to understand\n",
    "\n",
    "Both views are equivalent - just different ways of thinking about/implementing the same operation!\n",
    "\n",
    "Have you finished reading Section 3.2.2 on Multi-Head Attention? Ready to start implementing it, or do you want to read more of the paper first?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7067397c",
   "metadata": {},
   "source": [
    "## MultiHeadedAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e85e89",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "yes lets implement now\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Let's implement Multi-Head Attention.\n",
    "\n",
    "We'll start with the `__init__` method. You need to store:\n",
    "1. Number of heads (h) and dimension per head (d_k)\n",
    "2. The projection matrices (we'll use the consolidated approach - 4 linear layers)\n",
    "3. A dropout layer\n",
    "\n",
    "Try writing this:\n",
    "\n",
    "```python\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % h == 0  # d_model must be divisible by h\n",
    "        \n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        \n",
    "        # Create 4 linear layers (Q, K, V projections + final output)\n",
    "        # Hint: you can use a list or create them individually\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "```\n",
    "\n",
    "Can you add the 4 linear layers? Each should be `nn.Linear(d_model, d_model)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b265321b",
   "metadata": {
    "time_run": "2025-11-30T18:10:22.127511+00:00"
   },
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(torch.nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % h == 0  # d_model must be divisible by h\n",
    "        \n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.attn=None\n",
    "        \n",
    "        # Create 4 linear layers (Q, K, V projections + final output)\n",
    "        # Hint: you can use a list or create them individually\n",
    "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(d_model, d_model) for x in range(4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475ba07d",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "all good?\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent! Your `__init__` is perfect! \n",
    "\n",
    "You've got:\n",
    "-  d_k calculation\n",
    "-  All 4 linear layers in a ModuleList\n",
    "-  Dropout layer\n",
    "-  self.attn for storing attention weights (good thinking!)\n",
    "\n",
    "Now let's implement the `forward` method. The steps are:\n",
    "\n",
    "1. Get batch size\n",
    "2. Project input to Q, K, V using first 3 linear layers\n",
    "3. Reshape from (batch, seq_len, d_model) to (batch, h, seq_len, d_k)\n",
    "4. Apply attention function\n",
    "5. Reshape back and concatenate heads\n",
    "6. Apply final linear layer\n",
    "\n",
    "Try starting with steps 1-2. Can you write the code to:\n",
    "- Get the batch size from the query input\n",
    "- Apply the first 3 linear layers to query, key, value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a661ed",
   "metadata": {
    "time_run": "2025-11-30T18:10:22.176080+00:00"
   },
   "outputs": [],
   "source": [
    "def forward(self, query, key, value, mask=None):\n",
    "    # Step 1: Project query, key, value using the first 3 linear layers\n",
    "    Q = self.linear_layers[0](query)\n",
    "    K = self.linear_layers[1](key)\n",
    "    V = self.linear_layers[2](value)\n",
    "    # Step 2: Reshape to split into h heads\n",
    "    batch_size = Q.size(0)\n",
    "    seq_len = Q.size(1)\n",
    "    Q = Q.view(batch_size, self.h, seq_len, self.d_k)\n",
    "    K = K.view(batch_size, self.h, seq_len, self.d_k)\n",
    "    V = V.view(batch_size, self.h, seq_len, self.d_k)\n",
    "    # Step 3: Apply attention\n",
    "\n",
    "    # Step 4: Concatenate heads back together\n",
    "    # Step 5: Apply final linear projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2326b697",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "So far, so good?\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great progress! Your projection and reshaping look good. One small issue with the reshape:\n",
    "\n",
    "The order should be `(batch_size, seq_len, h, d_k)` first, then use `.transpose(1, 2)` to get `(batch_size, h, seq_len, d_k)`.\n",
    "\n",
    "Try changing:\n",
    "```python\n",
    "Q = Q.view(batch_size, seq_len, self.h, self.d_k).transpose(1, 2)\n",
    "```\n",
    "\n",
    "This makes the reshaping cleaner. Does that make sense?\n",
    "\n",
    "Once you fix that, try Step 3 - call your `attention()` function with Q, K, V. What do you get back, and what shape will it be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3df0ee",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Why is that cleaner? I don't understand. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good question! Let me explain why.\n",
    "\n",
    "**Your approach:**\n",
    "```python\n",
    "Q.view(batch_size, self.h, seq_len, self.d_k)\n",
    "```\n",
    "\n",
    "This directly reshapes the flat d_model dimension into (h, seq_len, d_k), but the data in memory isn't organized that way yet.\n",
    "\n",
    "**The cleaner approach:**\n",
    "```python\n",
    "Q.view(batch_size, seq_len, self.h, self.d_k).transpose(1, 2)\n",
    "```\n",
    "\n",
    "Step 1: `view(batch_size, seq_len, self.h, self.d_k)` - splits d_model into (h, d_k) while keeping seq_len intact\n",
    "Step 2: `.transpose(1, 2)` - swaps seq_len and h dimensions to get (batch_size, h, seq_len, d_k)\n",
    "\n",
    "**Why is it cleaner?** The view operation splits the last dimension naturally (d_model  h  d_k), which matches how the data is laid out in memory. Then transpose just reorders the dimensions.\n",
    "\n",
    "Your way might work, but the viewtranspose pattern is the standard approach and less likely to cause weird reshaping bugs.\n",
    "\n",
    "Want to try updating your code with this pattern?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a45b4e",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Oh, so I understand now. We are first trying to split DM into H pieces. Then we swap the dimension edge and sequence length. So that we can pass it into H attention heads. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Exactly! You've got it! \n",
    "\n",
    "**The logic:**\n",
    "1. Split d_model into h pieces of size d_k: `(batch, seq_len, d_model)  (batch, seq_len, h, d_k)`\n",
    "2. Swap so heads come before seq_len: `(batch, seq_len, h, d_k)  (batch, h, seq_len, d_k)`\n",
    "3. Now each head can process its own (seq_len, d_k) slice independently in parallel!\n",
    "\n",
    "This organization makes it easy to run attention on all h heads at once.\n",
    "\n",
    "Now try updating your reshape code with this pattern, then move to Step 3 - calling the `attention()` function. What will you pass to it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937be209",
   "metadata": {
    "time_run": "2025-11-30T18:10:22.235871+00:00"
   },
   "outputs": [],
   "source": [
    "def forward(self, query, key, value, mask=None):\n",
    "    # Step 1: Project query, key, value using the first 3 linear layers\n",
    "    Q = self.linear_layers[0](query)\n",
    "    K = self.linear_layers[1](key)\n",
    "    V = self.linear_layers[2](value)\n",
    "    # Step 2: Reshape to split into h heads\n",
    "    batch_size = Q.size(0)\n",
    "    seq_len = Q.size(1)\n",
    "    Q = Q.view(batch_size, seq_len, self.h, self.d_k).transpose(1,2)\n",
    "    K = K.view(batch_size, seq_len, self.h, self.d_k).transpose(1,2)\n",
    "    V = V.view(batch_size, seq_len, self.h, self.d_k).transpose(1,2)\n",
    "    # Step 3: Apply attention\n",
    "\n",
    "    # Step 4: Concatenate heads back together\n",
    "    # Step 5: Apply final linear projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e169101e",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "better now?\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your reshaping is now correct. \n",
    "\n",
    "Now for Step 3 - applying attention. You need to call your `attention()` function. \n",
    "\n",
    "What arguments will you pass to it? Remember the signature:\n",
    "```python\n",
    "attention(Q, K, V, dropout, mask)\n",
    "```\n",
    "\n",
    "What should each argument be? Give it a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f26ca1e",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "good?\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Almost! A few small issues:\n",
    "\n",
    "1. **self.mask doesn't exist** - you should pass the `mask` parameter from the function arguments\n",
    "2. **You're passing mask twice** - check your attention function signature\n",
    "3. **Store the result** - you need to capture what attention returns\n",
    "\n",
    "Your attention function signature is:\n",
    "```python\n",
    "def attention(Q, K, V, dropout, mask):\n",
    "```\n",
    "\n",
    "So it should be:\n",
    "```python\n",
    "x = attention(Q, K, V, self.dropout, mask)\n",
    "```\n",
    "\n",
    "Also, one more thing: if mask is provided, you need to unsqueeze it to match the head dimension. Try:\n",
    "```python\n",
    "if mask is not None:\n",
    "    mask = mask.unsqueeze(1)  # Add head dimension\n",
    "```\n",
    "\n",
    "Can you fix these issues?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7050c370",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "What is mask unsqueeze 1? I don't understand. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good question! Let me explain `unsqueeze`.\n",
    "\n",
    "**What is unsqueeze?**\n",
    "\n",
    "It adds a new dimension to a tensor at the specified position.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "mask = torch.tensor([[1, 1, 0, 0]])  # shape: (1, 4)\n",
    "\n",
    "mask.unsqueeze(0)  # shape: (1, 1, 4) - adds dim at position 0\n",
    "mask.unsqueeze(1)  # shape: (1, 1, 4) - adds dim at position 1\n",
    "mask.unsqueeze(2)  # shape: (1, 4, 1) - adds dim at position 2\n",
    "```\n",
    "\n",
    "**Why do we need it here?**\n",
    "\n",
    "Your mask comes in with shape: `(batch_size, seq_len, seq_len)`\n",
    "\n",
    "But after splitting into heads, Q, K, V have shape: `(batch_size, h, seq_len, d_k)`\n",
    "\n",
    "So the mask needs to be: `(batch_size, 1, seq_len, seq_len)` - the `1` broadcasts across all h heads.\n",
    "\n",
    "`mask.unsqueeze(1)` adds that dimension at position 1 (after batch_size).\n",
    "\n",
    "Does this make sense? Want to see a numerical example?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f063f92",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I still don't understand how the one broadcast across all H heads. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question! Let me explain **broadcasting**.\n",
    "\n",
    "**What is broadcasting?**\n",
    "\n",
    "When you do operations between tensors of different shapes, PyTorch automatically \"stretches\" dimensions of size 1 to match the other tensor.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "A = torch.tensor([[[1, 2, 3]]])  # shape: (1, 1, 3)\n",
    "B = torch.tensor([[[10], [20]]])  # shape: (1, 2, 1)\n",
    "\n",
    "A + B  # Result shape: (1, 2, 3)\n",
    "# The 1s get \"broadcast\" (repeated) to match\n",
    "```\n",
    "\n",
    "**In our case:**\n",
    "```python\n",
    "mask shape:      (batch, 1,     seq_len, seq_len)\n",
    "attention shape: (batch, h=8,   seq_len, seq_len)\n",
    "                          \n",
    "                    This 1 broadcasts to 8\n",
    "```\n",
    "\n",
    "The mask with dimension 1 automatically gets **copied/repeated** 8 times (once for each head) when you apply it.\n",
    "\n",
    "So the same mask applies to all heads, but PyTorch handles the copying automatically!\n",
    "\n",
    "Does this clarify how broadcasting works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed41cdd",
   "metadata": {
    "time_run": "2025-11-30T18:10:22.284388+00:00"
   },
   "outputs": [],
   "source": [
    "def forward(self, query, key, value, mask=None):\n",
    "    # Step 1: Project query, key, value using the first 3 linear layers\n",
    "    Q = self.linear_layers[0](query)\n",
    "    K = self.linear_layers[1](key)\n",
    "    V = self.linear_layers[2](value)\n",
    "    # Step 2: Reshape to split into h heads\n",
    "    batch_size = Q.size(0)\n",
    "    seq_len = Q.size(1)\n",
    "    Q = Q.view(batch_size, seq_len, self.h, self.d_k).transpose(1,2)\n",
    "    K = K.view(batch_size, seq_len, self.h, self.d_k).transpose(1,2)\n",
    "    V = V.view(batch_size, seq_len, self.h, self.d_k).transpose(1,2)\n",
    "    # Step 3: Apply attention\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(1)\n",
    "    x = attention(Q,K,V, self.dropout, mask)\n",
    "\n",
    "    # Step 4: Concatenate heads back together\n",
    "    # Step 5: Apply final linear projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9633fa",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this better now? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent! Step 3 is now correct! \n",
    "\n",
    "You've got:\n",
    "-  Mask unsqueeze for broadcasting across heads\n",
    "-  Calling attention with the right arguments\n",
    "-  Storing result in `x`\n",
    "\n",
    "Now for **Step 4: Concatenate heads back together**\n",
    "\n",
    "After attention, `x` has shape: `(batch_size, h, seq_len, d_k)`\n",
    "\n",
    "You need to get back to: `(batch_size, seq_len, d_model)`\n",
    "\n",
    "This is the reverse of what you did earlier:\n",
    "1. Transpose to swap h and seq_len back\n",
    "2. Reshape/view to merge h and d_k into d_model\n",
    "\n",
    "Try writing the code for step 4. What operations do you need?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32243280",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Wait, I'm seriously confused. How is reshaping the whole thing led to multiple attention heads? this is the attn fn \n",
    "def attention(Q, K, V, dropout, mask):\n",
    "    sqrt_d_k = math.sqrt(K.size(-1))\n",
    "    dropout_layer = torch.nn.Dropout(p=dropout)\n",
    "    scores = Q @ K.transpose(-2,-1) / sqrt_d_k\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask==0, -1e9)\n",
    "    attention_weights = torch.softmax(scores, dim=-1)\n",
    "    attention_weights = dropout_layer(attention_weights)\n",
    "    output = attention_weights @ V\n",
    "    return output\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent question! This is a key insight about how multi-head attention works.\n",
    "\n",
    "**The magic is in the tensor dimensions!**\n",
    "\n",
    "When you pass Q, K, V with shape `(batch_size, h, seq_len, d_k)` to the attention function, PyTorch's matrix operations work **independently on each head automatically**.\n",
    "\n",
    "Let's trace through it:\n",
    "\n",
    "```python\n",
    "Q shape: (batch=2, h=8, seq_len=10, d_k=64)\n",
    "K shape: (batch=2, h=8, seq_len=10, d_k=64)\n",
    "\n",
    "Q @ K.transpose(-2,-1)\n",
    "```\n",
    "\n",
    "The `@` operator does matrix multiplication on the **last two dimensions** only. The first dimensions (batch, h) are treated as \"batch dimensions\" - so it runs 28=16 separate attention operations in parallel!\n",
    "\n",
    "**In other words:**\n",
    "- You have 8 heads\n",
    "- Each head processes its slice: Q[:, 0, :, :], Q[:, 1, :, :], ... Q[:, 7, :, :]\n",
    "- The matrix operations happen independently for each head\n",
    "- All in one efficient operation!\n",
    "\n",
    "Does this click now? The reshaping sets up the dimensions so that one function call runs all heads in parallel!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f589c331",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Okay, this makes sense and clicks. No wonder attention (incl multiheaded attention) is so much faster than previous methods like R and N and LSTM. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Exactly! You've hit on one of the key innovations! \n",
    "\n",
    "**Why Transformers are faster:**\n",
    "\n",
    "- **RNNs/LSTMs**: Process sequentially (word 1  word 2  word 3...). Can't parallelize across the sequence.\n",
    "- **Transformers**: All positions processed at once! The entire attention matrix is computed in parallel.\n",
    "\n",
    "Plus, with multi-head attention, all 8 heads also run in parallel thanks to the clever tensor reshaping you just understood.\n",
    "\n",
    "This parallelization is what makes Transformers scale so well with modern GPUs!\n",
    "\n",
    "Now, ready to finish Step 4? You need to concatenate the heads back together. Remember:\n",
    "- Current shape: `(batch_size, h, seq_len, d_k)`\n",
    "- Target shape: `(batch_size, seq_len, d_model)`\n",
    "\n",
    "What operations do you need? (Hint: reverse of what you did earlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393a274e",
   "metadata": {
    "time_run": "2025-11-30T18:10:22.343087+00:00"
   },
   "outputs": [],
   "source": [
    "def forward(self, query, key, value, mask=None):\n",
    "    # Step 1: Project query, key, value using the first 3 linear layers\n",
    "    Q = self.linear_layers[0](query)\n",
    "    K = self.linear_layers[1](key)\n",
    "    V = self.linear_layers[2](value)\n",
    "    # Step 2: Reshape to split into h heads\n",
    "    batch_size = Q.size(0)\n",
    "    seq_len = Q.size(1)\n",
    "    Q = Q.view(batch_size, seq_len, self.h, self.d_k).transpose(1,2)\n",
    "    K = K.view(batch_size, seq_len, self.h, self.d_k).transpose(1,2)\n",
    "    V = V.view(batch_size, seq_len, self.h, self.d_k).transpose(1,2)\n",
    "    # Step 3: Apply attention\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(1)\n",
    "    x = attention(Q,K,V, self.dropout, mask)\n",
    "\n",
    "    # Step 4: Concatenate heads back together\n",
    "    x = x.transpose(1,2).view(batch_size,seq_len, -1)\n",
    "    # Step 5: Apply final linear projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04edb28",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this correct? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Step 4 is correct! \n",
    "\n",
    "You've done:\n",
    "- `.transpose(1,2)` to swap h and seq_len back: `(batch, h, seq_len, d_k)  (batch, seq_len, h, d_k)`\n",
    "- `.view(batch_size, seq_len, -1)` to merge the last two dims: `(batch, seq_len, h, d_k)  (batch, seq_len, d_model)`\n",
    "\n",
    "The `-1` automatically calculates h  d_k = d_model. Nice!\n",
    "\n",
    "Now for **Step 5: Apply final linear projection**\n",
    "\n",
    "You need to pass `x` through the 4th linear layer (the output projection W^O). This mixes information across all the concatenated heads.\n",
    "\n",
    "Can you add that final step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118dc776",
   "metadata": {
    "time_run": "2025-11-30T18:10:22.391017+00:00"
   },
   "outputs": [],
   "source": [
    "def forward(self, query, key, value, mask=None):\n",
    "    # Step 1: Project query, key, value using the first 3 linear layers\n",
    "    Q = self.linear_layers[0](query)\n",
    "    K = self.linear_layers[1](key)\n",
    "    V = self.linear_layers[2](value)\n",
    "    # Step 2: Reshape to split into h heads\n",
    "    batch_size = Q.size(0)\n",
    "    seq_len = Q.size(1)\n",
    "    Q = Q.view(batch_size, seq_len, self.h, self.d_k).transpose(1,2)\n",
    "    K = K.view(batch_size, seq_len, self.h, self.d_k).transpose(1,2)\n",
    "    V = V.view(batch_size, seq_len, self.h, self.d_k).transpose(1,2)\n",
    "    # Step 3: Apply attention\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(1)\n",
    "    x = attention(Q,K,V, self.dropout, mask)\n",
    "    # Step 4: Concatenate heads back together\n",
    "    x = x.transpose(1,2).view(batch_size,seq_len, -1)\n",
    "    # Step 5: Apply final linear projection\n",
    "    output = self.linear_layers[3](x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c66965",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Am I successful now? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent work! Your Multi-Head Attention implementation is complete! \n",
    "\n",
    "You've successfully implemented:\n",
    "-  Projecting to Q, K, V\n",
    "-  Splitting into multiple heads\n",
    "-  Running attention on all heads in parallel\n",
    "-  Concatenating heads back\n",
    "-  Final output projection\n",
    "\n",
    "Now let's test it to make sure it works! Try this:\n",
    "\n",
    "```python\n",
    "# Test with realistic dimensions\n",
    "mha = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "x = torch.randn(2, 10, 512)  # batch=2, seq_len=10, d_model=512\n",
    "\n",
    "output = mha.forward(x, x, x, mask=None)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))\n",
    "```\n",
    "\n",
    "Run this and see if it works! What do you get?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d788e7f",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Wait a minute, shouldn't we put the class and the function together? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good catch! Yes, you need to add the `forward` method **inside** the `MultiHeadedAttention` class!\n",
    "\n",
    "Right now you have the class definition with `__init__`, but the `forward` method is separate. You need to indent the `forward` method so it's part of the class.\n",
    "\n",
    "It should look like:\n",
    "\n",
    "```python\n",
    "class MultiHeadedAttention(torch.nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        # ... your init code ...\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        # ... your forward code ...\n",
    "```\n",
    "\n",
    "Can you combine them properly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f267327",
   "metadata": {
    "time_run": "2025-11-30T18:10:22.439276+00:00"
   },
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(torch.nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % h == 0  # d_model must be divisible by h\n",
    "        \n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.attn=None\n",
    "        \n",
    "        # Create 4 linear layers (Q, K, V projections + final output)\n",
    "        # Hint: you can use a list or create them individually\n",
    "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(d_model, d_model) for x in range(4)])\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        # Step 1: Project query, key, value using the first 3 linear layers\n",
    "        Q = self.linear_layers[0](query)\n",
    "        K = self.linear_layers[1](key)\n",
    "        V = self.linear_layers[2](value)\n",
    "        # Step 2: Reshape to split into h heads\n",
    "        batch_size = Q.size(0)\n",
    "        seq_len = Q.size(1)\n",
    "        Q = Q.view(batch_size, seq_len, self.h, self.d_k).transpose(1,2)\n",
    "        K = K.view(batch_size, seq_len, self.h, self.d_k).transpose(1,2)\n",
    "        V = V.view(batch_size, seq_len, self.h, self.d_k).transpose(1,2)\n",
    "        # Step 3: Apply attention\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "        x = attention(Q,K,V, self.dropout, mask)\n",
    "        # Step 4: Concatenate heads back together\n",
    "        x = x.transpose(1,2).view(batch_size,seq_len, -1)\n",
    "        # Step 5: Apply final linear projection\n",
    "        output = self.linear_layers[3](x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520f0ec6",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "all good?\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `MultiHeadedAttention` class is now complete and properly structured! \n",
    "\n",
    "Now let's test it to make sure everything works:\n",
    "\n",
    "```python\n",
    "# Test with realistic dimensions\n",
    "mha = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "x = torch.randn(2, 10, 512)  # batch=2, seq_len=10, d_model=512\n",
    "\n",
    "output = mha.forward(x, x, x, mask=None)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))\n",
    "```\n",
    "\n",
    "Run this and let me know if it works! Does the output shape match what you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b537959b",
   "metadata": {
    "time_run": "2025-11-30T18:10:22.499137+00:00"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m",
      "\u001b[32m      2\u001b[39m mha = MultiHeadedAttention(h=\u001b[32m8\u001b[39m, d_model=\u001b[32m512\u001b[39m, dropout=\u001b[32m0.1\u001b[39m)",
      "\u001b[32m      3\u001b[39m x = torch.randn(\u001b[32m2\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m512\u001b[39m)  \u001b[38;5;66;03m# batch=2, seq_len=10, d_model=512\u001b[39;00m",
      "\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m output = \u001b[43mmha\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m",
      "\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOutput shape:\u001b[39m\u001b[33m\"\u001b[39m, output.shape)",
      "\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExpected:\u001b[39m\u001b[33m\"\u001b[39m, (\u001b[32m2\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m512\u001b[39m))",
      "",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mMultiHeadedAttention.forward\u001b[39m\u001b[34m(self, query, key, value, mask)\u001b[39m",
      "\u001b[32m     29\u001b[39m x = attention(Q,K,V, \u001b[38;5;28mself\u001b[39m.dropout, mask)",
      "\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Step 4: Concatenate heads back together\u001b[39;00m",
      "\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m x = \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m",
      "\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Step 5: Apply final linear projection\u001b[39;00m",
      "\u001b[32m     33\u001b[39m output = \u001b[38;5;28mself\u001b[39m.linear_layers[\u001b[32m3\u001b[39m](x)",
      "",
      "\u001b[31mRuntimeError\u001b[39m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "# Test with realistic dimensions\n",
    "mha = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "x = torch.randn(2, 10, 512)  # batch=2, seq_len=10, d_model=512\n",
    "\n",
    "output = mha.forward(x, x, x, mask=None)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970472d2",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "no, whyyyy?\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Don't worry, this is a common issue! The error is telling you exactly what to do.\n",
    "\n",
    "**The problem:** After `.transpose()`, the tensor is no longer \"contiguous\" in memory, so `.view()` doesn't work.\n",
    "\n",
    "**The fix:** Use `.contiguous()` before `.view()`, or just use `.reshape()` instead:\n",
    "\n",
    "Change this line:\n",
    "```python\n",
    "x = x.transpose(1,2).view(batch_size, seq_len, -1)\n",
    "```\n",
    "\n",
    "To either:\n",
    "```python\n",
    "x = x.transpose(1,2).contiguous().view(batch_size, seq_len, -1)\n",
    "```\n",
    "\n",
    "Or simply:\n",
    "```python\n",
    "x = x.transpose(1,2).reshape(batch_size, seq_len, -1)\n",
    "```\n",
    "\n",
    "`.reshape()` handles the contiguity automatically! Try updating your code and run the test again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8de718",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I don't understand, what do you mean by \"contiguous?\" What exactly is the issue? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question! Let me explain **contiguous memory**.\n",
    "\n",
    "**What is contiguous?**\n",
    "\n",
    "Contiguous means the tensor's elements are stored in a single, continuous block of memory in the order you'd expect.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Original tensor: `[[1, 2], [3, 4]]` stored in memory as: `[1, 2, 3, 4]`  contiguous\n",
    "\n",
    "After transpose: `[[1, 3], [2, 4]]` but memory is still: `[1, 2, 3, 4]`\n",
    "\n",
    "PyTorch just changes how it *interprets* the memory (using strides), but doesn't actually move the data. So now it's not contiguous anymore!\n",
    "\n",
    "**Why does `.view()` care?**\n",
    "\n",
    "`.view()` requires contiguous memory because it's a \"zero-copy\" operation - it just reinterprets the existing memory layout. If the memory isn't laid out right, it can't do that.\n",
    "\n",
    "**Solutions:**\n",
    "- `.contiguous()` - actually rearranges memory to be contiguous (makes a copy)\n",
    "- `.reshape()` - automatically calls `.contiguous()` if needed\n",
    "\n",
    "Does this make sense? Try using `.reshape()` instead of `.view()` and it should work!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbd4034",
   "metadata": {},
   "source": [
    "### Final MultiHeaded Attention Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d22b4",
   "metadata": {
    "time_run": "2025-12-01T07:13:26.541242+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class MultiHeadedAttention(torch.nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % h == 0  # d_model must be divisible by h\n",
    "        \n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.attn=None\n",
    "        \n",
    "        # Create 4 linear layers (Q, K, V projections + final output)\n",
    "        # Hint: you can use a list or create them individually\n",
    "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(d_model, d_model) for x in range(4)])\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        # Step 1: Project query, key, value using the first 3 linear layers\n",
    "        Q = self.linear_layers[0](query)\n",
    "        K = self.linear_layers[1](key)\n",
    "        V = self.linear_layers[2](value)\n",
    "        # Step 2: Reshape to split into h heads\n",
    "        batch_size = Q.size(0)\n",
    "        Q = Q.reshape(batch_size, -1, self.h, self.d_k).transpose(1,2)\n",
    "        K = K.reshape(batch_size, -1, self.h, self.d_k).transpose(1,2)\n",
    "        V = V.reshape(batch_size, -1, self.h, self.d_k).transpose(1,2)\n",
    "        # Step 3: Apply attention\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "        x = attention(Q,K,V, self.dropout, mask)\n",
    "        # Step 4: Concatenate heads back together\n",
    "        x = x.transpose(1,2).reshape(batch_size,-1, self.h * self.d_k)\n",
    "        # Step 5: Apply final linear projection\n",
    "        output = self.linear_layers[3](x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2572f3",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this better? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Now let's test it again:\n",
    "\n",
    "```python\n",
    "# Test with realistic dimensions\n",
    "mha = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "x = torch.randn(2, 10, 512)  # batch=2, seq_len=10, d_model=512\n",
    "\n",
    "output = mha.forward(x, x, x, mask=None)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))\n",
    "```\n",
    "\n",
    "Run this and see if it works now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb3f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with realistic dimensions\n",
    "mha = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "x = torch.randn(2, 10, 512)  # batch=2, seq_len=10, d_model=512\n",
    "\n",
    "output = mha.forward(x, x, x, mask=None)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084880b4",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Awesome. Convert this into unit test. Assume I'm using NB dev. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Here's your Multi-Head Attention as a unit test for nbdev:\n",
    "\n",
    "```python\n",
    "#| export\n",
    "class MultiHeadedAttention(torch.nn.Module):\n",
    "    \"Multi-Head Attention mechanism\"\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % h == 0  # d_model must be divisible by h\n",
    "        \n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.attn = None\n",
    "        \n",
    "        # Create 4 linear layers (Q, K, V projections + final output)\n",
    "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(d_model, d_model) for _ in range(4)])\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        # Step 1: Project query, key, value using the first 3 linear layers\n",
    "        Q = self.linear_layers[0](query)\n",
    "        K = self.linear_layers[1](key)\n",
    "        V = self.linear_layers[2](value)\n",
    "        # Step 2: Reshape to split into h heads\n",
    "        batch_size = Q.size(0)\n",
    "        seq_len = Q.size(1)\n",
    "        Q = Q.reshape(batch_size, seq_len, self.h, self.d_k).transpose(1,2)\n",
    "        K = K.reshape(batch_size, seq_len, self.h, self.d_k).transpose(1,2)\n",
    "        V = V.reshape(batch_size, seq_len, self.h, self.d_k).transpose(1,2)\n",
    "        # Step 3: Apply attention\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "        x = attention(Q, K, V, self.dropout, mask)\n",
    "        # Step 4: Concatenate heads back together\n",
    "        x = x.transpose(1,2).reshape(batch_size, seq_len, -1)\n",
    "        # Step 5: Apply final linear projection\n",
    "        output = self.linear_layers[3](x)\n",
    "        return output\n",
    "```\n",
    "\n",
    "```python\n",
    "#| test\n",
    "def test_multihead_attention():\n",
    "    \"Test Multi-Head Attention with realistic dimensions\"\n",
    "    mha = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "    x = torch.randn(2, 10, 512)  # batch=2, seq_len=10, d_model=512\n",
    "    \n",
    "    output = mha.forward(x, x, x, mask=None)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 10, 512])\n",
    "```\n",
    "\n",
    "Great work! You've successfully implemented Multi-Head Attention from scratch! \n",
    "\n",
    "What would you like to tackle next? Position-wise Feed-Forward Networks, or something else from the architecture?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba0fce1",
   "metadata": {},
   "source": [
    "#### Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4057bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| test\n",
    "def test_multihead_attention():\n",
    "    \"Test Multi-Head Attention with realistic dimensions\"\n",
    "    mha = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "    x = torch.randn(2, 10, 512)  # batch=2, seq_len=10, d_model=512\n",
    "    \n",
    "    output = mha.forward(x, x, x, mask=None)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 10, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e57b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_multihead_attention()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afb0cdb",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Great, I've exported using NB Dev, now let's move on. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Awesome!  Your Multi-Head Attention is working perfectly!\n",
    "\n",
    "You've now implemented two major components:\n",
    "1.  Scaled Dot-Product Attention\n",
    "2.  Multi-Head Attention\n",
    "\n",
    "**What's next?**\n",
    "\n",
    "Looking at the Transformer architecture, the main components left are:\n",
    "\n",
    "1. **Position-wise Feed-Forward Network** - a simple 2-layer MLP applied to each position\n",
    "2. **Positional Encoding** - adds position information to embeddings\n",
    "3. **Layer Normalization & Residual Connections** - for stable training\n",
    "4. **Encoder Layer** - combines attention + feed-forward\n",
    "5. **Decoder Layer** - similar but with masked attention + cross-attention\n",
    "6. **Full Encoder/Decoder stacks**\n",
    "\n",
    "Which would you like to tackle next? I'd suggest the **Feed-Forward Network** since it's simpler and will give you a quick win!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd8c55",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I just have one question. So, all these linear layers we are using During multi-headed attention, why aren't there any non-linearities like ReLU at the end of these linear layers? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent question! This is a really important design choice.\n",
    "\n",
    "**Why no non-linearity in the projections?**\n",
    "\n",
    "The Q, K, V projections are meant to be **linear transformations** of the input into different subspaces. Adding non-linearities would change the nature of the dot-product attention mechanism.\n",
    "\n",
    "Think about it: attention computes similarity via dot products (QK^T). If you applied ReLU before this, you'd be computing similarity between \"rectified\" representations, which doesn't have the same mathematical properties.\n",
    "\n",
    "**Where DO we use non-linearities?**\n",
    "\n",
    "The non-linearity (ReLU) comes in the **Feed-Forward Network** that follows the attention layer! That's where the model gets its non-linear transformation capacity.\n",
    "\n",
    "**The pattern in each layer:**\n",
    "1. Multi-Head Attention (linear projections only)\n",
    "2. Add & Norm (residual connection)\n",
    "3. **Feed-Forward Network (has ReLU!)**  non-linearity here\n",
    "4. Add & Norm\n",
    "\n",
    "So the model does have non-linearities, just not inside the attention projections themselves.\n",
    "\n",
    "Does this distinction make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64652c88",
   "metadata": {},
   "source": [
    "## PositionwiseFeedForward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a237b160",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Yes, this makes sense. Let's move on to the next topic. Make sure we're sticking to the code which is given in the beginning. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Let's move on to the **Position-wise Feed-Forward Network**.\n",
    "\n",
    "Looking at the paper (Section 3.3), this is a simple component:\n",
    "\n",
    "**FFN(x) = max(0, xW + b)W + b**\n",
    "\n",
    "It's just:\n",
    "1. A linear layer that expands dimensions (d_model  d_ff)\n",
    "2. ReLU activation\n",
    "3. Another linear layer that projects back (d_ff  d_model)\n",
    "\n",
    "Typically d_ff = 2048 when d_model = 512 (4x expansion).\n",
    "\n",
    "Try implementing the class:\n",
    "\n",
    "```python\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # What do you need here?\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # What's the sequence of operations?\n",
    "```\n",
    "\n",
    "What layers do you need in `__init__`? Give it a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67d4ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(torch.nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # What do you need here?\n",
    "        self.linear_layer = torch.nn.Linear(d_model, d_ff)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.output_layer = torch.nn.Linear(d_ff, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # What's the sequence of operations?\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6313d0d7",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this correct? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent! Your `__init__` is perfect! \n",
    "\n",
    "You've got all the pieces:\n",
    "-  First linear layer (d_model  d_ff)\n",
    "-  ReLU activation\n",
    "-  Dropout\n",
    "-  Second linear layer (d_ff  d_model)\n",
    "\n",
    "Now for the `forward` method - what's the sequence of operations? \n",
    "\n",
    "Apply them in order: linear  relu  dropout  linear\n",
    "\n",
    "Give it a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e50b70a",
   "metadata": {},
   "source": [
    "### Final PositionwiseFeedForward Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea74ae09",
   "metadata": {
    "time_run": "2025-12-01T07:13:33.821852+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class PositionwiseFeedForward(torch.nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # What do you need here?\n",
    "        self.linear_layer = torch.nn.Linear(d_model, d_ff)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.output_layer = torch.nn.Linear(d_ff, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # What's the sequence of operations?\n",
    "        x = self.linear_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af590711",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Should be fine, right? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your Feed-Forward Network is complete and correct! \n",
    "\n",
    "The sequence is exactly right:\n",
    "-  Expand with first linear layer\n",
    "-  Apply ReLU non-linearity\n",
    "-  Apply dropout for regularization\n",
    "-  Project back with second linear layer\n",
    "\n",
    "Let's test it:\n",
    "\n",
    "```python\n",
    "ffn = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "x = torch.randn(2, 10, 512)  # batch=2, seq_len=10, d_model=512\n",
    "\n",
    "output = ffn(x)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))\n",
    "```\n",
    "\n",
    "Run this to verify it works, then we can move on to the next component!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "x = torch.randn(2, 10, 512)  # batch=2, seq_len=10, d_model=512\n",
    "\n",
    "output = ffn(x)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddff670",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Assume we are using NB dev. Convert this into a unit test. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Here's your Position-wise Feed-Forward Network as a unit test for nbdev:\n",
    "\n",
    "```python\n",
    "#| export\n",
    "class PositionwiseFeedForward(torch.nn.Module):\n",
    "    \"Position-wise Feed-Forward Network\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear_layer = torch.nn.Linear(d_model, d_ff)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.output_layer = torch.nn.Linear(d_ff, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "```\n",
    "\n",
    "```python\n",
    "#| test\n",
    "def test_positionwise_feedforward():\n",
    "    \"Test Position-wise Feed-Forward Network\"\n",
    "    ffn = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "    x = torch.randn(2, 10, 512)  # batch=2, seq_len=10, d_model=512\n",
    "    \n",
    "    output = ffn(x)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 10, 512])\n",
    "```\n",
    "\n",
    "Ready to move on to the next component?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fa6bcb",
   "metadata": {},
   "source": [
    "#### Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d162fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| test\n",
    "def test_positionwise_feedforward():\n",
    "    \"Test Position-wise Feed-Forward Network\"\n",
    "    ffn = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "    x = torch.randn(2, 10, 512)  # batch=2, seq_len=10, d_model=512\n",
    "    \n",
    "    output = ffn(x)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 10, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d495e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positionwise_feedforward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9039448a",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Why is it called position-wise feedforward? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question!\n",
    "\n",
    "**\"Position-wise\"** means the same feed-forward network is applied to **each position independently**.\n",
    "\n",
    "Think of it this way:\n",
    "- You have a sequence: `[word1, word2, word3, ...]`\n",
    "- Each word has a vector of size d_model=512\n",
    "- The FFN processes each word's vector **separately** - word1's vector doesn't interact with word2's vector\n",
    "\n",
    "It's like applying the same 2-layer neural network to each position in the sequence independently. The same weights are shared across all positions, but each position is processed on its own.\n",
    "\n",
    "**Contrast with attention:** Attention mixes information **across** positions (word1 looks at word2, word3, etc.). The FFN does **not** mix across positions - it just transforms each position's representation individually.\n",
    "\n",
    "Does this clarify why it's called \"position-wise\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05017768",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Okay, that makes it clear. Let's move on now. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! You've now completed:\n",
    "1.  Scaled Dot-Product Attention\n",
    "2.  Multi-Head Attention\n",
    "3.  Position-wise Feed-Forward Network\n",
    "\n",
    "**What's next?**\n",
    "\n",
    "The remaining key components are:\n",
    "\n",
    "1. **Embeddings** - convert tokens to vectors\n",
    "2. **Positional Encoding** - add position information (since attention has no inherent notion of order)\n",
    "3. **Layer Normalization** - for stable training\n",
    "4. **Residual Connections** - skip connections around sub-layers\n",
    "5. **Encoder Layer** - combines attention + FFN with residuals and norms\n",
    "6. **Decoder Layer** - similar but with masked self-attention + cross-attention\n",
    "\n",
    "I'd suggest **Positional Encoding** next - it's a unique and interesting part of the Transformer. It explains how the model knows the order of words.\n",
    "\n",
    "Want to tackle that? Or would you prefer a different component?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa7b62a",
   "metadata": {},
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f018005f",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Okay, I'm down for positional encoding. Let's do it. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Let's tackle **Positional Encoding**.\n",
    "\n",
    "**Why do we need it?**\n",
    "\n",
    "Attention has no inherent sense of order - it treats the sequence like a set. \"I love pizza\" and \"pizza love I\" would look the same! Positional encoding adds information about where each word is in the sequence.\n",
    "\n",
    "**How does it work?**\n",
    "\n",
    "The paper uses sine and cosine functions of different frequencies:\n",
    "\n",
    "- PE(pos, 2i) = sin(pos / 10000^(2i/d_model))\n",
    "- PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
    "\n",
    "Where:\n",
    "- `pos` = position in sequence (0, 1, 2, ...)\n",
    "- `i` = dimension index (0, 1, 2, ..., d_model/2)\n",
    "\n",
    "**The class structure:**\n",
    "\n",
    "```python\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super().__init__()\n",
    "        # Create the positional encoding matrix\n",
    "        # Store it as a buffer (not a parameter)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Add positional encoding to input x\n",
    "```\n",
    "\n",
    "Before coding, do you understand why they use sin/cos functions? Want me to explain the intuition?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c2538d",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I think they use sine and cos because sine and cos have different peaks. For example, sin is 1 while cos is 0. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "That's part of it! But there's more to why sin/cos are special here.\n",
    "\n",
    "**Key properties they wanted:**\n",
    "\n",
    "1. **Unique encoding for each position** - different positions get different patterns\n",
    "2. **Relative position information** - the model can learn \"word A is 3 positions before word B\"\n",
    "3. **Extrapolation** - can handle sequences longer than seen in training\n",
    "\n",
    "**Why sin/cos specifically?**\n",
    "\n",
    "For any fixed offset k, PE(pos+k) can be represented as a **linear function** of PE(pos). This is because of the trigonometric identity:\n",
    "\n",
    "sin(a + b) = sin(a)cos(b) + cos(a)sin(b)\n",
    "\n",
    "This means the model can easily learn to attend by relative positions!\n",
    "\n",
    "**Different frequencies:** Each dimension uses a different frequency (from 2 to 100002), so different dimensions capture patterns at different scales - some for nearby words, some for distant words.\n",
    "\n",
    "Does this deeper intuition make sense? Ready to start implementing it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657d42bb",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "No, I'm still not getting it. What I'm seeing from the formula is that for even dim we're using sine, and for odd dim we're using cosine. Secondly, what I am getting is the frequency changes as the dimension index changes. It goes from lower frequency to higher frequency. Is what I'm saying making sense? Am I getting the correct intuition? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes! You're getting it exactly right! \n",
    "\n",
    "**What you understand correctly:**\n",
    "\n",
    "1.  **Even dimensions use sine, odd dimensions use cosine** - this gives you pairs of (sin, cos) at the same frequency\n",
    "2.  **Frequency changes with dimension** - but actually it goes from **higher to lower** frequency as i increases (because we divide by larger numbers: 10000^(2i/d_model) gets bigger)\n",
    "\n",
    "**Why does frequency matter?**\n",
    "\n",
    "- **High frequency** (early dimensions): Changes quickly, good for capturing nearby positions (position 1 vs 2 vs 3)\n",
    "- **Low frequency** (later dimensions): Changes slowly, good for capturing distant positions (position 10 vs 50 vs 100)\n",
    "\n",
    "So different dimensions encode position information at different scales!\n",
    "\n",
    "**The sin/cos pairing:** Using both at the same frequency helps the model learn relative positions through those trig identities I mentioned.\n",
    "\n",
    "Does this click now? Ready to implement it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a652b6",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "How are early dimensions high frequency and later low frequency? Give a numerical example. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question! Let me show you with numbers.\n",
    "\n",
    "**The formula for frequency:**\n",
    "```\n",
    "div_term = 10000^(2i/d_model)\n",
    "```\n",
    "\n",
    "Let's say d_model = 512:\n",
    "\n",
    "**Early dimensions (i=0):**\n",
    "```\n",
    "10000^(2*0/512) = 10000^0 = 1\n",
    "frequency = 1/1 = 1  (HIGH frequency - changes fast!)\n",
    "```\n",
    "\n",
    "**Middle dimensions (i=64):**\n",
    "```\n",
    "10000^(2*64/512) = 10000^0.25  10\n",
    "frequency = 1/10 = 0.1  (medium frequency)\n",
    "```\n",
    "\n",
    "**Later dimensions (i=255):**\n",
    "```\n",
    "10000^(2*255/512) = 10000^0.996  6310\n",
    "frequency = 1/6310  0.00016  (LOW frequency - changes slowly!)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- Dimension 0: sin(pos/1) changes every position\n",
    "- Dimension 128: sin(pos/10) changes every ~10 positions  \n",
    "- Dimension 510: sin(pos/6310) barely changes across the sequence\n",
    "\n",
    "Does this numerical example clarify how frequency decreases as i increases?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7c43c6",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Okay, before jumping into the implementation, let's do some visualisation. Give me some visualisation code without thinking. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create positional encoding for visualization\n",
    "d_model = 64\n",
    "max_len = 100\n",
    "\n",
    "# Compute positional encodings\n",
    "pe = torch.zeros(max_len, d_model)\n",
    "position = torch.arange(0, max_len).unsqueeze(1)\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "\n",
    "pe[:, 0::2] = torch.sin(position * div_term)\n",
    "pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.imshow(pe.T, cmap='RdBu', aspect='auto')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Dimension')\n",
    "plt.colorbar()\n",
    "plt.title('Positional Encoding Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Plot specific dimensions\n",
    "plt.figure(figsize=(15, 4))\n",
    "for dim in [0, 2, 10, 30]:\n",
    "    plt.plot(pe[:, dim], label=f'dim {dim}')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Encoding Value')\n",
    "plt.legend()\n",
    "plt.title('Positional Encoding for Different Dimensions')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Run this to see how the encodings look!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915057f8",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Ok, let's implement now and much clearer. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Let's implement Positional Encoding.\n",
    "\n",
    "**Step 1: Create the positional encoding matrix in `__init__`**\n",
    "\n",
    "You need to:\n",
    "1. Create a matrix `pe` of shape (max_len, d_model) filled with zeros\n",
    "2. Create a `position` vector: [0, 1, 2, ..., max_len-1]\n",
    "3. Calculate `div_term` using the formula\n",
    "4. Fill in the even dimensions with sine\n",
    "5. Fill in the odd dimensions with cosine\n",
    "\n",
    "Try starting with the first 3 steps:\n",
    "\n",
    "```python\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Create pe matrix\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        \n",
    "        # Create position vector - try this yourself!\n",
    "        # Calculate div_term - try this yourself!\n",
    "```\n",
    "\n",
    "Can you create the `position` vector and calculate `div_term`? Remember the formulas we discussed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5fb146",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Create pe matrix\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "\n",
    "        half_range = torch.range(d_model//2)\n",
    "        \n",
    "        # Create position vector - try this yourself!\n",
    "        cosine = torch.cos(pos/ (1000**(2*half_range/d_model)) )\n",
    "        sin = torch.sin(pos/ (1000**(2*half_range/d_model)) )\n",
    "        pe[::2] = cosine\n",
    "        pe[1::2] = sin\n",
    "        # Calculate div_term - try this yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decbee74",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Am I doing well so far? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "You're on the right track with the concept, but there are a few issues to fix:\n",
    "\n",
    "1. **`pos` is not defined** - you need to create a position vector first: `torch.arange(0, max_len)`\n",
    "2. **`half_range`** - use `torch.arange(0, d_model, 2)` to get even indices\n",
    "3. **The indexing `pe[::2]`** - this won't work correctly. You need to fill columns (dimensions), not rows. Use `pe[:, 0::2]` for even dims and `pe[:, 1::2]` for odd dims\n",
    "4. **Broadcasting** - `pos` needs to be reshaped to broadcast correctly with `div_term`\n",
    "\n",
    "Try fixing step 1 first - create the position vector:\n",
    "```python\n",
    "position = torch.arange(0, max_len).unsqueeze(1)  # shape: (max_len, 1)\n",
    "```\n",
    "\n",
    "Does this make sense? Want to try the next step?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad1944b",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "What's the difference between A-range and range? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good question!\n",
    "\n",
    "**`torch.range()` (deprecated):**\n",
    "- Older function, not recommended\n",
    "- Includes the end value\n",
    "- `torch.range(0, 5)` gives `[0, 1, 2, 3, 4, 5]` (6 elements!)\n",
    "\n",
    "**`torch.arange()` (use this!):**\n",
    "- Modern version, works like Python's `range()`\n",
    "- Excludes the end value\n",
    "- `torch.arange(0, 5)` gives `[0, 1, 2, 3, 4]` (5 elements)\n",
    "\n",
    "So always use `torch.arange()` - it's more predictable and matches Python conventions!\n",
    "\n",
    "Ready to continue with the implementation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d9c13a",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Why are we unsqueezing? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question!\n",
    "\n",
    "**Why unsqueeze?**\n",
    "\n",
    "We need the shapes to broadcast correctly for the calculation.\n",
    "\n",
    "**The shapes:**\n",
    "- `position`: We want shape `(max_len, 1)` - each row is a position\n",
    "- `div_term`: Will have shape `(d_model/2,)` - different frequencies\n",
    "\n",
    "**When we multiply them:**\n",
    "```python\n",
    "position * div_term\n",
    "```\n",
    "\n",
    "Broadcasting gives us shape `(max_len, d_model/2)` - every position combined with every frequency!\n",
    "\n",
    "**Without unsqueeze:**\n",
    "- `position` would be shape `(max_len,)` \n",
    "- Multiplication wouldn't broadcast the way we want\n",
    "\n",
    "**Visual example:**\n",
    "```\n",
    "position (100, 1):        div_term (256,):\n",
    "[[0],                     [1.0, 0.5, 0.25, ...]\n",
    " [1],\n",
    " [2],                     Result (100, 256):\n",
    " ...]                     Each pos  each frequency\n",
    "```\n",
    "\n",
    "Does this clarify why we need that extra dimension?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af36cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Create pe matrix\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "\n",
    "        half_range = torch.range(d_model//2)\n",
    "        \n",
    "        # Create position vector - try this yourself!\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        # Calculate div_term - try this yourself!\n",
    "        div_term = 10000**(half_range/d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c97c0c",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Are we doing better? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Getting closer! A few more fixes needed:\n",
    "\n",
    "1. **`half_range`**: Should be `torch.arange(0, d_model, 2)` not `torch.range(d_model//2)`. You want the even indices: [0, 2, 4, 6, ...]\n",
    "\n",
    "2. **`div_term` formula**: You have it backwards! It should be dividing, not multiplying. Remember: we want 10000^(2i/d_model), which means:\n",
    "   ```python\n",
    "   div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "   ```\n",
    "   This computes the exponential in a numerically stable way.\n",
    "\n",
    "Try fixing these two things. Does the `div_term` formula make sense, or do you want me to explain why we use `exp` and `log`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Create pe matrix\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "\n",
    "        even_indices = torch.arange(0, d_model, 2)\n",
    "        \n",
    "        # Create position vector - try this yourself!\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        # Calculate div_term - try this yourself!\n",
    "        div_term = torch.exp(-even_indices*(torch.log(10000))/d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31769d4d",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "All good now? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your position vector and div_term are now correct! \n",
    "\n",
    "Now you need to fill in the `pe` matrix with sine and cosine values:\n",
    "\n",
    "```python\n",
    "pe[:, 0::2] = torch.sin(position * div_term)\n",
    "pe[:, 1::2] = torch.cos(position * div_term)\n",
    "```\n",
    "\n",
    "This fills:\n",
    "- Even columns (0, 2, 4, ...) with sine\n",
    "- Odd columns (1, 3, 5, ...) with cosine\n",
    "\n",
    "Then you need to:\n",
    "1. Add a batch dimension: `pe = pe.unsqueeze(0)` \n",
    "2. Register it as a buffer (not a trainable parameter): `self.register_buffer('pe', pe)`\n",
    "\n",
    "Can you add these steps to complete the `__init__` method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c8a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Create pe matrix\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "\n",
    "        even_indices = torch.arange(0, d_model, 2)\n",
    "        \n",
    "        # Create position vector - try this yourself!\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        # Calculate div_term - try this yourself!\n",
    "        div_term = torch.exp(-even_indices*(torch.log(10000))/d_model)\n",
    "\n",
    "        pe[:, ::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1547f2c",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Awesome, that's great. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Almost there! But you can't `return` from `__init__` - it's a constructor method.\n",
    "\n",
    "Instead, you need to:\n",
    "1. Add a batch dimension to `pe`\n",
    "2. Register it as a buffer so it's saved with the model but not trained\n",
    "\n",
    "Add these two lines at the end of `__init__`:\n",
    "\n",
    "```python\n",
    "pe = pe.unsqueeze(0)  # Add batch dimension: (1, max_len, d_model)\n",
    "self.register_buffer('pe', pe)  # Save as buffer, not parameter\n",
    "```\n",
    "\n",
    "Then you'll need to implement the `forward` method. Can you add these lines first?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8704dfa8",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Let me guess; we are unsqueezing to accommodate batch size, aren't we? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Exactly right! \n",
    "\n",
    "The `pe` matrix is currently shape `(max_len, d_model)`, but your input will have shape `(batch_size, seq_len, d_model)`.\n",
    "\n",
    "By unsqueezing to `(1, max_len, d_model)`, the batch dimension of size 1 will **broadcast** across whatever batch_size you have in your input.\n",
    "\n",
    "You're really getting the hang of these dimension manipulations!\n",
    "\n",
    "Now add those two lines to your code, then we can implement the `forward` method. Ready?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9979c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Create pe matrix\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "\n",
    "        even_indices = torch.arange(0, d_model, 2)\n",
    "        \n",
    "        # Create position vector - try this yourself!\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        # Calculate div_term - try this yourself!\n",
    "        div_term = torch.exp(-even_indices*(torch.log(10000))/d_model)\n",
    "\n",
    "        pe[:, ::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd85b89e",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Also, we are saving PE as a buffer, as that does not change at all. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Exactly! \n",
    "\n",
    "**Why use `register_buffer` instead of a parameter?**\n",
    "\n",
    "- **Parameters** (created with `nn.Parameter`): Are trained/updated during backpropagation\n",
    "- **Buffers** (created with `register_buffer`): Are part of the model state but NOT trained\n",
    "\n",
    "Since positional encodings are **fixed** (computed once using sin/cos, never updated), they should be a buffer, not a parameter!\n",
    "\n",
    "This also ensures `pe` gets moved to GPU when you call `model.to('cuda')` and gets saved/loaded with the model.\n",
    "\n",
    "Now let's implement the `forward` method. What should it do?\n",
    "1. Take input `x` of shape `(batch, seq_len, d_model)`\n",
    "2. Add the positional encoding for the first `seq_len` positions\n",
    "3. Apply dropout\n",
    "4. Return the result\n",
    "\n",
    "Can you try writing the `forward` method?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a225f35b",
   "metadata": {},
   "source": [
    "### Final PositionalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cd95da",
   "metadata": {
    "time_run": "2025-12-01T07:13:42.074214+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Create pe matrix\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "\n",
    "        even_indices = torch.arange(0, d_model, 2)\n",
    "        \n",
    "        # Create position vector - try this yourself!\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        # Calculate div_term - try this yourself!\n",
    "        div_term = torch.exp(-even_indices*(torch.log(torch.tensor(10000)))/d_model)\n",
    "\n",
    "        pe[:, ::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        x = x + self.pe[:,:seq_len,:].requires_grad_(False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad66e281",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this good? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your Positional Encoding implementation is complete and correct! \n",
    "\n",
    "You've got:\n",
    "-  Extract seq_len from input\n",
    "-  Slice the positional encoding to match: `self.pe[:, :seq_len, :]`\n",
    "-  Set `requires_grad_(False)` to ensure it's not trained\n",
    "-  Add it to the input\n",
    "-  Apply dropout\n",
    "\n",
    "Let's test it:\n",
    "\n",
    "```python\n",
    "pe = PositionalEncoding(d_model=512, dropout=0.1, max_len=100)\n",
    "x = torch.randn(2, 10, 512)  # batch=2, seq_len=10, d_model=512\n",
    "\n",
    "output = pe(x)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))\n",
    "```\n",
    "\n",
    "Run this to verify it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf52787",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PositionalEncoding(d_model=512, dropout=0.1, max_len=100)\n",
    "x = torch.randn(2, 10, 512)  # batch=2, seq_len=10, d_model=512\n",
    "\n",
    "output = pe(x)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a571a8",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Assume we are using NB Dev. Convert this into a unit test. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Here's your Positional Encoding as a unit test for nbdev:\n",
    "\n",
    "```python\n",
    "#| export\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    \"Positional Encoding using sine and cosine functions\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Create pe matrix\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        even_indices = torch.arange(0, d_model, 2)\n",
    "        \n",
    "        # Create position vector\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        # Calculate div_term\n",
    "        div_term = torch.exp(-even_indices*(torch.log(torch.tensor(10000.0))/d_model))\n",
    "        \n",
    "        pe[:, ::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        x = x + self.pe[:, :seq_len, :].requires_grad_(False)\n",
    "        return self.dropout(x)\n",
    "```\n",
    "\n",
    "```python\n",
    "#| test\n",
    "def test_positional_encoding():\n",
    "    \"Test Positional Encoding\"\n",
    "    pe = PositionalEncoding(d_model=512, dropout=0.1, max_len=100)\n",
    "    x = torch.randn(2, 10, 512)  # batch=2, seq_len=10, d_model=512\n",
    "    \n",
    "    output = pe(x)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 10, 512])\n",
    "```\n",
    "\n",
    "Great progress! Ready to move on to the next component?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bcd937",
   "metadata": {},
   "source": [
    "#### Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc166074",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| test\n",
    "def test_positional_encoding():\n",
    "    \"Test Positional Encoding\"\n",
    "    pe = PositionalEncoding(d_model=512, dropout=0.1, max_len=100)\n",
    "    x = torch.randn(2, 10, 512)  # batch=2, seq_len=10, d_model=512\n",
    "    \n",
    "    output = pe(x)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 10, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f25aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positional_encoding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4357f2",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "That's amazing, let's go on to the next block. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent work! You've now completed the core building blocks:\n",
    "1.  Scaled Dot-Product Attention\n",
    "2.  Multi-Head Attention\n",
    "3.  Position-wise Feed-Forward Network\n",
    "4.  Positional Encoding\n",
    "\n",
    "**What's next?**\n",
    "\n",
    "Now we need to build the **Encoder Layer** - this combines the components you've built into a complete encoder block.\n",
    "\n",
    "An Encoder Layer contains:\n",
    "1. Multi-Head Self-Attention\n",
    "2. Add & Norm (residual connection + layer normalization)\n",
    "3. Feed-Forward Network\n",
    "4. Add & Norm again\n",
    "\n",
    "Before we code, do you understand what **residual connections** and **layer normalization** are? Should I explain those concepts first, or do you want to dive into the implementation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588333f8",
   "metadata": {},
   "source": [
    "## Encoder Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af28953",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Yeah, you can test me on these concepts. I somewhat know them. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Let's test your understanding:\n",
    "\n",
    "**Question 1: Residual Connections**\n",
    "\n",
    "What is a residual connection, and why do we use them in deep networks? Can you write the simple equation for a residual connection?\n",
    "\n",
    "**Question 2: Layer Normalization**\n",
    "\n",
    "What does layer normalization do? How is it different from batch normalization?\n",
    "\n",
    "Give it a shot - explain in your own words!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b896c143",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "q1 Basically a residual connection is you after you do an operation on an input, you also bring the input forward bypassing the operation. so, output = x + sublayer(x)\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent! That's exactly right! \n",
    "\n",
    "**Residual connection:** `output = x + sublayer(x)`\n",
    "\n",
    "You've got the key insight - the input \"skips\" around the operation and gets added back. This helps with:\n",
    "- Gradient flow during backpropagation (prevents vanishing gradients)\n",
    "- Allows the network to learn identity mappings easily\n",
    "- Makes training very deep networks possible\n",
    "\n",
    "**Now for Question 2:**\n",
    "\n",
    "What does layer normalization do, and how does it work? (Hint: think about computing mean and standard deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d980b8",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "So basically, across all the dimensions, we take the mean and standard deviation, and we normalise the outputs. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Exactly right! \n",
    "\n",
    "**Layer Normalization:**\n",
    "- Computes mean and std **across all dimensions (features)** for each example\n",
    "- Normalizes: `(x - mean) / std`\n",
    "- Then applies learned scale () and shift () parameters\n",
    "\n",
    "**Key difference from Batch Normalization:**\n",
    "- **Batch Norm**: normalizes across the batch dimension (all examples)\n",
    "- **Layer Norm**: normalizes across the feature dimension (for each example independently)\n",
    "\n",
    "Layer Norm works better for sequences because sequence lengths can vary, making batch statistics unreliable.\n",
    "\n",
    "Now you understand both concepts! Ready to implement the **Encoder Layer** that uses these? It will combine:\n",
    "- Multi-Head Attention\n",
    "- Residual + Layer Norm\n",
    "- Feed-Forward\n",
    "- Residual + Layer Norm again\n",
    "\n",
    "Want to start coding?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3111443",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "lets code!!!\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Awesome! Let's build the **Encoder Layer**!\n",
    "\n",
    "First, let's think about what we need:\n",
    "\n",
    "1. **In `__init__`**: Store the components\n",
    "   - Multi-Head Attention module\n",
    "   - Feed-Forward module\n",
    "   - Layer Norm modules (how many do we need?)\n",
    "   - Store the size (d_model)\n",
    "\n",
    "2. **In `forward`**: Apply the operations with residual connections\n",
    "\n",
    "Before coding, a question: How many Layer Norm modules do we need? (Hint: think about how many residual connections we have)\n",
    "\n",
    "Once you answer, try writing the `__init__` method skeleton:\n",
    "\n",
    "```python\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super().__init__()\n",
    "        # What do we need to store?\n",
    "```\n",
    "\n",
    "Give it a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d8bf11",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "For layer normalisation, you will need one layer norm after the position-wise feed forward and another layer norm after the multi-head attention. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Exactly right! You need **2 Layer Norm modules** - one after each sub-layer (attention and feed-forward).\n",
    "\n",
    "Now try implementing the `__init__` method. You need to store:\n",
    "- `self.size` (d_model)\n",
    "- `self.self_attn` (the multi-head attention module passed in)\n",
    "- `self.feed_forward` (the FFN module passed in)\n",
    "- 2 Layer Norm modules (use `nn.LayerNorm(size)`)\n",
    "- Dropout\n",
    "\n",
    "Give it a try! What does your `__init__` look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(torch.nn.Module):\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super().__init__()\n",
    "        # What do we need to store?\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.layer_norms = torch.nn.ModuleList([torch.nn.LayerNorm(size) for x in range(2)])\n",
    "        self.dropout = dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f344255e",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this a cognizant with the original code? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Almost! Looking at the original code pattern, there's one difference:\n",
    "\n",
    "Instead of storing `dropout` as a value, you should create a `Dropout` layer:\n",
    "\n",
    "```python\n",
    "self.dropout = nn.Dropout(dropout)\n",
    "```\n",
    "\n",
    "But actually, looking at the original code more carefully, they use a **`SublayerConnection`** module that handles both the residual connection AND layer norm together. This is a cleaner pattern.\n",
    "\n",
    "Do you want to:\n",
    "1. **Option A**: Implement `SublayerConnection` class first (handles residual + norm), then use it in EncoderLayer\n",
    "2. **Option B**: Continue with your current approach (manual residual connections in forward)\n",
    "\n",
    "The original code uses Option A. Which would you prefer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78191b6f",
   "metadata": {},
   "source": [
    "### Sublayer Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c73296",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Where is this mentioned in the original code? Tell me. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Looking at the original code you provided at the beginning (the Annotated Transformer), you can find the `SublayerConnection` class. Let me point you to it:\n",
    "\n",
    "It's defined in the section about **Encoder and Decoder Stacks**. Here's where it appears:\n",
    "\n",
    "```python\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "```\n",
    "\n",
    "And then `EncoderLayer` uses it:\n",
    "\n",
    "```python\n",
    "self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "```\n",
    "\n",
    "So they create 2 `SublayerConnection` modules. Do you want to implement `SublayerConnection` first, or stick with your current approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4886c556",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "What should we do, man? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good question! Here's my recommendation:\n",
    "\n",
    "**Follow the original code structure** - implement `SublayerConnection` first. Here's why:\n",
    "\n",
    "1. It's cleaner and more modular\n",
    "2. You'll reuse it in the Decoder Layer too\n",
    "3. It matches the paper's approach (norm  sublayer  dropout  residual)\n",
    "\n",
    "The `SublayerConnection` is simple - it just wraps any sublayer with:\n",
    "- Layer normalization (applied first)\n",
    "- The sublayer operation\n",
    "- Dropout\n",
    "- Residual connection\n",
    "\n",
    "Want to implement `SublayerConnection` first? It's a small class - should only take a few minutes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fd94f3",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "ok\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Let's implement `SublayerConnection`.\n",
    "\n",
    "Looking at the original code, it needs:\n",
    "\n",
    "**In `__init__`:**\n",
    "- Store a LayerNorm module\n",
    "- Store a Dropout module\n",
    "\n",
    "**In `forward(self, x, sublayer)`:**\n",
    "- Apply layer norm to x\n",
    "- Pass normalized x through the sublayer function\n",
    "- Apply dropout\n",
    "- Add the residual connection (original x)\n",
    "\n",
    "The pattern is: `x + dropout(sublayer(norm(x)))`\n",
    "\n",
    "Try implementing it:\n",
    "\n",
    "```python\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"A residual connection followed by a layer norm\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super().__init__()\n",
    "        # What do you need here?\n",
    "        \n",
    "    def forward(self, x, sublayer):\n",
    "        # What's the operation?\n",
    "```\n",
    "\n",
    "Give it a shot!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b78355",
   "metadata": {},
   "source": [
    "### Final SublayerConnection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2700b2b9",
   "metadata": {
    "time_run": "2025-12-01T07:13:52.483595+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class SublayerConnection(torch.nn.Module):\n",
    "    \"A residual connection followed by a layer norm\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super().__init__()\n",
    "        # What do you need here?\n",
    "        self.layer_norm = torch.nn.LayerNorm(size)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, sublayer):\n",
    "        # What's the operation?\n",
    "        y = self.layer_norm(x)\n",
    "        y = sublayer(y)\n",
    "        y = self.dropout(y)\n",
    "        return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa046579",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "is this good? always refer to original code\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `SublayerConnection` is correct and matches the original code! \n",
    "\n",
    "You've got:\n",
    "-  Layer norm applied first\n",
    "-  Sublayer operation\n",
    "-  Dropout\n",
    "-  Residual connection (x + y)\n",
    "\n",
    "Now let's go back to the `EncoderLayer` and use `SublayerConnection`. \n",
    "\n",
    "Update your `EncoderLayer.__init__` to use:\n",
    "\n",
    "```python\n",
    "self.sublayer = nn.ModuleList([SublayerConnection(size, dropout) for _ in range(2)])\n",
    "```\n",
    "\n",
    "Instead of the separate layer_norms. Can you update your `EncoderLayer` code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b35b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.sublayer = nn.ModuleList([SublayerConnection(size, dropout) for _ in range(2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1962ae02",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "like this?\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `EncoderLayer.__init__` is now correct! \n",
    "\n",
    "Now let's implement the `forward` method. Looking at the original code, you need to:\n",
    "\n",
    "1. Apply first sublayer connection with self-attention\n",
    "2. Apply second sublayer connection with feed-forward\n",
    "\n",
    "The tricky part: you need to pass a **lambda function** to sublayer because self-attention takes multiple arguments (query, key, value, mask).\n",
    "\n",
    "Try writing the `forward` method. Here's the signature:\n",
    "\n",
    "```python\n",
    "def forward(self, x, mask):\n",
    "    # Step 1: Apply self-attention with first sublayer connection\n",
    "    # Step 2: Apply feed-forward with second sublayer connection\n",
    "```\n",
    "\n",
    "Hint: Look at how the original code uses `lambda` to wrap the self_attn call.\n",
    "\n",
    "Give it a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03393cdb",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I don't want to look at the original code, give me a clue. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good! Let me give you clues without showing the code.\n",
    "\n",
    "**Clue 1:** The `sublayer` in `SublayerConnection.forward(x, sublayer)` expects a **function** that takes one argument (x) and returns output.\n",
    "\n",
    "**Clue 2:** But `self.self_attn` needs 4 arguments: query, key, value, mask. For self-attention, query=key=value=x.\n",
    "\n",
    "**Clue 3:** You need to wrap `self.self_attn` in a function that takes only x as input. Use a `lambda` to do this.\n",
    "\n",
    "**Clue 4:** For the feed-forward, it's simpler - it already takes just x as input.\n",
    "\n",
    "Try writing:\n",
    "```python\n",
    "def forward(self, x, mask):\n",
    "    x = self.sublayer[0](x, lambda x: ???)  # What goes here?\n",
    "    x = self.sublayer[1](x, ???)  # What goes here?\n",
    "    return x\n",
    "```\n",
    "\n",
    "What would you put in the `???` spots?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9f03b9",
   "metadata": {},
   "source": [
    "### Final EncoderLayer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bac5989",
   "metadata": {
    "time_run": "2025-12-01T07:13:57.901356+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class EncoderLayer(torch.nn.Module):\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super().__init__()\n",
    "        # What do we need to store?\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = torch.nn.ModuleList([SublayerConnection(size, dropout) for _ in range(2)])\n",
    "    def forward(self, x, mask):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.feed_forward(x))\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b532add6",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this correct? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent work! Your `EncoderLayer` is now correct! \n",
    "\n",
    "You've got:\n",
    "-  First sublayer: self-attention with `lambda x: self.self_attn(x, x, x, mask)` (query=key=value=x)\n",
    "-  Second sublayer: feed-forward with `lambda x: self.feed_forward(x)`\n",
    "-  Both wrapped in `SublayerConnection` for residual + norm\n",
    "\n",
    "Let's test it to make sure everything works:\n",
    "\n",
    "```python\n",
    "# Create the components\n",
    "attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "encoder_layer = EncoderLayer(size=512, self_attn=attn, feed_forward=ff, dropout=0.1)\n",
    "\n",
    "# Test\n",
    "x = torch.randn(2, 10, 512)\n",
    "mask = None\n",
    "output = encoder_layer(x, mask)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))\n",
    "```\n",
    "\n",
    "Run this and see if it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474420d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the components\n",
    "attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "encoder_layer = EncoderLayer(size=512, self_attn=attn, feed_forward=ff, dropout=0.1)\n",
    "\n",
    "# Test\n",
    "x = torch.randn(2, 10, 512)\n",
    "mask = None\n",
    "output = encoder_layer(x, mask)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c232ff",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Very cool, now assume that you are an NB dev and create a unit test out of this. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Here's your Encoder Layer as a unit test for nbdev:\n",
    "\n",
    "```python\n",
    "#| export\n",
    "class SublayerConnection(torch.nn.Module):\n",
    "    \"A residual connection followed by a layer norm\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super().__init__()\n",
    "        self.layer_norm = torch.nn.LayerNorm(size)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, sublayer):\n",
    "        y = self.layer_norm(x)\n",
    "        y = sublayer(y)\n",
    "        y = self.dropout(y)\n",
    "        return x + y\n",
    "```\n",
    "\n",
    "```python\n",
    "#| export\n",
    "class EncoderLayer(torch.nn.Module):\n",
    "    \"Encoder layer with self-attention and feed-forward\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = torch.nn.ModuleList([SublayerConnection(size, dropout) for _ in range(2)])\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        x = self.sublayer[1](x, self.feed_forward)\n",
    "        return x\n",
    "```\n",
    "\n",
    "```python\n",
    "#| test\n",
    "def test_encoder_layer():\n",
    "    \"Test Encoder Layer\"\n",
    "    attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "    ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "    encoder_layer = EncoderLayer(size=512, self_attn=attn, feed_forward=ff, dropout=0.1)\n",
    "    \n",
    "    x = torch.randn(2, 10, 512)\n",
    "    output = encoder_layer(x, mask=None)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 10, 512])\n",
    "```\n",
    "\n",
    "Great work! Ready for the next component?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67906a37",
   "metadata": {},
   "source": [
    "#### Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1b0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| test\n",
    "def test_encoder_layer():\n",
    "    \"Test Encoder Layer\"\n",
    "    attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "    ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "    encoder_layer = EncoderLayer(size=512, self_attn=attn, feed_forward=ff, dropout=0.1)\n",
    "    \n",
    "    x = torch.randn(2, 10, 512)\n",
    "    output = encoder_layer(x, mask=None)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 10, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32068f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoder_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c7dfe7",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "That's great, let's move on. Also be honest to the code I provided in the beginning. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Awesome! You're making excellent progress! \n",
    "\n",
    "You've now built:\n",
    "1.  Attention mechanism\n",
    "2.  Multi-Head Attention\n",
    "3.  Feed-Forward Network\n",
    "4.  Positional Encoding\n",
    "5.  Sublayer Connection (residual + norm)\n",
    "6.  Encoder Layer\n",
    "\n",
    "**What's next?**\n",
    "\n",
    "Looking at the original code, the next component is the **Encoder** - which stacks N=6 identical `EncoderLayer`s on top of each other.\n",
    "\n",
    "The Encoder class needs to:\n",
    "- Take a single `EncoderLayer` and clone it N times\n",
    "- Apply them sequentially\n",
    "- Apply a final layer normalization\n",
    "\n",
    "Before we code, do you understand why we need to **clone** the layer instead of just reusing the same one N times?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e6e5fa",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "We are using clone because we want a deep copy, and we don't want to use the same address. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Exactly right! \n",
    "\n",
    "If you just reused the same layer N times, they'd all share the **same parameters** (same memory address). So when you update weights during training, all \"layers\" would be identical - defeating the purpose of having multiple layers!\n",
    "\n",
    "By cloning (deep copy), each layer gets its **own independent parameters** that can learn different things.\n",
    "\n",
    "Now let's implement the **Encoder**. Looking at the original code, you'll need:\n",
    "\n",
    "**In `__init__`:**\n",
    "- Clone the layer N times (there's a helper function `clones` in the original code)\n",
    "- Create a final LayerNorm\n",
    "\n",
    "**In `forward`:**\n",
    "- Pass input through each layer sequentially\n",
    "- Apply final norm\n",
    "- Return output\n",
    "\n",
    "First, let's implement the `clones` helper function:\n",
    "\n",
    "```python\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers\"\n",
    "    # How would you create N deep copies?\n",
    "```\n",
    "\n",
    "Can you implement this helper function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d16a1d",
   "metadata": {},
   "source": [
    "### Final clones function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ca4e0",
   "metadata": {
    "time_run": "2025-12-01T07:15:06.761097+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers\"\n",
    "    # How would you create N deep copies?\n",
    "    return torch.nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d889e0",
   "metadata": {},
   "source": [
    "## Encoder Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1ab9c7",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this correct? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `clones` function is exactly right! \n",
    "\n",
    "You're using:\n",
    "- `copy.deepcopy(module)` to create independent copies\n",
    "- `torch.nn.ModuleList` to properly register them with PyTorch\n",
    "- List comprehension to create N copies\n",
    "\n",
    "Now let's implement the **Encoder** class. Try writing it:\n",
    "\n",
    "```python\n",
    "class Encoder(nn.Module):\n",
    "    \"Stack of N encoder layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super().__init__()\n",
    "        # What do you need here?\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        # What's the sequence of operations?\n",
    "```\n",
    "\n",
    "What do you need in `__init__`? (Hint: use `clones` and create a LayerNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a398cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    \"Stack of N encoder layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super().__init__()\n",
    "        # What do you need here?\n",
    "        self.encoders = clones(layer, N)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        # What's the sequence of operations?\n",
    "        for encoder in encoders:\n",
    "            x = encoder(x, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022dbc7f",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this correct? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Almost! You're missing two things:\n",
    "\n",
    "1. **Missing final LayerNorm**: The original code applies a final layer normalization after all the encoder layers. Add:\n",
    "   ```python\n",
    "   self.norm = nn.LayerNorm(layer.size)\n",
    "   ```\n",
    "\n",
    "2. **Bug in forward**: You wrote `encoders` but it should be `self.encoders`\n",
    "\n",
    "Can you fix these two issues?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984cc057",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Why we need final layer norm. It's not there in the paper. Isn't the layer norm included in the sublayer anyway? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent question! You're absolutely right to question this.\n",
    "\n",
    "**You're correct** - in the paper's diagram (Figure 1), the layer norm is shown as part of each sublayer connection, not as a separate final norm.\n",
    "\n",
    "**However**, looking at the original Annotated Transformer code, they add a final layer norm after all encoder layers. This is a common implementation detail that helps with:\n",
    "- Stabilizing the output before it goes to the decoder\n",
    "- Ensuring the encoder output is well-normalized\n",
    "\n",
    "**The paper vs implementation:**\n",
    "The paper doesn't explicitly show this final norm in the diagram, but many implementations (including the original authors' code) include it for better training stability.\n",
    "\n",
    "So it's an implementation choice rather than strictly from the paper. Do you want to:\n",
    "1. Include it (matches the original code you provided)\n",
    "2. Skip it (strictly follows the paper diagram)\n",
    "\n",
    "What would you prefer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6dafc7",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I'll include it. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Let's include the final layer norm to match the original code.\n",
    "\n",
    "So your `Encoder` should have:\n",
    "\n",
    "**In `__init__`:**\n",
    "```python\n",
    "self.layers = clones(layer, N)\n",
    "self.norm = nn.LayerNorm(layer.size)\n",
    "```\n",
    "\n",
    "**In `forward`:**\n",
    "```python\n",
    "for layer in self.layers:\n",
    "    x = layer(x, mask)\n",
    "return self.norm(x)\n",
    "```\n",
    "\n",
    "Can you update your code with these changes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f163ae98",
   "metadata": {},
   "source": [
    "### Final encoder function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bdcea0",
   "metadata": {
    "time_run": "2025-12-01T07:14:05.470034+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder(torch.nn.Module):\n",
    "    \"Stack of N encoder layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super().__init__()\n",
    "        # What do you need here?\n",
    "        self.encoders = clones(layer, N)\n",
    "        self.layer_norm = torch.nn.LayerNorm(layer.size)\n",
    "    def forward(self, x, mask):\n",
    "        # What's the sequence of operations?\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x, mask)\n",
    "        return self.layer_norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c4d221",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this fine? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `Encoder` class is now correct! \n",
    "\n",
    "You've got:\n",
    "-  Cloning N encoder layers\n",
    "-  Final layer normalization\n",
    "-  Sequential application of all layers\n",
    "-  Returning normalized output\n",
    "\n",
    "Let's test it:\n",
    "\n",
    "```python\n",
    "# Create components\n",
    "attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "encoder_layer = EncoderLayer(size=512, self_attn=attn, feed_forward=ff, dropout=0.1)\n",
    "\n",
    "# Create encoder with N=6 layers\n",
    "encoder = Encoder(encoder_layer, N=6)\n",
    "\n",
    "# Test\n",
    "x = torch.randn(2, 10, 512)\n",
    "output = encoder(x, mask=None)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))\n",
    "```\n",
    "\n",
    "Run this to verify it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e69bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create components\n",
    "attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "encoder_layer = EncoderLayer(size=512, self_attn=attn, feed_forward=ff, dropout=0.1)\n",
    "\n",
    "# Create encoder with N=6 layers\n",
    "encoder = Encoder(encoder_layer, N=6)\n",
    "\n",
    "# Test\n",
    "x = torch.randn(2, 10, 512)\n",
    "output = encoder(x, mask=None)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06489334",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Assume we are using NBDEV and create a unit test out of this. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Here's your Encoder as a unit test for nbdev:\n",
    "\n",
    "```python\n",
    "#| export\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers\"\n",
    "    return torch.nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "```\n",
    "\n",
    "```python\n",
    "#| export\n",
    "class Encoder(torch.nn.Module):\n",
    "    \"Stack of N encoder layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super().__init__()\n",
    "        self.encoders = clones(layer, N)\n",
    "        self.layer_norm = torch.nn.LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x, mask)\n",
    "        return self.layer_norm(x)\n",
    "```\n",
    "\n",
    "```python\n",
    "#| test\n",
    "def test_encoder():\n",
    "    \"Test Encoder stack\"\n",
    "    attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "    ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "    encoder_layer = EncoderLayer(size=512, self_attn=attn, feed_forward=ff, dropout=0.1)\n",
    "    encoder = Encoder(encoder_layer, N=6)\n",
    "    \n",
    "    x = torch.randn(2, 10, 512)\n",
    "    output = encoder(x, mask=None)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 10, 512])\n",
    "```\n",
    "\n",
    "Excellent progress! The encoder is complete. Ready to move on to the Decoder components?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c358aaf1",
   "metadata": {},
   "source": [
    "#### Unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067d6afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| test\n",
    "def test_encoder():\n",
    "    \"Test Encoder stack\"\n",
    "    attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "    ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "    encoder_layer = EncoderLayer(size=512, self_attn=attn, feed_forward=ff, dropout=0.1)\n",
    "    encoder = Encoder(encoder_layer, N=6)\n",
    "    \n",
    "    x = torch.randn(2, 10, 512)\n",
    "    output = encoder(x, mask=None)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 10, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626d505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c096f612",
   "metadata": {},
   "source": [
    "## Decoder Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a6e37a",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Now, what is next? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great work! You've completed the entire **Encoder** side of the Transformer! \n",
    "\n",
    "**What's next: The Decoder**\n",
    "\n",
    "The Decoder is similar to the Encoder but has some key differences:\n",
    "\n",
    "1. **Masked Self-Attention** - prevents looking at future tokens\n",
    "2. **Cross-Attention** - attends to the encoder output\n",
    "3. **Three sub-layers** instead of two (self-attn, cross-attn, feed-forward)\n",
    "\n",
    "Let's start with the **Decoder Layer**. It will have:\n",
    "- Masked multi-head self-attention\n",
    "- Multi-head cross-attention (attends to encoder output)\n",
    "- Position-wise feed-forward\n",
    "- Three `SublayerConnection` modules (one for each sub-layer)\n",
    "\n",
    "Before coding, do you understand the difference between:\n",
    "- **Self-attention** (what the encoder uses)\n",
    "- **Masked self-attention** (decoder looks at previous tokens only)\n",
    "- **Cross-attention** (decoder attends to encoder output)\n",
    "\n",
    "Want me to clarify these concepts first?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2affdd01",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I'd rather you quiz me on the concepts. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Let's test your understanding:\n",
    "\n",
    "**Question 1: Masked Self-Attention**\n",
    "\n",
    "In the decoder, why do we need to mask the self-attention? What would happen if we didn't mask it during training?\n",
    "\n",
    "**Question 2: Cross-Attention**\n",
    "\n",
    "In cross-attention, where do the Query (Q), Key (K), and Value (V) come from? (Hint: think about what the decoder has access to)\n",
    "\n",
    "**Question 3: Decoder Architecture**\n",
    "\n",
    "How many sublayers does a decoder layer have, and what does each one do?\n",
    "\n",
    "Give these a shot!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f10f9e1",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I think masking is needed mostly while training. The thing is, the eventual output is already known. But we want to make sure that we do not leak the future word output words beforehand. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Exactly right! \n",
    "\n",
    "**Masked Self-Attention:** During training, we have the entire target sequence available. Without masking, the decoder could \"cheat\" by looking at future words it's supposed to predict. The mask ensures position i can only attend to positions  i.\n",
    "\n",
    "**Key insight:** During inference (actual use), we generate one token at a time, so there ARE no future tokens to look at. But during training, we need the mask to simulate this autoregressive behavior.\n",
    "\n",
    "Great answer! Now try **Question 2:**\n",
    "\n",
    "In cross-attention (the second attention mechanism in the decoder), where do Q, K, and V come from? Think about what inputs the decoder has access to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcf2399",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Let's explore this in a bit of detail. The input is, \"You are good.\" And the output is. Vous etes bons\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! Let's trace through this example step by step.\n",
    "\n",
    "**Input (English):** \"You are good\"\n",
    "**Output (French):** \"Vous tes bons\"\n",
    "\n",
    "**During training, let's say we're predicting the 2nd word \"tes\":**\n",
    "\n",
    "**Encoder side:**\n",
    "- Processes \"You are good\"  produces contextualized representations (memory)\n",
    "\n",
    "**Decoder side at position 2:**\n",
    "\n",
    "1. **Masked Self-Attention:** \n",
    "   - Query from \"tes\" position\n",
    "   - Can attend to: \"Vous\" and \"tes\" (not \"bons\" - that's future!)\n",
    "   - Q, K, V all come from decoder's own input\n",
    "\n",
    "2. **Cross-Attention:** (This is your Question 2!)\n",
    "   - Where does Q come from?\n",
    "   - Where do K and V come from?\n",
    "\n",
    "Think about what the decoder needs to \"look at\" from the encoder. What would make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e206a8b5",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "In cross-attention, Q and K come from the encoder outputs. And V comes from the output of the Masked multi-head attention. So basically, the query is from the input, and the key that is the dictionary is also from the input, but the eventual value will come from the output, or in this case, the translation. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Not quite! Let me clarify:\n",
    "\n",
    "**In Cross-Attention:**\n",
    "\n",
    "- **Q (Query)**: Comes from the **decoder** (the output of masked self-attention)\n",
    "- **K (Key)**: Comes from the **encoder** output (memory)\n",
    "- **V (Value)**: Comes from the **encoder** output (memory)\n",
    "\n",
    "So the decoder is asking \"what information do I need from the input?\" and the encoder provides both the keys (what's available) and values (the actual information).\n",
    "\n",
    "**Think of it this way:**\n",
    "- Decoder says: \"I'm trying to generate 'tes', what from the English sentence is relevant?\" (Query)\n",
    "- Encoder says: \"Here's what I have: 'You', 'are', 'good'\" (Keys)\n",
    "- Decoder attends strongly to \"are\" \n",
    "- Encoder provides: \"Here's the information about 'are'\" (Value)\n",
    "\n",
    "Does this clarify where Q, K, V come from in cross-attention?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac0c55e",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Okay, that's clear. That query is from the decoder, and the key and value are from the encoder. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Now you've got it! \n",
    "\n",
    "**Cross-Attention summary:**\n",
    "- Q: from decoder (asking \"what do I need?\")\n",
    "- K, V: from encoder (providing \"here's what's available\")\n",
    "\n",
    "Now let's move to **Question 3:**\n",
    "\n",
    "How many sublayers does a decoder layer have, and what does each one do?\n",
    "\n",
    "Give it a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1c4d8",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "There are three sublayers. The first sub-layer is self-attention on the mast output. The second sub-layer is cross-attention. Like I said, the query is from the decoder, and the key and value from the encoder. And the third sublayer once again is the position-wise feedforward network. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent! You've got it perfectly! \n",
    "\n",
    "**Three sublayers in Decoder Layer:**\n",
    "1. **Masked Self-Attention** - decoder attends to its own previous outputs\n",
    "2. **Cross-Attention** - decoder attends to encoder output (Q from decoder, K&V from encoder)\n",
    "3. **Position-wise Feed-Forward** - same as encoder\n",
    "\n",
    "Each sublayer has a residual connection + layer norm wrapped around it (using `SublayerConnection`).\n",
    "\n",
    "Now you're ready to implement the **Decoder Layer**! \n",
    "\n",
    "Looking at the structure, what do you think you'll need in `__init__`?\n",
    "\n",
    "Hint: You'll need to store 3 attention modules and create 3 `SublayerConnection` modules.\n",
    "\n",
    "Want to give it a try?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622f8f9c",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Yes, I would like to give it a try. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Let's implement the **Decoder Layer**.\n",
    "\n",
    "Start with the `__init__` method. You need to store:\n",
    "\n",
    "1. `self.size` (d_model)\n",
    "2. Three attention modules:\n",
    "   - `self.self_attn` (masked self-attention)\n",
    "   - `self.src_attn` (cross-attention to encoder)\n",
    "   - `self.feed_forward` (FFN)\n",
    "3. Three `SublayerConnection` modules (one for each sublayer)\n",
    "\n",
    "Try writing the `__init__`:\n",
    "\n",
    "```python\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super().__init__()\n",
    "        # What do you need here?\n",
    "```\n",
    "\n",
    "Give it a shot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7108b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(torch.nn.Module):\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super().__init__()\n",
    "        # What do you need here?\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayers = clones(SublayerConnection(size, dropout), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0621a7",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "All good. Be faithful to the original code. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `__init__` is exactly right and matches the original code! \n",
    "\n",
    "You've got:\n",
    "-  All three attention modules stored\n",
    "-  Feed-forward stored\n",
    "-  Three `SublayerConnection` modules cloned\n",
    "\n",
    "Now for the `forward` method. You need to implement:\n",
    "\n",
    "```python\n",
    "def forward(self, x, memory, src_mask, tgt_mask):\n",
    "    # What are the three sublayer operations?\n",
    "```\n",
    "\n",
    "Where:\n",
    "- `x` = decoder input\n",
    "- `memory` = encoder output\n",
    "- `src_mask` = mask for encoder (used in cross-attention)\n",
    "- `tgt_mask` = mask for decoder (used in masked self-attention)\n",
    "\n",
    "Try writing the three sublayer calls using lambdas (like you did in EncoderLayer). What would each one look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091994ff",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this good? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Close! But there are a few issues to fix:\n",
    "\n",
    "1. **First sublayer**: You're missing the `x` argument to the lambda, and the mask should be `tgt_mask` (not `None`):\n",
    "   ```python\n",
    "   x = self.sublayers[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "   ```\n",
    "\n",
    "2. **Second sublayer**: What are `K` and `V`? They should come from `memory` (the encoder output). The query comes from decoder (`x`), but keys and values come from encoder:\n",
    "   ```python\n",
    "   x = self.sublayers[1](x, lambda x: self.src_attn(x, memory, memory, src_mask))\n",
    "   ```\n",
    "\n",
    "3. **Third sublayer**: This one is correct!\n",
    "\n",
    "Can you fix the first two sublayers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6ec742",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I'm not sure I understand what's the difference between tgt_mask and src_mask. Can you explain to me? I would guess that TGT mask is to avoid leakage of outputs, but I am not sure about SRC mask. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question! Let me clarify the two masks:\n",
    "\n",
    "**tgt_mask (target mask):**\n",
    "You're exactly right! This is the **causal/look-ahead mask** for the decoder. It prevents position i from seeing positions > i. This is the triangular mask that ensures no future leakage.\n",
    "\n",
    "**src_mask (source mask):**\n",
    "This is a **padding mask** for the encoder output. Remember when you batch sentences together, shorter sentences get padded with `<pad>` tokens? The src_mask tells the decoder \"don't pay attention to these padding positions in the encoder output - they're meaningless.\"\n",
    "\n",
    "**Where they're used:**\n",
    "- `tgt_mask`: In masked self-attention (decoder looking at its own tokens)\n",
    "- `src_mask`: In cross-attention (decoder looking at encoder output)\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Source: \"Hello world <pad> <pad>\"   src_mask hides the <pad>\n",
    "Target: \"Bonjour le monde\"          tgt_mask prevents future leakage\n",
    "```\n",
    "\n",
    "Does this clarify the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5230b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x, memory, src_mask, tgt_mask):\n",
    "    # What are the three sublayer operations?\n",
    "    x = self.sublayers[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "    x = self.sublayers[1](x, lambda x: self.src_attn(x, K, V, src_mask))\n",
    "    x = self.sublayers[2](x, lambda x: self.feed_forward(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb8a3e3",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this correct? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Almost! You still have `K` and `V` as variables in the second sublayer, but they're not defined.\n",
    "\n",
    "Remember: in cross-attention, both the keys and values come from `memory` (the encoder output). So it should be:\n",
    "\n",
    "```python\n",
    "x = self.sublayers[1](x, lambda x: self.src_attn(x, memory, memory, src_mask))\n",
    "```\n",
    "\n",
    "The pattern is: `self.src_attn(query, key, value, mask)` where:\n",
    "- query = `x` (from decoder)\n",
    "- key = `memory` (from encoder)\n",
    "- value = `memory` (from encoder)\n",
    "\n",
    "Can you fix that line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a0cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x, memory, src_mask, tgt_mask):\n",
    "    # What are the three sublayer operations?\n",
    "    x = self.sublayers[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "    x = self.sublayers[1](x, lambda x: self.src_attn(x, memory, memory, src_mask))\n",
    "    x = self.sublayers[2](x, lambda x: self.feed_forward(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7b4322",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this correct? Stay loyal to the original code. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `DecoderLayer.forward` is now correct and matches the original code! \n",
    "\n",
    "You've got:\n",
    "-  Masked self-attention with `tgt_mask`\n",
    "-  Cross-attention with query from decoder, K&V from encoder memory, using `src_mask`\n",
    "-  Feed-forward network\n",
    "\n",
    "Now let's combine the `__init__` and `forward` into the complete class and test it:\n",
    "\n",
    "```python\n",
    "class DecoderLayer(torch.nn.Module):\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayers = clones(SublayerConnection(size, dropout), 3)\n",
    "    \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        x = self.sublayers[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayers[1](x, lambda x: self.src_attn(x, memory, memory, src_mask))\n",
    "        x = self.sublayers[2](x, self.feed_forward)\n",
    "        return x\n",
    "```\n",
    "\n",
    "Want to test it now?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ebf231",
   "metadata": {},
   "source": [
    "### Final decoder layer Function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d048a",
   "metadata": {
    "time_run": "2025-12-01T07:14:22.008053+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class DecoderLayer(torch.nn.Module):\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayers = clones(SublayerConnection(size, dropout), 3)\n",
    "    \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        x = self.sublayers[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayers[1](x, lambda x: self.src_attn(x, memory, memory, src_mask))\n",
    "        x = self.sublayers[2](x, self.feed_forward)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d32edf",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Okay, let's test it. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! Let's test your `DecoderLayer`:\n",
    "\n",
    "```python\n",
    "# Create components\n",
    "self_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "src_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "decoder_layer = DecoderLayer(size=512, self_attn=self_attn, src_attn=src_attn, \n",
    "                             feed_forward=ff, dropout=0.1)\n",
    "\n",
    "# Test\n",
    "x = torch.randn(2, 10, 512)  # decoder input\n",
    "memory = torch.randn(2, 15, 512)  # encoder output (different seq_len is fine)\n",
    "src_mask = None\n",
    "tgt_mask = None\n",
    "\n",
    "output = decoder_layer(x, memory, src_mask, tgt_mask)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))\n",
    "```\n",
    "\n",
    "Run this and see if it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5e9f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create components\n",
    "self_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "src_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "decoder_layer = DecoderLayer(size=512, self_attn=self_attn, src_attn=src_attn, \n",
    "                             feed_forward=ff, dropout=0.1)\n",
    "\n",
    "# Test\n",
    "x = torch.randn(2, 10, 512)  # decoder input\n",
    "memory = torch.randn(2, 15, 512)  # encoder output (different seq_len is fine)\n",
    "src_mask = None\n",
    "tgt_mask = None\n",
    "\n",
    "output = decoder_layer(x, memory, src_mask, tgt_mask)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f632bf07",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "What happened, bro? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Ah, I see the issue! The problem is in your `MultiHeadedAttention.forward` method.\n",
    "\n",
    "**The bug:** In cross-attention, the `key` and `value` come from `memory` which has a **different sequence length** (15) than the query which comes from `x` (10).\n",
    "\n",
    "But in your code, you're using `seq_len` from Q for reshaping K and V:\n",
    "\n",
    "```python\n",
    "seq_len = Q.size(1)  # This is 10 (from decoder)\n",
    "K = K.reshape(batch_size, seq_len, self.h, self.d_k)  # But K has seq_len=15!\n",
    "```\n",
    "\n",
    "**The fix:** You need to get the sequence length from each tensor individually:\n",
    "\n",
    "```python\n",
    "Q = Q.reshape(batch_size, -1, self.h, self.d_k).transpose(1,2)\n",
    "K = K.reshape(batch_size, -1, self.h, self.d_k).transpose(1,2)\n",
    "V = V.reshape(batch_size, -1, self.h, self.d_k).transpose(1,2)\n",
    "```\n",
    "\n",
    "Using `-1` lets PyTorch infer the sequence length automatically!\n",
    "\n",
    "Can you update your `MultiHeadedAttention` class to fix this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed7a448",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Are you sure? Is this honest to the original code? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "You're right to question me! Let me check the original code more carefully.\n",
    "\n",
    "Looking at the original `MultiHeadedAttention.forward`:\n",
    "\n",
    "```python\n",
    "nbatches = query.size(0)\n",
    "\n",
    "# 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "query, key, value = [\n",
    "    lin(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "    for lin, x in zip(self.linears, (query, key, value))\n",
    "]\n",
    "```\n",
    "\n",
    "You're right - the original code uses `-1` to automatically infer the sequence length! So yes, my fix is correct and matches the original.\n",
    "\n",
    "Your current code has:\n",
    "```python\n",
    "seq_len = Q.size(1)\n",
    "Q = Q.reshape(batch_size, seq_len, self.h, self.d_k).transpose(1,2)\n",
    "K = K.reshape(batch_size, seq_len, self.h, self.d_k).transpose(1,2)  # Bug here!\n",
    "```\n",
    "\n",
    "Should be:\n",
    "```python\n",
    "Q = Q.reshape(batch_size, -1, self.h, self.d_k).transpose(1,2)\n",
    "K = K.reshape(batch_size, -1, self.h, self.d_k).transpose(1,2)\n",
    "V = V.reshape(batch_size, -1, self.h, self.d_k).transpose(1,2)\n",
    "```\n",
    "\n",
    "Can you update your `MultiHeadedAttention` class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2696fa17",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I could fix that, but what about the part where we're concatenating and we're using seq_length again? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent catch! You're absolutely right - there's the same issue in the concatenation step!\n",
    "\n",
    "Looking at your code, you probably have something like:\n",
    "\n",
    "```python\n",
    "x = x.transpose(1,2).reshape(batch_size, seq_len, -1)\n",
    "```\n",
    "\n",
    "But `seq_len` was computed from Q, so it won't work when K and V have different lengths.\n",
    "\n",
    "**The fix:** Use `-1` there too:\n",
    "\n",
    "```python\n",
    "x = x.transpose(1,2).reshape(batch_size, -1, self.h * self.d_k)\n",
    "```\n",
    "\n",
    "Or even simpler (matching the original code):\n",
    "\n",
    "```python\n",
    "x = x.transpose(1,2).contiguous().view(nbatches, -1, self.h * self.d_k)\n",
    "```\n",
    "\n",
    "Can you update both the reshaping at the beginning AND the concatenation at the end of your `MultiHeadedAttention.forward` method?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c4a96e",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "fixed it now\n",
    "\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! Now let's test your `DecoderLayer` again with the fixed `MultiHeadedAttention`:\n",
    "\n",
    "```python\n",
    "# Create components\n",
    "self_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "src_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "decoder_layer = DecoderLayer(size=512, self_attn=self_attn, src_attn=src_attn, \n",
    "                             feed_forward=ff, dropout=0.1)\n",
    "\n",
    "# Test\n",
    "x = torch.randn(2, 10, 512)  # decoder input\n",
    "memory = torch.randn(2, 15, 512)  # encoder output (different seq_len)\n",
    "src_mask = None\n",
    "tgt_mask = None\n",
    "\n",
    "output = decoder_layer(x, memory, src_mask, tgt_mask)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))\n",
    "```\n",
    "\n",
    "Run this and let me know if it works now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e090d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create components\n",
    "self_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "src_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "decoder_layer = DecoderLayer(size=512, self_attn=self_attn, src_attn=src_attn, \n",
    "                             feed_forward=ff, dropout=0.1)\n",
    "\n",
    "# Test\n",
    "x = torch.randn(2, 10, 512)  # decoder input\n",
    "memory = torch.randn(2, 15, 512)  # encoder output (different seq_len)\n",
    "src_mask = None\n",
    "tgt_mask = None\n",
    "\n",
    "output = decoder_layer(x, memory, src_mask, tgt_mask)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca06d12",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Awesome, assume we are using NBDev and create a unit test out of this. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Here's your Decoder Layer as a unit test for nbdev:\n",
    "\n",
    "```python\n",
    "#| export\n",
    "class DecoderLayer(torch.nn.Module):\n",
    "    \"Decoder layer with masked self-attention, cross-attention, and feed-forward\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayers = clones(SublayerConnection(size, dropout), 3)\n",
    "    \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        x = self.sublayers[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayers[1](x, lambda x: self.src_attn(x, memory, memory, src_mask))\n",
    "        x = self.sublayers[2](x, self.feed_forward)\n",
    "        return x\n",
    "```\n",
    "\n",
    "```python\n",
    "#| test\n",
    "def test_decoder_layer():\n",
    "    \"Test Decoder Layer with cross-attention\"\n",
    "    self_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "    src_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "    ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "    decoder_layer = DecoderLayer(size=512, self_attn=self_attn, src_attn=src_attn, \n",
    "                                 feed_forward=ff, dropout=0.1)\n",
    "    \n",
    "    x = torch.randn(2, 10, 512)  # decoder input\n",
    "    memory = torch.randn(2, 15, 512)  # encoder output\n",
    "    output = decoder_layer(x, memory, src_mask=None, tgt_mask=None)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 10, 512])\n",
    "```\n",
    "\n",
    "Excellent work! Ready to build the full Decoder stack next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c3e7b2",
   "metadata": {},
   "source": [
    "#### Unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4561cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| test\n",
    "def test_decoder_layer():\n",
    "    \"Test Decoder Layer with cross-attention\"\n",
    "    self_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "    src_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "    ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "    decoder_layer = DecoderLayer(size=512, self_attn=self_attn, src_attn=src_attn, \n",
    "                                 feed_forward=ff, dropout=0.1)\n",
    "    \n",
    "    x = torch.randn(2, 10, 512)  # decoder input\n",
    "    memory = torch.randn(2, 15, 512)  # encoder output\n",
    "    output = decoder_layer(x, memory, src_mask=None, tgt_mask=None)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 10, 512])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51a3c6f",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f124d5",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Amazing progress, now let's finish this. Stay honest to the original code. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent! You're almost done with the Transformer! \n",
    "\n",
    "**What's left:**\n",
    "\n",
    "1. **Decoder** - Stack N=6 decoder layers (similar to how you built Encoder)\n",
    "2. **Embeddings** - Convert token IDs to vectors\n",
    "3. **Generator** - Final linear + softmax to predict next token\n",
    "4. **EncoderDecoder** - The complete model that ties everything together\n",
    "\n",
    "Let's start with the **Decoder** stack. It's very similar to the Encoder you already built.\n",
    "\n",
    "Looking at the original code, what do you think the Decoder class needs?\n",
    "\n",
    "Hint: It's almost identical to Encoder, but the `forward` method takes different arguments. Try writing the skeleton:\n",
    "\n",
    "```python\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super().__init__()\n",
    "        # What do you need?\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        # What's the sequence of operations?\n",
    "```\n",
    "\n",
    "Give it a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb1b52f",
   "metadata": {},
   "source": [
    "### Final decoder function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb25178f",
   "metadata": {
    "time_run": "2025-12-01T07:14:26.619408+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super().__init__()\n",
    "        # What do you need?\n",
    "        self.layers = clones(layer, N)\n",
    "        self.layer_norm = torch.nn.LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        # What's the sequence of operations?\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.layer_norm(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35870422",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Have we done it? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `Decoder` class is exactly right and matches the original code! \n",
    "\n",
    "You've got:\n",
    "-  Cloning N decoder layers\n",
    "-  Final layer normalization\n",
    "-  Sequential application passing all 4 arguments (x, memory, src_mask, tgt_mask)\n",
    "-  Returning normalized output\n",
    "\n",
    "Let's test it:\n",
    "\n",
    "```python\n",
    "# Create components\n",
    "self_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "src_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "decoder_layer = DecoderLayer(size=512, self_attn=self_attn, src_attn=src_attn, \n",
    "                             feed_forward=ff, dropout=0.1)\n",
    "\n",
    "# Create decoder with N=6 layers\n",
    "decoder = Decoder(decoder_layer, N=6)\n",
    "\n",
    "# Test\n",
    "x = torch.randn(2, 10, 512)\n",
    "memory = torch.randn(2, 15, 512)\n",
    "output = decoder(x, memory, src_mask=None, tgt_mask=None)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))\n",
    "```\n",
    "\n",
    "Run this to verify!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcaaff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create components\n",
    "self_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "src_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "decoder_layer = DecoderLayer(size=512, self_attn=self_attn, src_attn=src_attn, \n",
    "                             feed_forward=ff, dropout=0.1)\n",
    "\n",
    "# Create decoder with N=6 layers\n",
    "decoder = Decoder(decoder_layer, N=6)\n",
    "\n",
    "# Test\n",
    "x = torch.randn(2, 10, 512)\n",
    "memory = torch.randn(2, 15, 512)\n",
    "output = decoder(x, memory, src_mask=None, tgt_mask=None)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefd073e",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Amazing! Then now assume you're a NB Dev. No need to show the original function but show the unit test. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "```python\n",
    "#| test\n",
    "def test_decoder():\n",
    "    \"Test Decoder stack\"\n",
    "    self_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "    src_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "    ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "    decoder_layer = DecoderLayer(size=512, self_attn=self_attn, src_attn=src_attn, \n",
    "                                 feed_forward=ff, dropout=0.1)\n",
    "    decoder = Decoder(decoder_layer, N=6)\n",
    "    \n",
    "    x = torch.randn(2, 10, 512)\n",
    "    memory = torch.randn(2, 15, 512)\n",
    "    output = decoder(x, memory, src_mask=None, tgt_mask=None)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 10, 512])\n",
    "```\n",
    "\n",
    "Fantastic progress! You've now built both the complete Encoder and Decoder stacks! What's next - Embeddings, Generator, or the final EncoderDecoder wrapper?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef59dbd",
   "metadata": {},
   "source": [
    "### Unit test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ead8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| test\n",
    "def test_decoder():\n",
    "    \"Test Decoder stack\"\n",
    "    self_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "    src_attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "    ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "    decoder_layer = DecoderLayer(size=512, self_attn=self_attn, src_attn=src_attn, \n",
    "                                 feed_forward=ff, dropout=0.1)\n",
    "    decoder = Decoder(decoder_layer, N=6)\n",
    "    \n",
    "    x = torch.randn(2, 10, 512)\n",
    "    memory = torch.randn(2, 15, 512)\n",
    "    output = decoder(x, memory, src_mask=None, tgt_mask=None)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 10, 512])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2905ed",
   "metadata": {},
   "source": [
    "## Embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e28db",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Okay, let's do embeddings. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! Let's implement **Embeddings**.\n",
    "\n",
    "**What are embeddings?**\n",
    "\n",
    "They convert discrete token IDs (integers) into continuous vector representations. For example:\n",
    "- Token ID 42  vector of size d_model=512\n",
    "\n",
    "Looking at the paper and original code, the Embeddings class:\n",
    "1. Uses `nn.Embedding` to create a lookup table\n",
    "2. Multiplies the output by d_model (for scaling)\n",
    "\n",
    "**Why multiply by d_model?**\n",
    "\n",
    "This scaling ensures that the embedding values and positional encoding values are on a similar scale before adding them together.\n",
    "\n",
    "Try implementing it:\n",
    "\n",
    "```python\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super().__init__()\n",
    "        # What do you need here?\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # What's the operation?\n",
    "```\n",
    "\n",
    "What do you need to store in `__init__`, and what operation goes in `forward`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d084cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(torch.nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super().__init__()\n",
    "        # What do you need here?\n",
    "        self.embedding = torch.nn.Embedding(vocab, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # What's the operation?\n",
    "        return self.embedding(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3010ec4b",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this correct? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Almost! You're missing the scaling factor. Remember, the paper multiplies the embeddings by d_model.\n",
    "\n",
    "You need to:\n",
    "1. Store `d_model` in `__init__` so you can use it in `forward`\n",
    "2. Multiply the embedding output by `math.sqrt(self.d_model)`\n",
    "\n",
    "Can you add these two things?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245a032c",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Why are we doing this? I don't understand. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question! Let me explain why we scale by d_model.\n",
    "\n",
    "**The problem:**\n",
    "\n",
    "After creating embeddings, you **add** them to positional encodings:\n",
    "```\n",
    "final_input = embeddings + positional_encoding\n",
    "```\n",
    "\n",
    "But embeddings from `nn.Embedding` typically have small values (initialized around -0.1 to 0.1), while positional encodings use sin/cos which range from -1 to 1.\n",
    "\n",
    "**Without scaling:**\n",
    "- Embeddings: small values (~0.1)\n",
    "- Positional encoding: larger values (~1.0)\n",
    "- The positional encoding would dominate!\n",
    "\n",
    "**With d_model scaling:**\n",
    "- If d_model = 512, then 512  22.6\n",
    "- Embeddings get multiplied by ~22.6, making them comparable in magnitude to positional encodings\n",
    "- Now both contribute meaningfully to the final representation\n",
    "\n",
    "**In short:** It balances the contribution of embeddings and positional encodings so neither dominates.\n",
    "\n",
    "Does this make sense now?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b05ef1",
   "metadata": {},
   "source": [
    "### Final Embeddings Model Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaf79db",
   "metadata": {
    "time_run": "2025-12-01T07:14:31.197306+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class Embeddings(torch.nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super().__init__()\n",
    "        # What do you need here?\n",
    "        self.d_model = d_model\n",
    "        self.embedding = torch.nn.Embedding(vocab, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # What's the operation?\n",
    "        return self.embedding(x) * math.sqrt(self.d_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5e2c6d",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Are you happy now? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `Embeddings` class is now correct and matches the original code! \n",
    "\n",
    "You've got:\n",
    "-  Storing d_model\n",
    "-  Creating the embedding layer\n",
    "-  Scaling by d_model in forward\n",
    "\n",
    "Let's test it:\n",
    "\n",
    "```python\n",
    "embeddings = Embeddings(d_model=512, vocab=10000)\n",
    "x = torch.randint(0, 10000, (2, 10))  # batch=2, seq_len=10, random token IDs\n",
    "output = embeddings(x)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))\n",
    "```\n",
    "\n",
    "Run this to verify it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a64aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = Embeddings(d_model=512, vocab=10000)\n",
    "x = torch.randint(0, 10000, (2, 10))  # batch=2, seq_len=10, random token IDs\n",
    "output = embeddings(x)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99f55b",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "That's amazing. Now, assume we're using NBDEV. We don't need to output the original function, just the unit test. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "```python\n",
    "#| test\n",
    "def test_embeddings():\n",
    "    \"Test Embeddings with scaling\"\n",
    "    embeddings = Embeddings(d_model=512, vocab=10000)\n",
    "    x = torch.randint(0, 10000, (2, 10))  # batch=2, seq_len=10\n",
    "    output = embeddings(x)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 10, 512])\n",
    "    # Check that scaling is applied (output should be larger than raw embedding)\n",
    "    raw_embed = embeddings.embedding(x)\n",
    "    assert torch.allclose(output, raw_embed * math.sqrt(512))\n",
    "```\n",
    "\n",
    "Great! What's next - Generator or the final EncoderDecoder wrapper?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57174606",
   "metadata": {},
   "source": [
    "### Unit test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863259c8",
   "metadata": {
    "time_run": "2025-11-30T18:10:51.285432+00:00"
   },
   "outputs": [],
   "source": [
    "#| test\n",
    "def test_embeddings():\n",
    "    \"Test Embeddings with scaling\"\n",
    "    embeddings = Embeddings(d_model=512, vocab=10000)\n",
    "    x = torch.randint(0, 10000, (2, 10))  # batch=2, seq_len=10\n",
    "    output = embeddings(x)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 10, 512])\n",
    "    # Check that scaling is applied (output should be larger than raw embedding)\n",
    "    raw_embed = embeddings.embedding(x)\n",
    "    assert torch.allclose(output, raw_embed * math.sqrt(512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53c6031",
   "metadata": {
    "time_run": "2025-11-30T18:10:52.551004+00:00"
   },
   "outputs": [],
   "source": [
    "test_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f8e33",
   "metadata": {},
   "source": [
    "## Generator class "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb67dbf",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Awesome. Now what? Stay honest to the original quote. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent progress! Looking at the original code structure, the next component is the **Generator**.\n",
    "\n",
    "**What does the Generator do?**\n",
    "\n",
    "It's the final layer that converts the decoder's output (d_model=512 dimensions) into vocabulary predictions. It does:\n",
    "1. Linear projection: d_model  vocab_size\n",
    "2. Log softmax to get log probabilities for each token\n",
    "\n",
    "This is what actually predicts \"what's the next word?\"\n",
    "\n",
    "Try implementing it:\n",
    "\n",
    "```python\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super().__init__()\n",
    "        # What layer do you need?\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # What operation?\n",
    "```\n",
    "\n",
    "What do you need in `__init__` and `forward`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55026e6b",
   "metadata": {},
   "source": [
    "### Final generator function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0ca2bd",
   "metadata": {
    "time_run": "2025-12-01T07:14:36.181962+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super().__init__()\n",
    "        # What layer do you need?\n",
    "        self.linear = torch.nn.Linear(d_model, vocab)\n",
    "        self.logsoftmax = torch.nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # What operation?\n",
    "        x = self.linear(x)\n",
    "        return self.logsoftmax(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06466daa",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "see if tihs works?\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `Generator` class looks correct and matches the original code! \n",
    "\n",
    "You've got:\n",
    "-  Linear layer (d_model  vocab)\n",
    "-  LogSoftmax on the last dimension\n",
    "\n",
    "Let's test it:\n",
    "\n",
    "```python\n",
    "generator = Generator(d_model=512, vocab=10000)\n",
    "x = torch.randn(2, 10, 512)  # decoder output\n",
    "output = generator(x)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 10, 10000))  # log probabilities for each token in vocab\n",
    "```\n",
    "\n",
    "Run this to verify it works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d9d79c",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Now assume we are using NBDEV. No need to output the function but output the unit test. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "```python\n",
    "#| test\n",
    "def test_generator():\n",
    "    \"Test Generator output projection\"\n",
    "    generator = Generator(d_model=512, vocab=10000)\n",
    "    x = torch.randn(2, 10, 512)  # decoder output\n",
    "    output = generator(x)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 10, 10000])\n",
    "    # Check that output is log probabilities (should sum to ~1 after exp)\n",
    "    assert torch.allclose(output.exp().sum(dim=-1), torch.ones(2, 10), atol=1e-5)\n",
    "```\n",
    "\n",
    "Excellent! You're almost done! The final piece is the **EncoderDecoder** wrapper that ties everything together. Ready for that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47bc976",
   "metadata": {},
   "source": [
    "#### Unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f983578",
   "metadata": {
    "time_run": "2025-11-30T18:21:47.344198+00:00"
   },
   "outputs": [],
   "source": [
    "#| test\n",
    "def test_generator():\n",
    "    \"Test Generator output projection\"\n",
    "    generator = Generator(d_model=512, vocab=10000)\n",
    "    x = torch.randn(2, 10, 512)  # decoder output\n",
    "    output = generator(x)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 10, 10000])\n",
    "    # Check that output is log probabilities (should sum to ~1 after exp)\n",
    "    assert torch.allclose(output.exp().sum(dim=-1), torch.ones(2, 10), atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97feb70c",
   "metadata": {
    "time_run": "2025-11-30T18:22:07.005663+00:00"
   },
   "outputs": [],
   "source": [
    "test_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36c5782",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Awesome. What's next? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Amazing work! You're at the final step! \n",
    "\n",
    "**What's left: EncoderDecoder**\n",
    "\n",
    "This is the top-level class that ties everything together. Looking at the original code, it stores all the components and defines how data flows through the model.\n",
    "\n",
    "**What does EncoderDecoder need?**\n",
    "\n",
    "In `__init__`, it stores:\n",
    "- encoder\n",
    "- decoder  \n",
    "- src_embed (source embeddings + positional encoding)\n",
    "- tgt_embed (target embeddings + positional encoding)\n",
    "- generator\n",
    "\n",
    "In `forward`, it needs methods like:\n",
    "- `encode()` - process source through encoder\n",
    "- `decode()` - process target through decoder\n",
    "- `forward()` - full forward pass\n",
    "\n",
    "Before coding, do you understand the data flow? Source goes through encoder, then decoder uses encoder output + target to generate predictions.\n",
    "\n",
    "Want to try implementing the `__init__` first?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42237b5a",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Yes, let's try it. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Let's implement the **EncoderDecoder** class.\n",
    "\n",
    "Start with the `__init__` method. Looking at the original code, you need to store 5 components:\n",
    "\n",
    "```python\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super().__init__()\n",
    "        # Store all 5 components\n",
    "```\n",
    "\n",
    "Try writing the `__init__` - just store each component as an attribute. What would you write?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e72d14",
   "metadata": {
    "time_run": "2025-11-30T18:25:42.918302+00:00"
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(torch.nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super().__init__()\n",
    "        # Store all 5 components\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011db03d",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is that good? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `__init__` is exactly right! \n",
    "\n",
    "Now let's implement the methods. Looking at the original code, you need:\n",
    "\n",
    "1. **`encode(self, src, src_mask)`** - runs source through embedding and encoder\n",
    "2. **`decode(self, memory, src_mask, tgt, tgt_mask)`** - runs target through embedding and decoder\n",
    "3. **`forward(self, src, tgt, src_mask, tgt_mask)`** - combines encode and decode\n",
    "\n",
    "Try implementing the `encode` method first. What should it do?\n",
    "\n",
    "Hint: Apply src_embed to src, then pass through encoder with the mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56043dc6",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I'm sleepy, let's do the rest tomorrow. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "No problem! You've made incredible progress today! \n",
    "\n",
    "**What you've accomplished:**\n",
    "-  Attention mechanism\n",
    "-  Multi-Head Attention\n",
    "-  Position-wise Feed-Forward\n",
    "-  Positional Encoding\n",
    "-  Sublayer Connection\n",
    "-  Encoder Layer & full Encoder stack\n",
    "-  Decoder Layer & full Decoder stack\n",
    "-  Embeddings\n",
    "-  Generator\n",
    "\n",
    "**What's left (very little!):**\n",
    "- Finish EncoderDecoder (encode, decode, forward methods)\n",
    "- Optional: make_model helper function to build the complete transformer\n",
    "\n",
    "You're about 95% done with implementing the Transformer from scratch! Get some rest, and we'll finish it up tomorrow. Great work! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7771d0e",
   "metadata": {
    "solveit_ai": true,
    "use_thinking": true
   },
   "source": [
    "I'm back again. Let's get started. Stay honest to the original code. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "\n",
    "\n",
    "Welcome back! \n",
    "\n",
    "You were so close yesterday! You've already implemented the `EncoderDecoder.__init__`. Now you just need three methods:\n",
    "\n",
    "1. **`encode(self, src, src_mask)`** - embed source, pass through encoder\n",
    "2. **`decode(self, memory, src_mask, tgt, tgt_mask)`** - embed target, pass through decoder\n",
    "3. **`forward(self, src, tgt, src_mask, tgt_mask)`** - call encode, then decode\n",
    "\n",
    "Let's start with `encode`. It should:\n",
    "- Apply `self.src_embed` to `src`\n",
    "- Pass the result through `self.encoder` with the mask\n",
    "\n",
    "Try writing it:\n",
    "\n",
    "```python\n",
    "def encode(self, src, src_mask):\n",
    "    # What goes here?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740bc972",
   "metadata": {
    "time_run": "2025-12-01T07:03:22.137065+00:00"
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(torch.nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super().__init__()\n",
    "        # Store all 5 components\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "    def encode(self, src, src_mask):\n",
    "        x = self.src_embed(src)\n",
    "        return self.encoder(x, src_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d2801",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Does this make sense? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `encode` method is exactly right! \n",
    "\n",
    "You've got:\n",
    "-  Apply source embeddings\n",
    "-  Pass through encoder with mask\n",
    "-  Return the encoder output (memory)\n",
    "\n",
    "Now try the `decode` method. It should:\n",
    "- Apply `self.tgt_embed` to `tgt`\n",
    "- Pass the result through `self.decoder` along with `memory`, `src_mask`, and `tgt_mask`\n",
    "\n",
    "Give it a try:\n",
    "\n",
    "```python\n",
    "def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "    # What goes here?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d1b4a",
   "metadata": {
    "time_run": "2025-12-01T07:05:38.527223+00:00"
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(torch.nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super().__init__()\n",
    "        # Store all 5 components\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "    def encode(self, src, src_mask):\n",
    "        x = self.src_embed(src)\n",
    "        return self.encoder(x, src_mask)\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        # What goes here?\n",
    "        x = self.tgt_embed(tgt)\n",
    "        return self.decoder(x, memory, src_mask, tgt_mask)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0974f544",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this cool? Stay loyal to the original code. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `decode` method is exactly right and matches the original code! \n",
    "\n",
    "You've got:\n",
    "-  Apply target embeddings\n",
    "-  Pass through decoder with all the right arguments (x, memory, src_mask, tgt_mask)\n",
    "\n",
    "Now the final method: `forward`. It should:\n",
    "- Call `encode` to get memory\n",
    "- Call `decode` with the memory\n",
    "- Return the decoder output\n",
    "\n",
    "Try writing it:\n",
    "\n",
    "```python\n",
    "def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "    # What goes here?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac36cc47",
   "metadata": {},
   "source": [
    "### Final Encoder Decoder Function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b731c519",
   "metadata": {
    "time_run": "2025-12-01T07:14:40.594193+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class EncoderDecoder(torch.nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super().__init__()\n",
    "        # Store all 5 components\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "    def encode(self, src, src_mask):\n",
    "        x = self.src_embed(src)\n",
    "        return self.encoder(x, src_mask)\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        # What goes here?\n",
    "        x = self.tgt_embed(tgt)\n",
    "        return self.decoder(x, memory, src_mask, tgt_mask)\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        # What goes here?\n",
    "        memory = self.encode(src, src_mask)\n",
    "        return self.decode(memory, src_mask, tgt, tgt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639aff78",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "done baby\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent! Your `EncoderDecoder` class is complete and correct! \n",
    "\n",
    "You've got:\n",
    "-  `encode` - processes source\n",
    "-  `decode` - processes target with encoder memory\n",
    "-  `forward` - ties them together\n",
    "\n",
    "This is the complete Transformer architecture! Let's test it to make sure everything works together:\n",
    "\n",
    "```python\n",
    "# You'll need to create all the components and test\n",
    "# Want me to help you write a test, or do you want to try?\n",
    "```\n",
    "\n",
    "But wait - looking at the original code, there's one more super useful thing: the **`make_model`** helper function that builds a complete transformer with all the right components.\n",
    "\n",
    "Do you want to:\n",
    "1. Test the EncoderDecoder as-is\n",
    "2. Implement the `make_model` helper function (makes it easy to create a full transformer)\n",
    "\n",
    "What would you prefer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf9a549",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Before moving on, let's make a unit test for this function, like we usually do, assuming we are in NB dev and the output function is already exported. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "```python\n",
    "#| test\n",
    "def test_encoder_decoder():\n",
    "    \"Test complete EncoderDecoder model\"\n",
    "    # Create all components\n",
    "    attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "    ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "    \n",
    "    encoder_layer = EncoderLayer(size=512, self_attn=copy.deepcopy(attn), \n",
    "                                  feed_forward=copy.deepcopy(ff), dropout=0.1)\n",
    "    decoder_layer = DecoderLayer(size=512, \n",
    "                                  self_attn=copy.deepcopy(attn),\n",
    "                                  src_attn=copy.deepcopy(attn),\n",
    "                                  feed_forward=copy.deepcopy(ff), dropout=0.1)\n",
    "    \n",
    "    encoder = Encoder(encoder_layer, N=2)\n",
    "    decoder = Decoder(decoder_layer, N=2)\n",
    "    \n",
    "    src_embed = torch.nn.Sequential(Embeddings(512, 1000), PositionalEncoding(512, 0.1))\n",
    "    tgt_embed = torch.nn.Sequential(Embeddings(512, 1000), PositionalEncoding(512, 0.1))\n",
    "    generator = Generator(512, 1000)\n",
    "    \n",
    "    model = EncoderDecoder(encoder, decoder, src_embed, tgt_embed, generator)\n",
    "    \n",
    "    # Test\n",
    "    src = torch.randint(0, 1000, (2, 10))\n",
    "    tgt = torch.randint(0, 1000, (2, 8))\n",
    "    output = model(src, tgt, src_mask=None, tgt_mask=None)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 8, 512])\n",
    "```\n",
    "\n",
    "Ready to move on to `make_model`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3818e1",
   "metadata": {},
   "source": [
    "#### Unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eddd49",
   "metadata": {
    "time_run": "2025-12-01T07:14:46.884587+00:00"
   },
   "outputs": [],
   "source": [
    "#| test\n",
    "def test_encoder_decoder():\n",
    "    \"Test complete EncoderDecoder model\"\n",
    "    # Create all components\n",
    "    attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
    "    ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
    "    \n",
    "    encoder_layer = EncoderLayer(size=512, self_attn=copy.deepcopy(attn), \n",
    "                                  feed_forward=copy.deepcopy(ff), dropout=0.1)\n",
    "    decoder_layer = DecoderLayer(size=512, \n",
    "                                  self_attn=copy.deepcopy(attn),\n",
    "                                  src_attn=copy.deepcopy(attn),\n",
    "                                  feed_forward=copy.deepcopy(ff), dropout=0.1)\n",
    "    \n",
    "    encoder = Encoder(encoder_layer, N=2)\n",
    "    decoder = Decoder(decoder_layer, N=2)\n",
    "    \n",
    "    src_embed = torch.nn.Sequential(Embeddings(512, 1000), PositionalEncoding(512, 0.1))\n",
    "    tgt_embed = torch.nn.Sequential(Embeddings(512, 1000), PositionalEncoding(512, 0.1))\n",
    "    generator = Generator(512, 1000)\n",
    "    \n",
    "    model = EncoderDecoder(encoder, decoder, src_embed, tgt_embed, generator)\n",
    "    \n",
    "    # Test\n",
    "    src = torch.randint(0, 1000, (2, 10))\n",
    "    tgt = torch.randint(0, 1000, (2, 8))\n",
    "    output = model(src, tgt, src_mask=None, tgt_mask=None)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 8, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b1bd63",
   "metadata": {
    "time_run": "2025-12-01T07:15:12.915895+00:00"
   },
   "outputs": [],
   "source": [
    "test_encoder_decoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358bf686",
   "metadata": {},
   "source": [
    "## Make Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd4d8cf",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Okay, let's go further. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Awesome!  Your complete Transformer is working!\n",
    "\n",
    "**What's next: `make_model` helper function**\n",
    "\n",
    "Looking at the original code, `make_model` is a convenience function that builds a complete transformer from just hyperparameters. Instead of manually creating all components like in your test, you can just call:\n",
    "\n",
    "```python\n",
    "model = make_model(src_vocab=11, tgt_vocab=11, N=6)\n",
    "```\n",
    "\n",
    "And it creates everything for you!\n",
    "\n",
    "**What does `make_model` need to do?**\n",
    "\n",
    "Looking at the original code, it takes these parameters:\n",
    "- `src_vocab`, `tgt_vocab` - vocabulary sizes\n",
    "- `N` - number of layers (default 6)\n",
    "- `d_model` - model dimension (default 512)\n",
    "- `d_ff` - feed-forward dimension (default 2048)\n",
    "- `h` - number of attention heads (default 8)\n",
    "- `dropout` - dropout rate (default 0.1)\n",
    "\n",
    "Then it creates all the components and returns an `EncoderDecoder` model.\n",
    "\n",
    "Want to try implementing it, or should I break it down into smaller steps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95cf0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(src_vocab=11, tgt_vocab=11, N=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee79456b",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I'm guessing this function just creates an encoder-decoder layer, Along with the inputs which are needed for the encoder-decoder. Am I correct? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Exactly right! \n",
    "\n",
    "`make_model` is just a convenience factory function that:\n",
    "1. Creates all the components (attention modules, feed-forward, embeddings, etc.)\n",
    "2. Assembles them into an `EncoderDecoder` model\n",
    "3. Initializes the parameters properly\n",
    "\n",
    "It saves you from writing all that boilerplate code every time you want to create a transformer.\n",
    "\n",
    "Looking at the original code, it also does one more important thing at the end: **Xavier initialization** of parameters for better training.\n",
    "\n",
    "Want to try implementing it? Start with the function signature:\n",
    "\n",
    "```python\n",
    "def make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    # Create components\n",
    "    # Assemble into EncoderDecoder\n",
    "    # Initialize parameters\n",
    "```\n",
    "\n",
    "What would you create first inside this function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71d79ab",
   "metadata": {
    "solveit_ai": true,
    "time_run": "2025-12-01T07:17:27.881735+00:00"
   },
   "source": [
    "This is actually a good exercise that brings all the components we built together. We need to know which order to build them first. All the way from low-level to high-level. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent insight! You're absolutely right - this is a great exercise in understanding the dependency hierarchy.\n",
    "\n",
    "Let's think through the order together. What components have **no dependencies** (the lowest level building blocks)?\n",
    "\n",
    "Start from the bottom - which components can be created first without needing anything else?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da58eef6",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "We start from Attention, then multi-header attention, then position-wise feed forward, then subconnection layer, then encoder layer, then decoder layer, then encoder, then decoder, then encoder-decoder both, and in between also we need clones. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great breakdown! You've got the dependency order mostly right! Let me refine it slightly:\n",
    "\n",
    "**Level 1 (no dependencies):**\n",
    "- `attention` function\n",
    "- `clones` function\n",
    "\n",
    "**Level 2 (uses Level 1):**\n",
    "- `MultiHeadedAttention` (uses attention)\n",
    "- `PositionwiseFeedForward`\n",
    "- `PositionalEncoding`\n",
    "- `Embeddings`\n",
    "\n",
    "**Level 3 (uses Level 2):**\n",
    "- `SublayerConnection`\n",
    "\n",
    "**Level 4 (uses Level 2 & 3):**\n",
    "- `EncoderLayer` (uses MultiHeadedAttention, PositionwiseFeedForward, SublayerConnection)\n",
    "- `DecoderLayer` (uses MultiHeadedAttention x2, PositionwiseFeedForward, SublayerConnection)\n",
    "\n",
    "**Level 5 (uses Level 4):**\n",
    "- `Encoder` (uses EncoderLayer, clones)\n",
    "- `Decoder` (uses DecoderLayer, clones)\n",
    "- `Generator`\n",
    "\n",
    "**Level 6 (final assembly):**\n",
    "- `EncoderDecoder` (uses Encoder, Decoder, embeddings+positional, Generator)\n",
    "\n",
    "So in `make_model`, what should you create first?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edada97a",
   "metadata": {
    "time_run": "2025-12-01T07:49:09.224929+00:00"
   },
   "outputs": [],
   "source": [
    "def make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    # Create components\n",
    "    # Level 1\n",
    "    # Attention and Clones functions already created. As they are not classes, no need to create instances.\n",
    "    # Level 2\n",
    "    multi_head_attention = MultiHeadedAttention(h, d_model, dropout)\n",
    "    feedforward_layer = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    positional_encoding = PositionalEncoding(d_model, dropout)\n",
    "    src_embedding_layer = Embeddings(d_model, src_vocab)\n",
    "    tgt_embeddings_layer = Embeddings(d_model, tgt_vocab)\n",
    "    # Level 3\n",
    "    sub_layer_connection = SublayerConnection(d_model, dropout)\n",
    "    # Level 4\n",
    "    encoder_layer = EncoderLayer(d_model, multi_head_attention, feedforward_layer, dropout)\n",
    "    decoder_layer = DecoderLayer(d_model, multi_head_attention, multi_head_attention, feedforward_layer, dropout)\n",
    "    # Assemble into EncoderDecoder\n",
    "    # Initialize parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b4fe7b",
   "metadata": {
    "solveit_ai": true,
    "use_thinking": true
   },
   "source": [
    "So far so good. I'm having a feeling I'm screwing it up because I should create different instances of attention and feed-forward layer for different things, or will the clone take care of it? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "\n",
    "\n",
    "Great instinct! You're absolutely right to be concerned!\n",
    "\n",
    "**The issue:** If you pass the same `multi_head_attention` instance to both encoder and decoder (and to both self_attn and src_attn in decoder), they'll all share the same weights. That's not what we want!\n",
    "\n",
    "**Looking at the original code**, they solve this with `copy.deepcopy`:\n",
    "\n",
    "```python\n",
    "c = copy.deepcopy\n",
    "```\n",
    "\n",
    "Then when creating layers, they use `c(attn)`, `c(ff)` to make copies.\n",
    "\n",
    "**Also:** You don't need to create `SublayerConnection` manually - remember it's already created inside `EncoderLayer` and `DecoderLayer`!\n",
    "\n",
    "**Key places needing separate copies:**\n",
    "- EncoderLayer needs: 1 attention, 1 feedforward\n",
    "- DecoderLayer needs: 2 attentions (self + src), 1 feedforward\n",
    "\n",
    "Can you update your code using `copy.deepcopy` where needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c75224",
   "metadata": {
    "time_run": "2025-12-01T08:21:54.708444+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    # Create components\n",
    "    # Level 1\n",
    "    # Attention and Clones functions already created. As they are not classes, no need to create instances.\n",
    "    # Level 2\n",
    "    multi_head_attentions = [copy.deepcopy(MultiHeadedAttention(h, d_model, dropout)) for _ in range(3)]\n",
    "    feedforward_layers = [copy.deepcopy(PositionwiseFeedForward(d_model, d_ff, dropout)) for _ in range(2)]\n",
    "    positional_encoding = [PositionalEncoding(d_model, dropout) for _ in range(2)]\n",
    "    src_embedding_layer = Embeddings(d_model, src_vocab)\n",
    "    tgt_embeddings_layer = Embeddings(d_model, tgt_vocab)\n",
    "    src_embed = torch.nn.Sequential([src_embedding_layer, positional_encoding[0]])\n",
    "    tgt_embed = torch.nn.Sequential([tgt_embeddings_layer, positional_encoding[1]])\n",
    "    # Level 3\n",
    "    # Sublayer\n",
    "    # Level 4\n",
    "    encoder_layer = EncoderLayer(d_model, multi_head_attentions[0], \n",
    "                                feedforward_layers[0], dropout)\n",
    "    decoder_layer = DecoderLayer(d_model, multi_head_attentions[1], \n",
    "                                multi_head_attentions[2], feedforward_layers[1], \n",
    "                                dropout)\n",
    "    # Level 5 \n",
    "    encoder = Encoder(encoder_layer, N)\n",
    "    decoder = Decoder(decoder_layer, N)\n",
    "    generator = Generator(d_model, vocab)\n",
    "    # Assemble into EncoderDecoder\n",
    "    return EncoderDecoder(encoder, decoder, src_embed, tgt_embed, generator) \n",
    "    # Initialize parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478a37ac",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Am I on the right path? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "You're very close! A few small issues to fix:\n",
    "\n",
    "1. **`torch.nn.Sequential` doesn't take a list** - it takes the modules directly as arguments:\n",
    "   ```python\n",
    "   src_embed = torch.nn.Sequential(src_embedding_layer, positional_encoding[0])\n",
    "   ```\n",
    "\n",
    "2. **`vocab` is undefined** in Generator - should be `tgt_vocab`:\n",
    "   ```python\n",
    "   generator = Generator(d_model, tgt_vocab)\n",
    "   ```\n",
    "\n",
    "3. **You don't need lists** for the positional encodings - they're already separate instances when you create them:\n",
    "   ```python\n",
    "   pos_enc_1 = PositionalEncoding(d_model, dropout)\n",
    "   pos_enc_2 = PositionalEncoding(d_model, dropout)\n",
    "   ```\n",
    "\n",
    "4. **After creating the model**, you need to add Xavier initialization (looking at the original code):\n",
    "   ```python\n",
    "   for p in model.parameters():\n",
    "       if p.dim() > 1:\n",
    "           nn.init.xavier_uniform_(p)\n",
    "   ```\n",
    "\n",
    "Can you fix these issues?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d60a4a4",
   "metadata": {},
   "source": [
    "### Final Make Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7144cb59",
   "metadata": {
    "time_run": "2025-12-01T08:30:49.359331+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    # Create components\n",
    "    # Level 1\n",
    "    # Attention and Clones functions already created. As they are not classes, no need to create instances.\n",
    "    # Level 2\n",
    "    multi_head_attentions = [copy.deepcopy(MultiHeadedAttention(h, d_model, dropout)) for _ in range(3)]\n",
    "    feedforward_layers = [copy.deepcopy(PositionwiseFeedForward(d_model, d_ff, dropout)) for _ in range(2)]\n",
    "    positional_encoding = [PositionalEncoding(d_model, dropout) for _ in range(2)]\n",
    "    src_embedding_layer = Embeddings(d_model, src_vocab)\n",
    "    tgt_embeddings_layer = Embeddings(d_model, tgt_vocab)\n",
    "    src_embed = torch.nn.Sequential(src_embedding_layer, positional_encoding[0])\n",
    "    tgt_embed = torch.nn.Sequential(tgt_embeddings_layer, positional_encoding[1])\n",
    "    # Level 3\n",
    "    # Sublayer\n",
    "    # Level 4\n",
    "    encoder_layer = EncoderLayer(d_model, multi_head_attentions[0], \n",
    "                                feedforward_layers[0], dropout)\n",
    "    decoder_layer = DecoderLayer(d_model, multi_head_attentions[1], \n",
    "                                multi_head_attentions[2], feedforward_layers[1], \n",
    "                                dropout)\n",
    "    # Level 5 \n",
    "    encoder = Encoder(encoder_layer, N)\n",
    "    decoder = Decoder(decoder_layer, N)\n",
    "    generator = Generator(d_model, tgt_vocab)\n",
    "    # Assemble into EncoderDecoder\n",
    "    encoder_decoder =  EncoderDecoder(encoder, decoder, src_embed, tgt_embed, generator) \n",
    "    # Initialize parameters\n",
    "    for p in encoder_decoder.parameters():\n",
    "        if p.dim() > 1:\n",
    "            torch.nn.init.xavier_uniform_(p)\n",
    "    return encoder_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a223f65",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this good? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `make_model` function is now correct and matches the original code! \n",
    "\n",
    "You've got:\n",
    "-  Creating separate copies of attention and feedforward modules\n",
    "-  Embeddings + positional encoding wrapped in Sequential\n",
    "-  Building encoder and decoder layers\n",
    "-  Assembling the complete model\n",
    "-  Xavier initialization for better training\n",
    "\n",
    "Let's test it:\n",
    "\n",
    "```python\n",
    "model = make_model(src_vocab=1000, tgt_vocab=1000, N=2)\n",
    "src = torch.randint(0, 1000, (2, 10))\n",
    "tgt = torch.randint(0, 1000, (2, 8))\n",
    "output = model(src, tgt, src_mask=None, tgt_mask=None)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 8, 512))\n",
    "```\n",
    "\n",
    "Run this to verify your complete Transformer works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca0fb6",
   "metadata": {
    "time_run": "2025-12-01T08:32:02.849531+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 8, 512])\n",
      "Expected: (2, 8, 512)\n"
     ]
    }
   ],
   "source": [
    "model = make_model(src_vocab=1000, tgt_vocab=1000, N=2)\n",
    "src = torch.randint(0, 1000, (2, 10))\n",
    "tgt = torch.randint(0, 1000, (2, 8))\n",
    "output = model(src, tgt, src_mask=None, tgt_mask=None)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Expected:\", (2, 8, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51daa6bb",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Bravo, assume you are using NBDEV, and the final function is already exported. Make an end-to-end test based on this. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "```python\n",
    "#| test\n",
    "def test_make_model_end_to_end():\n",
    "    \"Test complete Transformer with make_model\"\n",
    "    model = make_model(src_vocab=1000, tgt_vocab=1000, N=2, d_model=512, \n",
    "                       d_ff=2048, h=8, dropout=0.1)\n",
    "    \n",
    "    # Test forward pass\n",
    "    src = torch.randint(0, 1000, (2, 10))\n",
    "    tgt = torch.randint(0, 1000, (2, 8))\n",
    "    output = model(src, tgt, src_mask=None, tgt_mask=None)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 8, 512])\n",
    "    \n",
    "    # Test that parameters were initialized\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            # Xavier init should give reasonable values (not all zeros)\n",
    "            assert not torch.allclose(p, torch.zeros_like(p))\n",
    "    \n",
    "    # Test encode and decode separately\n",
    "    memory = model.encode(src, src_mask=None)\n",
    "    assert memory.shape == torch.Size([2, 10, 512])\n",
    "    \n",
    "    decoded = model.decode(memory, src_mask=None, tgt=tgt, tgt_mask=None)\n",
    "    assert decoded.shape == torch.Size([2, 8, 512])\n",
    "```\n",
    "\n",
    " **Congratulations! You've successfully implemented a complete Transformer from scratch!** This is a huge accomplishment! What would you like to do next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a62eeed",
   "metadata": {},
   "source": [
    "#### End-to-end test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf8fa9a",
   "metadata": {
    "time_run": "2025-12-01T08:32:51.968285+00:00"
   },
   "outputs": [],
   "source": [
    "#| test\n",
    "def test_make_model_end_to_end():\n",
    "    \"Test complete Transformer with make_model\"\n",
    "    model = make_model(src_vocab=1000, tgt_vocab=1000, N=2, d_model=512, \n",
    "                       d_ff=2048, h=8, dropout=0.1)\n",
    "    \n",
    "    # Test forward pass\n",
    "    src = torch.randint(0, 1000, (2, 10))\n",
    "    tgt = torch.randint(0, 1000, (2, 8))\n",
    "    output = model(src, tgt, src_mask=None, tgt_mask=None)\n",
    "    \n",
    "    assert output.shape == torch.Size([2, 8, 512])\n",
    "    \n",
    "    # Test that parameters were initialized\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            # Xavier init should give reasonable values (not all zeros)\n",
    "            assert not torch.allclose(p, torch.zeros_like(p))\n",
    "    \n",
    "    # Test encode and decode separately\n",
    "    memory = model.encode(src, src_mask=None)\n",
    "    assert memory.shape == torch.Size([2, 10, 512])\n",
    "    \n",
    "    decoded = model.decode(memory, src_mask=None, tgt=tgt, tgt_mask=None)\n",
    "    assert decoded.shape == torch.Size([2, 8, 512])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a849ae92",
   "metadata": {},
   "source": [
    "## Module Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92afcac",
   "metadata": {
    "time_run": "2025-12-01T11:10:12.584707+00:00"
   },
   "outputs": [],
   "source": [
    "@register_cell_magic\n",
    "def mm(line, cell):\n",
    "    escaped_cell = html.escape(cell)\n",
    "    display(HTML(f\"\"\"\n",
    "<div class=\"mermaid\">\n",
    "{escaped_cell}\n",
    "</div>\n",
    "<script type=\"module\">\n",
    "import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.1/+esm';\n",
    "mermaid.initialize({{ startOnLoad: true }});\n",
    "mermaid.run();\n",
    "</script>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689a462f",
   "metadata": {
    "time_run": "2025-12-01T09:51:57.124867+00:00"
   },
   "outputs": [],
   "source": [
    "# Wrap to describe it\n",
    "def tool_mermaid(graph:str # string representing the chart to be displayed\n",
    "    )->str:\n",
    "    '''Returns two blocks:\n",
    "    - html_graph: this one need to be added where you want to dispaly the chart\n",
    "    - html_run: this one need to be added at the end of the message and only \"once\" even if you generate multiple charts\n",
    "    The result should be returned inline with the response without any markdown codeblock.\n",
    "    ''' \n",
    "    html_graph,html_run = mm_html(graph)\n",
    "    return dict(html_graph=html_graph,html_run=html_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7b0c34",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I like that you created different levels for the abstractions. Can we create a mermaid diagram to show this? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Absolutely! A mermaid diagram would be perfect for visualizing the module hierarchy!\n",
    "\n",
    "Let me create a diagram showing the dependency levels:\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    subgraph \"Level 1: Core Functions\"\n",
    "        A[attention function]\n",
    "        B[clones function]\n",
    "    end\n",
    "    \n",
    "    subgraph \"Level 2: Basic Modules\"\n",
    "        C[MultiHeadedAttention]\n",
    "        D[PositionwiseFeedForward]\n",
    "        E[PositionalEncoding]\n",
    "        F[Embeddings]\n",
    "    end\n",
    "    \n",
    "    subgraph \"Level 3: Connection\"\n",
    "        G[SublayerConnection]\n",
    "    end\n",
    "    \n",
    "    subgraph \"Level 4: Layer Modules\"\n",
    "        H[EncoderLayer]\n",
    "        I[DecoderLayer]\n",
    "    end\n",
    "    \n",
    "    subgraph \"Level 5: Stacks\"\n",
    "        J[Encoder]\n",
    "        K[Decoder]\n",
    "        L[Generator]\n",
    "    end\n",
    "    \n",
    "    subgraph \"Level 6: Complete Model\"\n",
    "        M[EncoderDecoder]\n",
    "        N[make_model]\n",
    "    end\n",
    "    \n",
    "    A --> C\n",
    "    C --> H\n",
    "    C --> I\n",
    "    D --> H\n",
    "    D --> I\n",
    "    E --> N\n",
    "    F --> N\n",
    "    G --> H\n",
    "    G --> I\n",
    "    B --> J\n",
    "    B --> K\n",
    "    H --> J\n",
    "    I --> K\n",
    "    J --> M\n",
    "    K --> M\n",
    "    L --> M\n",
    "    M --> N\n",
    "```\n",
    "\n",
    "Would you like me to adjust the diagram to show more detail, or is this level of abstraction good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ab9081",
   "metadata": {
    "time_run": "2025-12-01T11:11:03.677807+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"mermaid\">\n",
       "graph TD\n",
       "    subgraph &quot;Level 1: Core Functions&quot;\n",
       "        A[attention function]\n",
       "        B[clones function]\n",
       "    end\n",
       "\n",
       "    subgraph &quot;Level 2: Basic Modules&quot;\n",
       "        C[MultiHeadedAttention]\n",
       "        D[PositionwiseFeedForward]\n",
       "        E[PositionalEncoding]\n",
       "        F[Embeddings]\n",
       "    end\n",
       "\n",
       "    subgraph &quot;Level 3: Connection&quot;\n",
       "        G[SublayerConnection]\n",
       "    end\n",
       "\n",
       "    subgraph &quot;Level 4: Layer Modules&quot;\n",
       "        H[EncoderLayer]\n",
       "        I[DecoderLayer]\n",
       "    end\n",
       "\n",
       "    subgraph &quot;Level 5: Stacks&quot;\n",
       "        J[Encoder]\n",
       "        K[Decoder]\n",
       "        L[Generator]\n",
       "    end\n",
       "\n",
       "    subgraph &quot;Level 6: Complete Model&quot;\n",
       "        M[EncoderDecoder]\n",
       "        N[make_model]\n",
       "    end\n",
       "\n",
       "    A --&gt; C\n",
       "    C --&gt; H\n",
       "    C --&gt; I\n",
       "    D --&gt; H\n",
       "    D --&gt; I\n",
       "    E --&gt; N\n",
       "    F --&gt; N\n",
       "    G --&gt; H\n",
       "    G --&gt; I\n",
       "    B --&gt; J\n",
       "    B --&gt; K\n",
       "    H --&gt; J\n",
       "    I --&gt; K\n",
       "    J --&gt; M\n",
       "    K --&gt; M\n",
       "    L --&gt; M\n",
       "    M --&gt; N\n",
       "\n",
       "</div>\n",
       "<script type=\"module\">\n",
       "import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.1/+esm';\n",
       "mermaid.initialize({ startOnLoad: true });\n",
       "mermaid.run();\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%mm\n",
    "graph TD\n",
    "    subgraph \"Level 1: Core Functions\"\n",
    "        A[attention function]\n",
    "        B[clones function]\n",
    "    end\n",
    "    \n",
    "    subgraph \"Level 2: Basic Modules\"\n",
    "        C[MultiHeadedAttention]\n",
    "        D[PositionwiseFeedForward]\n",
    "        E[PositionalEncoding]\n",
    "        F[Embeddings]\n",
    "    end\n",
    "    \n",
    "    subgraph \"Level 3: Connection\"\n",
    "        G[SublayerConnection]\n",
    "    end\n",
    "    \n",
    "    subgraph \"Level 4: Layer Modules\"\n",
    "        H[EncoderLayer]\n",
    "        I[DecoderLayer]\n",
    "    end\n",
    "    \n",
    "    subgraph \"Level 5: Stacks\"\n",
    "        J[Encoder]\n",
    "        K[Decoder]\n",
    "        L[Generator]\n",
    "    end\n",
    "    \n",
    "    subgraph \"Level 6: Complete Model\"\n",
    "        M[EncoderDecoder]\n",
    "        N[make_model]\n",
    "    end\n",
    "    \n",
    "    A --> C\n",
    "    C --> H\n",
    "    C --> I\n",
    "    D --> H\n",
    "    D --> I\n",
    "    E --> N\n",
    "    F --> N\n",
    "    G --> H\n",
    "    G --> I\n",
    "    B --> J\n",
    "    B --> K\n",
    "    H --> J\n",
    "    I --> K\n",
    "    J --> M\n",
    "    K --> M\n",
    "    L --> M\n",
    "    M --> N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d6c686",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Fantastic, now what can I do? Have we finished the original code? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    " **Amazing work!** You've implemented the **core Transformer architecture** from scratch!\n",
    "\n",
    "**What you've completed:**\n",
    "-  All the fundamental building blocks\n",
    "-  Complete Encoder and Decoder\n",
    "-  Full EncoderDecoder model\n",
    "-  Convenience `make_model` function\n",
    "\n",
    "**What's in the original code that we haven't covered:**\n",
    "\n",
    "1. **Training infrastructure:**\n",
    "   - Batch class (for handling batches with masks)\n",
    "   - Loss computation\n",
    "   - Learning rate scheduler (the warmup schedule)\n",
    "   - Label smoothing\n",
    "   - Training loop\n",
    "\n",
    "2. **Inference:**\n",
    "   - Greedy decoding\n",
    "   - Beam search (mentioned but not fully implemented)\n",
    "\n",
    "3. **Real-world example:**\n",
    "   - Data loading (Multi30k dataset)\n",
    "   - Tokenization with spacy\n",
    "   - Actual training on translation task\n",
    "\n",
    "**What would you like to do next?**\n",
    "\n",
    "1. Implement the training infrastructure (batching, loss, optimizer schedule)?\n",
    "2. Implement inference/decoding methods?\n",
    "3. Try a simple training example (like the copy task)?\n",
    "4. Move on to something else?\n",
    "\n",
    "What interests you most?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce893688",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "What do you suggest? I think training my own LLM and seeing it work would be a magical moment. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "That's an amazing goal! Seeing your own model learn and generate text is truly magical! \n",
    "\n",
    "However, let me set realistic expectations:\n",
    "\n",
    "**Full LLM training** (like GPT) requires:\n",
    "- Massive datasets (billions of tokens)\n",
    "- Huge computational resources (multiple GPUs, weeks of training)\n",
    "- Significant memory and storage\n",
    "\n",
    "**But you have great options to see the magic:**\n",
    "\n",
    "1. **Copy task** (quickest win, ~5 minutes)\n",
    "   - Train the model to memorize a sequence\n",
    "   - See it learn from random to perfect in real-time\n",
    "   - Great for verifying everything works\n",
    "\n",
    "2. **Small translation task** (realistic, ~30-60 minutes)\n",
    "   - Use a tiny dataset (like Multi30k: GermanEnglish)\n",
    "   - Train on your laptop/Colab\n",
    "   - Actually see translation working!\n",
    "\n",
    "3. **Character-level language model** (middle ground)\n",
    "   - Train on a small text corpus\n",
    "   - Generate text character by character\n",
    "   - Can run on modest hardware\n",
    "\n",
    "**My suggestion:** Start with #1 (copy task) to see the magic quickly, then move to #2 if you want something more impressive.\n",
    "\n",
    "Which sounds most exciting to you?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f94445",
   "metadata": {
    "solveit_ai": true,
    "use_thinking": true
   },
   "source": [
    "What does the original code do? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "\n",
    "\n",
    "Great question! Looking at the original code you provided, it includes:\n",
    "\n",
    "**1. Simple Copy Task (A First Example)**\n",
    "- Synthetic data: generates random sequences\n",
    "- Trains the model to copy input to output (e.g., input [1,2,3,4]  output [1,2,3,4])\n",
    "- Quick to train, proves the model works\n",
    "- Uses greedy decoding for inference\n",
    "\n",
    "**2. Real-World Translation (Part 3)**\n",
    "- Multi30k GermanEnglish dataset\n",
    "- Full training pipeline with:\n",
    "  - Data loading and tokenization (spacy)\n",
    "  - Batching with masks\n",
    "  - Label smoothing loss\n",
    "  - Adam optimizer with warmup schedule\n",
    "  - Multi-GPU support\n",
    "\n",
    "**Supporting infrastructure:**\n",
    "- `Batch` class - handles src/tgt with masks\n",
    "- `run_epoch` - training loop\n",
    "- `LabelSmoothing` - regularization technique\n",
    "- Learning rate scheduler with warmup\n",
    "- `greedy_decode` - simple inference\n",
    "\n",
    "Would you like to start with the **copy task** (simpler, faster, proves your model works) or jump to building the training infrastructure?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a039f7",
   "metadata": {},
   "source": [
    "## Copy Code Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fbb5b0",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "lets go\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Awesome! Let's start with the **copy task** - it's the quickest way to see your Transformer learn something magical! \n",
    "\n",
    "Before we begin coding, let me explain what we'll build:\n",
    "\n",
    "**The Copy Task:**\n",
    "- Input: Random sequence like `[1, 2, 3, 4, 5]`\n",
    "- Target: Same sequence `[1, 2, 3, 4, 5]`\n",
    "- Goal: Train the model to copy the input to output\n",
    "\n",
    "**What we need to implement (in order):**\n",
    "1. **Synthetic data generator** - creates random sequences\n",
    "2. **Batch class** - handles masking\n",
    "3. **Loss computation** - measures how well the model does\n",
    "4. **Training loop** - actually trains the model\n",
    "5. **Greedy decoding** - generates predictions\n",
    "\n",
    "**First question:** Do you want to implement each piece yourself (I'll guide you), or would you like me to provide the code so we can see it working quickly and then understand how it works?\n",
    "\n",
    "Which approach would you prefer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b6d1cd",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Isn't looking at the code cheating? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "You're absolutely right! Looking at the code would be cheating yourself out of the learning experience! \n",
    "\n",
    "You've come this far implementing the Transformer from scratch - let's keep that momentum going!\n",
    "\n",
    "**Let's start with the first component: Synthetic Data Generator**\n",
    "\n",
    "For the copy task, we need a function that generates random batches of sequences. It should:\n",
    "- Create random sequences of integers (e.g., from vocabulary of size V)\n",
    "- Make both source and target the same (since we're copying)\n",
    "- Add a start token at the beginning\n",
    "- Return batches\n",
    "\n",
    "Looking at what you need, the function signature would be:\n",
    "```python\n",
    "def data_gen(V, batch_size, nbatches):\n",
    "    # Generate nbatches of random data\n",
    "    # Each batch has batch_size sequences\n",
    "    # Each sequence has random integers from 1 to V-1\n",
    "```\n",
    "\n",
    "What do you think you need to do inside this function? Try describing the steps first before coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75f6b73",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Ok Vara, I am kind of clueless. You need to give me some helper functions, some helper structures. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "No problem! Let me break down what you need step by step.\n",
    "\n",
    "**For the copy task, you need 4 main pieces:**\n",
    "\n",
    "1. **Batch class** - wraps source/target data and creates masks\n",
    "2. **data_gen function** - generates random training data\n",
    "3. **SimpleLossCompute** - calculates loss during training\n",
    "4. **run_epoch function** - the training loop\n",
    "\n",
    "Let's start with the **Batch class** since everything else depends on it.\n",
    "\n",
    "**What does Batch need to do?**\n",
    "- Store source (`src`) and target (`tgt`) sequences\n",
    "- Create `src_mask` (padding mask for source)\n",
    "- Create `tgt_mask` (causal mask for target - prevents looking ahead)\n",
    "- Count number of tokens (`ntokens`)\n",
    "\n",
    "Try implementing the `__init__` method. You'll need:\n",
    "- Take `src`, `tgt`, and `pad` (padding token ID) as inputs\n",
    "- Create masks using operations you've seen before\n",
    "\n",
    "Want to give it a try, or should I give you more hints about what each mask should look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5b2faf",
   "metadata": {
    "time_run": "2025-12-01T09:45:38.624720+00:00"
   },
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    def __init__(src, tgt, pad=2):\n",
    "        src_mask = src!=pad\n",
    "        tgt_mask = tgt==uppertriangle\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac6d81f",
   "metadata": {
    "solveit_ai": true,
    "use_thinking": true
   },
   "source": [
    "Okay, I'm clueless. This is what I've done so far. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "\n",
    "\n",
    "You're on the right track! Let me clarify a few things:\n",
    "\n",
    "**First, small fix:** You need `self` in the method:\n",
    "```python\n",
    "def __init__(self, src, tgt, pad=2):\n",
    "```\n",
    "\n",
    "**Your intuitions are correct!**\n",
    "\n",
    "1. **src_mask** - You're right, it's about padding! But we need to keep the non-pad tokens, so it should create a boolean mask where True = real token, False = padding. Also, we need to `unsqueeze` to add a dimension.\n",
    "\n",
    "2. **tgt_mask** - Yes, it involves the upper triangle! You want to use `torch.triu` (upper triangle) to block future positions. But there's a helper function we created earlier - remember `subsequent_mask`? \n",
    "\n",
    "Wait... we didn't implement `subsequent_mask`! Let's do that first.\n",
    "\n",
    "**subsequent_mask** creates a triangular mask like:\n",
    "```\n",
    "[[1, 0, 0],\n",
    " [1, 1, 0],\n",
    " [1, 1, 1]]\n",
    "```\n",
    "\n",
    "This lets position 0 see only itself, position 1 see 0 and 1, etc.\n",
    "\n",
    "Can you try implementing `subsequent_mask(size)` that returns a lower triangular matrix of ones?\n",
    "\n",
    "Hint: Look at `torch.triu` or `torch.tril`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f6258",
   "metadata": {
    "solveit_ai": true,
    "time_run": "2025-12-01T09:45:38.624720+00:00"
   },
   "source": [
    "Why we need to unsqueeze. \n",
    "        \n",
    "\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question! Let me explain the dimensions.\n",
    "\n",
    "**Without unsqueeze:**\n",
    "- `src` has shape: `(batch_size, seq_len)`\n",
    "- `src != pad` gives: `(batch_size, seq_len)` - a 2D mask\n",
    "\n",
    "**But in attention:**\n",
    "- We compute scores with shape: `(batch_size, num_heads, seq_len, seq_len)`\n",
    "- The mask needs to broadcast across the `num_heads` and `seq_len` dimensions\n",
    "\n",
    "**With unsqueeze:**\n",
    "- We add a dimension: `(batch_size, 1, seq_len)`\n",
    "- This broadcasts correctly when applied to attention scores\n",
    "\n",
    "Think of it like this: the `1` in the middle says \"apply this same mask to all attention heads.\"\n",
    "\n",
    "Does this clarify why we need the extra dimension?\n",
    "\n",
    "Now, want to try implementing `subsequent_mask(size)` first, or should we continue with the Batch class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878e3f8",
   "metadata": {
    "time_run": "2025-12-01T10:00:52.560122+00:00"
   },
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    def __init__(src, tgt, pad=2):\n",
    "        src_mask = src!=pad\n",
    "        src_mask.unsqueeze(1)\n",
    "        tgt_mask = torch.ones([tgt.size(0), tgt.size(1)]).triu()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815c3a65",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I still think I'm not correct, but I think I'm getting warmer. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "You're definitely getting warmer! A few things to fix:\n",
    "\n",
    "1. **Missing `self`** - you need `self` as the first parameter and use it to store attributes:\n",
    "   ```python\n",
    "   def __init__(self, src, tgt, pad=2):\n",
    "       self.src = src\n",
    "   ```\n",
    "\n",
    "2. **`unsqueeze` doesn't modify in place** - you need to assign it:\n",
    "   ```python\n",
    "   self.src_mask = (src != pad).unsqueeze(-2)\n",
    "   ```\n",
    "   The `-2` adds a dimension at position -2 (second from last).\n",
    "\n",
    "3. **`triu` creates upper triangle, but we want lower!** - Use `torch.tril` for lower triangle, OR use `torch.triu` with `diagonal=1` and then invert it. Actually, there's a cleaner way - remember we saw `subsequent_mask` in the original code?\n",
    "\n",
    "4. **Target mask needs to combine two things:**\n",
    "   - Padding mask (like src)\n",
    "   - Causal mask (subsequent_mask)\n",
    "\n",
    "Before fixing all this, let's first implement the `subsequent_mask` helper function. Can you write a function that returns a lower triangular matrix of True values with shape `(1, size, size)`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6888ddc1",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Actually, I have not read the original code. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "You're absolutely right - I apologize! You've been implementing everything from scratch without looking at the original code, and I should respect that.\n",
    "\n",
    "Let me guide you without referencing the original code.\n",
    "\n",
    "**Let's implement `subsequent_mask` from first principles:**\n",
    "\n",
    "You need a function that creates a mask to prevent looking at future positions. For a sequence of length 3, it should look like:\n",
    "\n",
    "```\n",
    "Position 0 can see: [True,  False, False]  (only itself)\n",
    "Position 1 can see: [True,  True,  False]  (0 and 1)\n",
    "Position 2 can see: [True,  True,  True]   (0, 1, and 2)\n",
    "```\n",
    "\n",
    "This is a **lower triangular matrix** (ones below and on the diagonal, zeros above).\n",
    "\n",
    "Try writing:\n",
    "```python\n",
    "def subsequent_mask(size):\n",
    "    # Create a lower triangular matrix\n",
    "    # Return shape should be (1, size, size)\n",
    "```\n",
    "\n",
    "Hint: `torch.tril(torch.ones(size, size))` creates a lower triangular matrix. Then you need to add the batch dimension and convert to boolean.\n",
    "\n",
    "Give it a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee1c339",
   "metadata": {},
   "source": [
    "### Final subsequent mask function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cc4765",
   "metadata": {
    "time_run": "2025-12-01T10:16:01.684312+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def subsequent_mask(size):\n",
    "    # Create a lower triangular matrix\n",
    "    lower_t = torch.ones([size, size]).tril().bool()\n",
    "    lower_t = lower_t.unsqueeze(0)\n",
    "    # Return shape should be (1, size, size)\n",
    "    return lower_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910ac76",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this good? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `subsequent_mask` function is exactly right! \n",
    "\n",
    "You've got:\n",
    "-  Lower triangular matrix with `tril()`\n",
    "-  Convert to boolean\n",
    "-  Add batch dimension with `unsqueeze(0)`\n",
    "-  Returns shape `(1, size, size)`\n",
    "\n",
    "Now let's go back to the **Batch class**. You need to:\n",
    "\n",
    "1. Store `self.src` and create `self.src_mask`\n",
    "2. For the target, you need to:\n",
    "   - Store `self.tgt` (but shift it - remove last token)\n",
    "   - Store `self.tgt_y` (the labels - remove first token)\n",
    "   - Create `self.tgt_mask` combining padding mask AND subsequent_mask\n",
    "   - Count `self.ntokens` (number of non-padding tokens in target)\n",
    "\n",
    "Try implementing just the `__init__` signature and storing src/src_mask first:\n",
    "\n",
    "```python\n",
    "class Batch:\n",
    "    def __init__(self, src, tgt=None, pad=2):\n",
    "        self.src = src\n",
    "        self.src_mask = # what goes here?\n",
    "```\n",
    "\n",
    "What should `src_mask` be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e2cfa3",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "What exactly are you talking about? What is TGT and TGT_why? And why aren't we unsqueezing the masks? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great questions! Let me clarify:\n",
    "\n",
    "**Why shift the target?**\n",
    "\n",
    "During training, the decoder needs:\n",
    "- **Input (tgt)**: What it's seen so far: `[<start>, word1, word2]`\n",
    "- **Label (tgt_y)**: What it should predict next: `[word1, word2, word3]`\n",
    "\n",
    "So if your full target is `[<start>, word1, word2, word3]`:\n",
    "- `tgt` = `[<start>, word1, word2]` (everything except last)\n",
    "- `tgt_y` = `[word1, word2, word3]` (everything except first)\n",
    "\n",
    "This way, when the model sees `<start>`, it should predict `word1`, etc.\n",
    "\n",
    "**About unsqueezing:**\n",
    "\n",
    "You're right to question this! For `src_mask`, we DO need to unsqueeze:\n",
    "```python\n",
    "self.src_mask = (src != pad).unsqueeze(-2)\n",
    "```\n",
    "\n",
    "This makes it shape `(batch, 1, seq_len)` which broadcasts correctly.\n",
    "\n",
    "**Let's simplify - just focus on src first:**\n",
    "\n",
    "```python\n",
    "class Batch:\n",
    "    def __init__(self, src, tgt=None, pad=2):\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "```\n",
    "\n",
    "Does this part make sense now? Once you're comfortable, we'll add the target handling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bff53d",
   "metadata": {
    "solveit_ai": true,
    "time_run": "2025-12-01T10:15:13.724149+00:00"
   },
   "source": [
    "Yes, let's move on. \n",
    "\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! Now let's add the target handling.\n",
    "\n",
    "**When `tgt` is provided, you need to:**\n",
    "\n",
    "1. **Shift the target:**\n",
    "   - `self.tgt = tgt[:, :-1]` (all but last token - this is the decoder input)\n",
    "   - `self.tgt_y = tgt[:, 1:]` (all but first token - these are the labels)\n",
    "\n",
    "2. **Create tgt_mask** that combines:\n",
    "   - Padding mask: `(self.tgt != pad)`\n",
    "   - Subsequent mask: `subsequent_mask(self.tgt.size(-1))`\n",
    "   - Combine them with `&` (logical AND)\n",
    "\n",
    "3. **Count tokens:**\n",
    "   - `self.ntokens = (self.tgt_y != pad).sum()`\n",
    "\n",
    "Try adding the `if tgt is not None:` block to handle these. What would you write?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bed850",
   "metadata": {
    "time_run": "2025-12-01T10:22:03.127004+00:00"
   },
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    def __init__(self, src, tgt=None, pad=2):\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        if tgt is not None:\n",
    "                self.tgt = tgt[:, :-1]\n",
    "                self.tgt_y = tgt[:,1:]\n",
    "                self.pad_tgt_mask = (self.tgt!=pad)\n",
    "                self.subseq_tgt_mask = subsequent_mask(tgt.size(1))\n",
    "                self.tgt_mask = self.pad_tgt_mask & self.subseq_tgt_mask\n",
    "                self.ntokens = (self.tgt_y!=pad).sum()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223fe1f1",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent work! Your Batch class is almost perfect! Just a couple of small fixes:\n",
    "\n",
    "1. **`subsequent_mask` size:** You're using `tgt.size(1)` but you should use `self.tgt.size(1)` since you've already sliced it (removed last token)\n",
    "\n",
    "2. **Unsqueeze pad_tgt_mask:** The padding mask needs to match dimensions with subsequent_mask for broadcasting:\n",
    "   ```python\n",
    "   self.pad_tgt_mask = (self.tgt != pad).unsqueeze(-2)\n",
    "   ```\n",
    "\n",
    "Those are the only changes needed! Want to fix these and then we can test the Batch class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded08260",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "You're doing great! Just make those two small fixes:\n",
    "\n",
    "1. Change `tgt.size(1)` to `self.tgt.size(1)` \n",
    "2. Add `.unsqueeze(-2)` to the padding mask\n",
    "\n",
    "Once you update those, your Batch class will be complete! Want to give it a try?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840e8bc8",
   "metadata": {},
   "source": [
    "### Final Batch Class for copy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f746b5b",
   "metadata": {
    "time_run": "2025-12-01T10:23:20.700343+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class Batch:\n",
    "    def __init__(self, src, tgt=None, pad=2):\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        if tgt is not None:\n",
    "                self.tgt = tgt[:, :-1]\n",
    "                self.tgt_y = tgt[:,1:]\n",
    "                self.pad_tgt_mask = (self.tgt!=pad).unsqueeze(-2)\n",
    "                self.subseq_tgt_mask = subsequent_mask(self.tgt.size(1))\n",
    "                self.tgt_mask = self.pad_tgt_mask & self.subseq_tgt_mask\n",
    "                self.ntokens = (self.tgt_y!=pad).sum()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3c0d4b",
   "metadata": {
    "solveit_ai": true,
    "time_run": "2025-12-01T10:23:31.292647+00:00"
   },
   "source": [
    "fine?\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `Batch` class is now complete and correct! \n",
    "\n",
    "Let's test it quickly:\n",
    "\n",
    "```python\n",
    "src = torch.LongTensor([[1, 2, 3, 4, 0, 0]])  # 0 = padding\n",
    "tgt = torch.LongTensor([[1, 2, 3, 4, 5, 0]])\n",
    "batch = Batch(src, tgt, pad=0)\n",
    "\n",
    "print(\"src_mask shape:\", batch.src_mask.shape)\n",
    "print(\"tgt_mask shape:\", batch.tgt_mask.shape)\n",
    "print(\"ntokens:\", batch.ntokens)\n",
    "```\n",
    "\n",
    "Try running this to verify it works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a667c459",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "can we also print the mask and src tgt for demo?\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Absolutely! Let's see everything:\n",
    "\n",
    "```python\n",
    "src = torch.LongTensor([[1, 2, 3, 4, 0, 0]])  # 0 = padding\n",
    "tgt = torch.LongTensor([[1, 2, 3, 4, 5, 0]])\n",
    "batch = Batch(src, tgt, pad=0)\n",
    "\n",
    "print(\"Source:\", batch.src)\n",
    "print(\"Source mask:\", batch.src_mask)\n",
    "print(\"\\nTarget input:\", batch.tgt)\n",
    "print(\"Target labels:\", batch.tgt_y)\n",
    "print(\"\\nTarget mask shape:\", batch.tgt_mask.shape)\n",
    "print(\"Target mask:\\n\", batch.tgt_mask)\n",
    "print(\"\\nNumber of tokens:\", batch.ntokens.item())\n",
    "```\n",
    "\n",
    "Run this to see how the shifting works and what the masks look like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a0ef03",
   "metadata": {
    "time_run": "2025-12-01T10:28:29.341230+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: tensor([[1, 2, 3, 4, 0, 0]])\n",
      "Source mask: tensor([[[ True,  True,  True,  True, False, False]]])\n",
      "\n",
      "Target input: tensor([[1, 2, 3, 4, 5]])\n",
      "Target labels: tensor([[2, 3, 4, 5, 0]])\n",
      "\n",
      "Target mask shape: torch.Size([1, 5, 5])\n",
      "Target mask:\n",
      " tensor([[[ True, False, False, False, False],\n",
      "         [ True,  True, False, False, False],\n",
      "         [ True,  True,  True, False, False],\n",
      "         [ True,  True,  True,  True, False],\n",
      "         [ True,  True,  True,  True,  True]]])\n",
      "\n",
      "Number of tokens: 4\n"
     ]
    }
   ],
   "source": [
    "src = torch.LongTensor([[1, 2, 3, 4, 0, 0]])  # 0 = padding\n",
    "tgt = torch.LongTensor([[1, 2, 3, 4, 5, 0]])\n",
    "batch = Batch(src, tgt, pad=0)\n",
    "\n",
    "print(\"Source:\", batch.src)\n",
    "print(\"Source mask:\", batch.src_mask)\n",
    "print(\"\\nTarget input:\", batch.tgt)\n",
    "print(\"Target labels:\", batch.tgt_y)\n",
    "print(\"\\nTarget mask shape:\", batch.tgt_mask.shape)\n",
    "print(\"Target mask:\\n\", batch.tgt_mask)\n",
    "print(\"\\nNumber of tokens:\", batch.ntokens.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72720c29",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Assuming we are using NBDEV and we already outputted the function, create a comprehensive unit test for this. \n",
    "\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "```python\n",
    "#| test\n",
    "def test_batch_class():\n",
    "    \"Test Batch class with masking and shifting\"\n",
    "    # Test with padding\n",
    "    src = torch.LongTensor([[1, 2, 3, 4, 0, 0]])  # 0 = padding\n",
    "    tgt = torch.LongTensor([[1, 2, 3, 4, 5, 0]])\n",
    "    batch = Batch(src, tgt, pad=0)\n",
    "    \n",
    "    # Check source\n",
    "    assert batch.src.shape == torch.Size([1, 6])\n",
    "    assert batch.src_mask.shape == torch.Size([1, 1, 6])\n",
    "    assert batch.src_mask[0, 0, :4].all()  # First 4 are True\n",
    "    assert not batch.src_mask[0, 0, 4:].any()  # Last 2 are False\n",
    "    \n",
    "    # Check target shifting\n",
    "    assert batch.tgt.shape == torch.Size([1, 5])\n",
    "    assert batch.tgt_y.shape == torch.Size([1, 5])\n",
    "    assert torch.equal(batch.tgt[0], torch.LongTensor([1, 2, 3, 4, 5]))\n",
    "    assert torch.equal(batch.tgt_y[0], torch.LongTensor([2, 3, 4, 5, 0]))\n",
    "    \n",
    "    # Check target mask is lower triangular\n",
    "    assert batch.tgt_mask.shape == torch.Size([1, 5, 5])\n",
    "    for i in range(5):\n",
    "        assert batch.tgt_mask[0, i, :i+1].all()  # Can see up to position i\n",
    "        if i < 4:\n",
    "            assert not batch.tgt_mask[0, i, i+1:].any()  # Cannot see future\n",
    "    \n",
    "    # Check token count (excludes padding)\n",
    "    assert batch.ntokens.item() == 4  # 2,3,4,5 (not the final 0)\n",
    "    \n",
    "    # Test without target\n",
    "    batch_no_tgt = Batch(src, tgt=None, pad=0)\n",
    "    assert batch_no_tgt.src_mask.shape == torch.Size([1, 1, 6])\n",
    "```\n",
    "\n",
    "Great! Now that Batch is done, ready to move on to the data generator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06406bd7",
   "metadata": {
    "time_run": "2025-12-01T10:31:09.489853+00:00"
   },
   "outputs": [],
   "source": [
    "#| test\n",
    "def test_batch_class():\n",
    "    \"Test Batch class with masking and shifting\"\n",
    "    # Test with padding\n",
    "    src = torch.LongTensor([[1, 2, 3, 4, 0, 0]])  # 0 = padding\n",
    "    tgt = torch.LongTensor([[1, 2, 3, 4, 5, 0]])\n",
    "    batch = Batch(src, tgt, pad=0)\n",
    "    \n",
    "    # Check source\n",
    "    assert batch.src.shape == torch.Size([1, 6])\n",
    "    assert batch.src_mask.shape == torch.Size([1, 1, 6])\n",
    "    assert batch.src_mask[0, 0, :4].all()  # First 4 are True\n",
    "    assert not batch.src_mask[0, 0, 4:].any()  # Last 2 are False\n",
    "    \n",
    "    # Check target shifting\n",
    "    assert batch.tgt.shape == torch.Size([1, 5])\n",
    "    assert batch.tgt_y.shape == torch.Size([1, 5])\n",
    "    assert torch.equal(batch.tgt[0], torch.LongTensor([1, 2, 3, 4, 5]))\n",
    "    assert torch.equal(batch.tgt_y[0], torch.LongTensor([2, 3, 4, 5, 0]))\n",
    "    \n",
    "    # Check target mask is lower triangular\n",
    "    assert batch.tgt_mask.shape == torch.Size([1, 5, 5])\n",
    "    for i in range(5):\n",
    "        assert batch.tgt_mask[0, i, :i+1].all()  # Can see up to position i\n",
    "        if i < 4:\n",
    "            assert not batch.tgt_mask[0, i, i+1:].any()  # Cannot see future\n",
    "    \n",
    "    # Check token count (excludes padding)\n",
    "    assert batch.ntokens.item() == 4  # 2,3,4,5 (not the final 0)\n",
    "    \n",
    "    # Test without target\n",
    "    batch_no_tgt = Batch(src, tgt=None, pad=0)\n",
    "    assert batch_no_tgt.src_mask.shape == torch.Size([1, 1, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce4898a",
   "metadata": {
    "time_run": "2025-12-01T10:31:21.916815+00:00"
   },
   "outputs": [],
   "source": [
    "test_batch_class()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef41378",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Moving on. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent! Now let's build the **data generator** for the copy task.\n",
    "\n",
    "**What does `data_gen` need to do?**\n",
    "\n",
    "Generate synthetic training data where the target is a copy of the source:\n",
    "- Create random sequences of integers from 1 to V-1 (vocabulary size)\n",
    "- Make sure token 0 is reserved (for padding/blank)\n",
    "- Token 1 is the start token\n",
    "- Both src and tgt should be identical (it's a copy task!)\n",
    "- Yield `nbatches` batches, each with `batch_size` sequences\n",
    "\n",
    "Try writing the function signature and thinking about the steps:\n",
    "\n",
    "```python\n",
    "def data_gen(V, batch_size, nbatches):\n",
    "    \"Generate random data for a src-tgt copy task\"\n",
    "    for i in range(nbatches):\n",
    "        # What do you need to create here?\n",
    "        # How do you generate random sequences?\n",
    "        # How do you make src and tgt?\n",
    "        # What do you yield?\n",
    "```\n",
    "\n",
    "What would be your approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e7c05b",
   "metadata": {
    "time_run": "2025-12-01T10:36:18.757227+00:00"
   },
   "outputs": [],
   "source": [
    "def data_gen(V, batch_size, nbatches):\n",
    "    \"Generate random data for a src-tgt copy task\"\n",
    "    for i in range(nbatches):\n",
    "        # What do you need to create here?\n",
    "        # How do you generate random sequences?\n",
    "        # How do you make src and tgt?\n",
    "        # What do you yield?\n",
    "        random_int = np.random.randint(1, V, size=[batch_size, seq_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b0742f",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this a correct direction? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good start! You're on the right track using `np.random.randint`. A few things:\n",
    "\n",
    "1. **`seq_len` is not defined** - you need to decide on a sequence length. For the copy task, let's use a fixed length like 10.\n",
    "\n",
    "2. **Start token** - The first position should always be 1 (the start token), not random.\n",
    "\n",
    "3. **Convert to tensor** - You need to convert the numpy array to a PyTorch tensor.\n",
    "\n",
    "4. **Create src and tgt** - For the copy task, they should be the same!\n",
    "\n",
    "5. **Yield a Batch** - You need to wrap it in your `Batch` class and yield it.\n",
    "\n",
    "Try fixing step 1 and 2 first - how would you:\n",
    "- Set a fixed sequence length (say 10)?\n",
    "- Make sure the first token is always 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f1e195",
   "metadata": {},
   "source": [
    "### Final Data Gen Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632b0ed7",
   "metadata": {
    "time_run": "2025-12-01T10:39:09.914883+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def data_gen(V, batch_size, nbatches):\n",
    "    \"Generate random data for a src-tgt copy task\"\n",
    "    for i in range(nbatches):\n",
    "        # What do you need to create here?\n",
    "        # How do you generate random sequences?\n",
    "        # How do you make src and tgt?\n",
    "        # What do you yield?\n",
    "        random_int = np.random.randint(1, V, size=[batch_size, 10])\n",
    "        random_int[:,0] = 1\n",
    "        random_int = torch.tensor(random_int)\n",
    "        src = random_int\n",
    "        tgt = random_int\n",
    "        yield Batch(src, tgt, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61db9723",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Going well? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent! Your `data_gen` function is almost perfect! \n",
    "\n",
    "You've got:\n",
    "-  Random integers from 1 to V-1\n",
    "-  Fixed sequence length of 10\n",
    "-  First token set to 1 (start token)\n",
    "-  Convert to tensor\n",
    "-  src and tgt are the same (copy task!)\n",
    "-  Yield Batch objects\n",
    "\n",
    "One small thing: You're using `pad=0` in the Batch, which is correct!\n",
    "\n",
    "Let's test it:\n",
    "\n",
    "```python\n",
    "gen = data_gen(V=11, batch_size=2, nbatches=3)\n",
    "batch = next(gen)\n",
    "print(\"Source:\", batch.src)\n",
    "print(\"Target input:\", batch.tgt)\n",
    "print(\"Are they the same?\", torch.equal(batch.src, batch.tgt[:, :-1]))\n",
    "```\n",
    "\n",
    "Try running this to see your data generator in action! Does it make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a14cdf5",
   "metadata": {
    "time_run": "2025-12-01T10:39:54.759601+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: tensor([[ 1,  3,  3,  4, 10, 10,  2,  8,  3,  1],\n",
      "        [ 1,  3,  5,  4,  4,  2,  6,  4, 10,  7]])\n",
      "Target input: tensor([[ 1,  3,  3,  4, 10, 10,  2,  8,  3],\n",
      "        [ 1,  3,  5,  4,  4,  2,  6,  4, 10]])\n",
      "Are they the same? False\n"
     ]
    }
   ],
   "source": [
    "gen = data_gen(V=11, batch_size=2, nbatches=3)\n",
    "batch = next(gen)\n",
    "print(\"Source:\", batch.src)\n",
    "print(\"Target input:\", batch.tgt)\n",
    "print(\"Are they the same?\", torch.equal(batch.src, batch.tgt[:, :-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99354829",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this correct? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Almost! Let me explain what's happening:\n",
    "\n",
    "**Why is it False?**\n",
    "\n",
    "Remember in the `Batch` class, `self.tgt` is the target **input** (with last token removed). So:\n",
    "- `batch.src` has 10 tokens\n",
    "- `batch.tgt` has 9 tokens (last one removed)\n",
    "\n",
    "They should be almost the same, except `tgt` is one shorter!\n",
    "\n",
    "The correct comparison is:\n",
    "```python\n",
    "print(\"Are first 9 tokens the same?\", torch.equal(batch.src[:, :-1], batch.tgt))\n",
    "```\n",
    "\n",
    "But actually, your data generator is working perfectly! The \"False\" is expected because of the length difference.\n",
    "\n",
    "**Let's create a unit test for `data_gen`:**\n",
    "\n",
    "Want to write the test yourself, or should I help you structure it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ce60c8",
   "metadata": {
    "time_run": "2025-12-01T10:41:55.920645+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  3,  3,  4, 10, 10,  2,  8,  3,  1],\n",
       "        [ 1,  3,  5,  4,  4,  2,  6,  4, 10,  7]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(batch.src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44426227",
   "metadata": {
    "time_run": "2025-12-01T10:43:30.382440+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  3,  3,  4, 10, 10,  2,  8,  3],\n",
       "        [ 1,  3,  5,  4,  4,  2,  6,  4, 10]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(batch.src[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb2dd47",
   "metadata": {
    "time_run": "2025-12-01T10:42:11.717823+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  3,  3,  4, 10, 10,  2,  8,  3],\n",
       "        [ 1,  3,  5,  4,  4,  2,  6,  4, 10]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(batch.tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f64f2e3",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Why was torch equal false\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good catch! Looking at your output, `batch.src[:, :-1]` and `batch.tgt` are actually identical! So `torch.equal` should return `True`.\n",
    "\n",
    "Let me check your original comparison:\n",
    "```python\n",
    "torch.equal(batch.src, batch.tgt[:, :-1])\n",
    "```\n",
    "\n",
    "This compares:\n",
    "- `batch.src` (shape: 2, 10)\n",
    "- `batch.tgt[:, :-1]` (shape: 2, 8) - removes last token from already-shortened tgt\n",
    "\n",
    "That's why it was False - wrong shapes!\n",
    "\n",
    "The correct comparison is:\n",
    "```python\n",
    "torch.equal(batch.src[:, :-1], batch.tgt)\n",
    "```\n",
    "\n",
    "Try running this - it should return `True` now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ad1e5",
   "metadata": {
    "time_run": "2025-12-01T10:44:45.676003+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(batch.src, batch.tgt[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5b2f8c",
   "metadata": {
    "time_run": "2025-12-01T10:45:06.001213+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(batch.src[:, :-1], batch.tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeb3917",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "lol\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    " There we go! Now it makes sense!\n",
    "\n",
    "Your `data_gen` is working perfectly - the source and target are indeed the same (copy task), just with the shifting that happens in the `Batch` class.\n",
    "\n",
    "**Ready to move on?** \n",
    "\n",
    "Next up is **SimpleLossCompute** - this will calculate how well the model is doing during training. It needs to:\n",
    "- Take the model's predictions\n",
    "- Compare them to the true labels\n",
    "- Calculate the loss\n",
    "\n",
    "Want to give it a try, or should I explain what it needs to do first?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35056611",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "ok\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! Let's build **SimpleLossCompute**.\n",
    "\n",
    "**What does it need to do?**\n",
    "\n",
    "It's a class that computes the loss during training. It needs:\n",
    "\n",
    "**In `__init__`:**\n",
    "- Store a `generator` (your Generator class that outputs vocab predictions)\n",
    "- Store a `criterion` (the loss function, like CrossEntropyLoss)\n",
    "\n",
    "**In `__call__` (so you can use it like a function):**\n",
    "- Take model output `x`, true labels `y`, and `norm` (for normalization)\n",
    "- Pass `x` through the generator to get predictions\n",
    "- Calculate loss using the criterion\n",
    "- Return the loss\n",
    "\n",
    "Try writing the class structure:\n",
    "\n",
    "```python\n",
    "class SimpleLossCompute:\n",
    "    def __init__(self, generator, criterion):\n",
    "        # What do you store?\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        # What operations do you do?\n",
    "```\n",
    "\n",
    "What would you put in each method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bd6265",
   "metadata": {
    "time_run": "2025-12-01T10:49:38.881902+00:00"
   },
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    def __init__(self, generator, criterion):\n",
    "        # What do you store?\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        # What operations do you do?\n",
    "        pred = self.generator(x)\n",
    "        return self.criterion(y, pred, norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac3524d",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this correct? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "You're very close! A few things to adjust:\n",
    "\n",
    "1. **Generator output shape:** After `self.generator(x)`, you get shape `(batch, seq_len, vocab)`. But the criterion expects flattened tensors.\n",
    "\n",
    "2. **Criterion arguments:** Most PyTorch loss functions take `(predictions, targets)` not `(targets, predictions, norm)`. The `norm` is used to normalize the loss, not passed to the criterion.\n",
    "\n",
    "3. **Return value:** You need to return both the scalar loss (for logging) and the loss tensor (for backprop).\n",
    "\n",
    "Here's what you need to do:\n",
    "- Flatten `pred` to shape `(batch * seq_len, vocab)`\n",
    "- Flatten `y` to shape `(batch * seq_len)`\n",
    "- Calculate loss with `self.criterion(pred_flat, y_flat)`\n",
    "- Divide by `norm` to normalize\n",
    "- Return both the data value and the tensor\n",
    "\n",
    "Want to try fixing these issues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c77b16",
   "metadata": {
    "time_run": "2025-12-01T10:53:02.714285+00:00"
   },
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    def __init__(self, generator, criterion):\n",
    "        # What do you store?\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        # What operations do you do?\n",
    "        pred = self.generator(x)\n",
    "        pred_flat = pred.reshape(-1, vocab)\n",
    "        y_flat = y.reshape(-1,vocab)\n",
    "        return self.criterion(pred_flat, y_flat) / norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413242fe",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this better now? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Almost there! A few more fixes:\n",
    "\n",
    "1. **`vocab` is not defined** - you need to get the vocab size from the prediction tensor: `pred.size(-1)`\n",
    "\n",
    "2. **`y` shape is wrong** - `y` contains token IDs (integers), not one-hot vectors. So it should be flattened to 1D, not 2D:\n",
    "   ```python\n",
    "   y_flat = y.contiguous().view(-1)\n",
    "   ```\n",
    "\n",
    "3. **Return both values** - You need to return the loss data (for logging) AND the loss tensor (for backprop):\n",
    "   ```python\n",
    "   loss = self.criterion(pred_flat, y_flat) / norm\n",
    "   return loss.data * norm, loss\n",
    "   ```\n",
    "\n",
    "Can you make these three fixes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6a649a",
   "metadata": {},
   "source": [
    "### Final Simple Loss Compute Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c0765d",
   "metadata": {
    "time_run": "2025-12-01T10:55:35.670417+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class SimpleLossCompute:\n",
    "    def __init__(self, generator, criterion):\n",
    "        # What do you store?\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        # What operations do you do?\n",
    "        pred = self.generator(x)\n",
    "        vocab = pred.size(-1)\n",
    "        pred_flat = pred.reshape(-1, vocab)\n",
    "        y_flat = y.reshape(-1)\n",
    "        loss = self.criterion(pred_flat, y_flat) / norm\n",
    "        return loss.data * norm, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6c0d72",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "finally \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `SimpleLossCompute` is now complete and correct! \n",
    "\n",
    "You've got:\n",
    "-  Store generator and criterion\n",
    "-  Get vocab size from predictions\n",
    "-  Flatten predictions to (batch*seq_len, vocab)\n",
    "-  Flatten labels to (batch*seq_len)\n",
    "-  Calculate and normalize loss\n",
    "-  Return both scalar (for logging) and tensor (for backprop)\n",
    "\n",
    "Now you have all the pieces to actually **train** the model! \n",
    "\n",
    "The final piece is the **training loop** (`run_epoch`). This will:\n",
    "- Loop through batches\n",
    "- Run forward pass\n",
    "- Compute loss\n",
    "- Backpropagate\n",
    "- Update weights\n",
    "\n",
    "Want to tackle this next, or take a break?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaf1ab0",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "lets do \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Awesome! Let's build the **training loop** (`run_epoch`).\n",
    "\n",
    "**What does `run_epoch` need to do?**\n",
    "\n",
    "It trains (or evaluates) the model for one complete pass through the data. It needs:\n",
    "\n",
    "**Parameters:**\n",
    "- `data_iter` - iterator that yields batches\n",
    "- `model` - your transformer\n",
    "- `loss_compute` - your SimpleLossCompute\n",
    "- `optimizer` - updates weights\n",
    "- `scheduler` - adjusts learning rate\n",
    "- `mode` - \"train\" or \"eval\"\n",
    "\n",
    "**Steps in the loop:**\n",
    "1. Iterate through batches\n",
    "2. Run model forward pass\n",
    "3. Compute loss\n",
    "4. If training: backpropagate and update weights\n",
    "5. Track total loss and tokens\n",
    "\n",
    "Try writing the function signature and the basic loop structure:\n",
    "\n",
    "```python\n",
    "def run_epoch(data_iter, model, loss_compute, optimizer, scheduler, mode=\"train\"):\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(data_iter):\n",
    "        # What goes here?\n",
    "```\n",
    "\n",
    "What would be your first step inside the loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d31f55",
   "metadata": {
    "time_run": "2025-12-01T11:04:23.456122+00:00"
   },
   "outputs": [],
   "source": [
    "def run_epoch(data_iter, model, loss_compute, optimizer, scheduler, mode=\"train\"):\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(data_iter):\n",
    "        # What goes here?\n",
    "        pred = model(batch)\n",
    "        num_loss, tensor_loss = loss_compute(pred, batch.tgt, norm)\n",
    "        model.backward()\n",
    "        total_loss += num_loss \n",
    "        total_tokens += batch.ntokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087a8c29",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Does this make sense? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "You're on the right track! A few things to fix:\n",
    "\n",
    "1. **Model forward pass needs all arguments:**\n",
    "   ```python\n",
    "   out = model.forward(batch.src, batch.tgt, batch.src_mask, batch.tgt_mask)\n",
    "   ```\n",
    "\n",
    "2. **`norm` is not defined** - it should be `batch.ntokens` (normalize by number of tokens)\n",
    "\n",
    "3. **Backprop is on loss, not model:**\n",
    "   ```python\n",
    "   tensor_loss.backward()\n",
    "   ```\n",
    "\n",
    "4. **Only train if mode is \"train\"** - wrap backprop and optimizer steps in an if statement\n",
    "\n",
    "5. **Missing optimizer and scheduler steps** after backward\n",
    "\n",
    "Can you fix these issues? Focus on fixing #1 and #2 first!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e65d7c9",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Wait a minute, what the hell are the model.dot forward signature? Is it same as encoder-decoder? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent question! Yes, exactly right!\n",
    "\n",
    "The `model` is an instance of `EncoderDecoder`, so its `forward` signature is:\n",
    "\n",
    "```python\n",
    "def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "```\n",
    "\n",
    "So you need to call it with:\n",
    "```python\n",
    "out = model.forward(batch.src, batch.tgt, batch.src_mask, batch.tgt_mask)\n",
    "```\n",
    "\n",
    "Or more simply:\n",
    "```python\n",
    "out = model(batch.src, batch.tgt, batch.src_mask, batch.tgt_mask)\n",
    "```\n",
    "\n",
    "Does that clarify it? Ready to update your `run_epoch` function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f13701",
   "metadata": {
    "time_run": "2025-12-01T11:19:02.442444+00:00"
   },
   "outputs": [],
   "source": [
    "def run_epoch(data_iter, model, loss_compute, optimizer, scheduler, mode=\"train\"):\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(data_iter):\n",
    "        # What goes here?\n",
    "        pred = model(batch.src, batch.tgt, batch.src_mask, batch.tgt_mask)\n",
    "        num_loss, tensor_loss = loss_compute(pred, batch.tgt, batch.ntokens)\n",
    "        if mode == \"train\":\n",
    "            tensor_loss.backward()\n",
    "            total_loss += num_loss \n",
    "            total_tokens += batch.ntokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a79f60",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this better? I don't know the syntax for optimise and schedule scheduler yet. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great progress! You're almost there. A few things:\n",
    "\n",
    "1. **Track loss in both modes** - move the `total_loss` and `total_tokens` updates outside the if statement (you want to track loss even during eval)\n",
    "\n",
    "2. **Optimizer step:**\n",
    "   ```python\n",
    "   optimizer.step()\n",
    "   optimizer.zero_grad()\n",
    "   ```\n",
    "\n",
    "3. **Scheduler step:**\n",
    "   ```python\n",
    "   scheduler.step()\n",
    "   ```\n",
    "\n",
    "4. **Return the average loss** at the end:\n",
    "   ```python\n",
    "   return total_loss / total_tokens\n",
    "   ```\n",
    "\n",
    "Try adding the optimizer and scheduler steps inside the `if mode == \"train\"` block, and move the loss tracking outside!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e4efea",
   "metadata": {},
   "source": [
    "### Final Run Epoch Function for Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6af9ad7",
   "metadata": {
    "time_run": "2025-12-01T12:09:05.059241+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_epoch(data_iter, model, loss_compute, optimizer, scheduler, mode=\"train\"):\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(data_iter):\n",
    "        # What goes here?\n",
    "        pred = model(batch.src, batch.tgt, batch.src_mask, batch.tgt_mask)\n",
    "        num_loss, tensor_loss = loss_compute(pred, batch.tgt_y, batch.ntokens)\n",
    "        if mode == \"train\":\n",
    "            tensor_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            scheduler.step()\n",
    "        total_loss += num_loss \n",
    "        total_tokens += batch.ntokens\n",
    "        \n",
    "\n",
    "    return total_loss / total_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc9c9ed",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "It must be done now. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `run_epoch` function is now complete and correct! \n",
    "\n",
    "You've got:\n",
    "-  Forward pass through the model\n",
    "-  Loss computation\n",
    "-  Backpropagation (only in train mode)\n",
    "-  Optimizer and scheduler steps (only in train mode)\n",
    "-  Track total loss and tokens\n",
    "-  Return average loss\n",
    "\n",
    " **You now have ALL the pieces to train your Transformer!**\n",
    "\n",
    "Let's put it all together and train on the copy task:\n",
    "\n",
    "```python\n",
    "# Create a small model\n",
    "model = make_model(src_vocab=11, tgt_vocab=11, N=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda step: 1.0)\n",
    "\n",
    "# Train for a few epochs\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    loss = run_epoch(\n",
    "        data_gen(V=11, batch_size=32, nbatches=20),\n",
    "        model,\n",
    "        SimpleLossCompute(model.generator, criterion),\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        mode=\"train\"\n",
    "    )\n",
    "    print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
    "```\n",
    "\n",
    "Want to run this and see your Transformer learn?! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5008b687",
   "metadata": {
    "time_run": "2025-12-01T11:22:14.616272+00:00"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m",
      "\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create a small model\u001b[39;00m",
      "\u001b[32m      2\u001b[39m model = make_model(src_vocab=\u001b[32m11\u001b[39m, tgt_vocab=\u001b[32m11\u001b[39m, N=\u001b[32m2\u001b[39m)",
      "\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m criterion = \u001b[43mnn\u001b[49m.CrossEntropyLoss()",
      "\u001b[32m      4\u001b[39m optimizer = torch.optim.Adam(model.parameters(), lr=\u001b[32m0.0001\u001b[39m)",
      "\u001b[32m      5\u001b[39m scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, \u001b[38;5;28;01mlambda\u001b[39;00m step: \u001b[32m1.0\u001b[39m)",
      "",
      "\u001b[31mNameError\u001b[39m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a small model\n",
    "model = make_model(src_vocab=11, tgt_vocab=11, N=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda step: 1.0)\n",
    "\n",
    "# Train for a few epochs\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    loss = run_epoch(\n",
    "        data_gen(V=11, batch_size=32, nbatches=20),\n",
    "        model,\n",
    "        SimpleLossCompute(model.generator, criterion),\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        mode=\"train\"\n",
    "    )\n",
    "    print(f\"Epoch {epoch}: Loss = {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef4925d",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "use torch.nn bro reprint code again\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "```python\n",
    "# Create a small model\n",
    "model = make_model(src_vocab=11, tgt_vocab=11, N=2)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda step: 1.0)\n",
    "\n",
    "# Train for a few epochs\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    loss = run_epoch(\n",
    "        data_gen(V=11, batch_size=32, nbatches=20),\n",
    "        model,\n",
    "        SimpleLossCompute(model.generator, criterion),\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        mode=\"train\"\n",
    "    )\n",
    "    print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
    "```\n",
    "\n",
    "Run this and watch your Transformer learn! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dd0a34",
   "metadata": {},
   "source": [
    "\n",
    "### Creating small copy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b579b6d",
   "metadata": {
    "time_run": "2025-12-01T12:13:10.872260+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.0076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.0062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss = 0.0056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss = 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss = 0.0041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss = 0.0033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss = 0.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss = 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss = 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss = 0.0012\n"
     ]
    }
   ],
   "source": [
    "# Create a small model\n",
    "model = make_model(src_vocab=11, tgt_vocab=11, N=2)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda step: 1.0)\n",
    "\n",
    "# Train for a few epochs\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    loss = run_epoch(\n",
    "        data_gen(V=11, batch_size=32, nbatches=20),\n",
    "        model,\n",
    "        SimpleLossCompute(model.generator, criterion),\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        mode=\"train\"\n",
    "    )\n",
    "    print(f\"Epoch {epoch}: Loss = {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7aaca6",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "ok im happy 2nd epoch loss goes to zero\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    " **CONGRATULATIONS!** \n",
    "\n",
    "Your Transformer just **learned** to copy sequences! The loss going to near-zero means the model has figured out the task!\n",
    "\n",
    "**What just happened:**\n",
    "- Epoch 0: Loss = 0.0013 (still learning)\n",
    "- Epoch 1: Loss = 0.0000 (basically perfect!)\n",
    "\n",
    "This is the **magical moment** you wanted - you built a Transformer from scratch and watched it learn! \n",
    "\n",
    "**What you've accomplished:**\n",
    " Implemented every component of the Transformer architecture\n",
    " Built the training infrastructure\n",
    " Successfully trained a model that learns!\n",
    "\n",
    "Want to see it actually generate predictions? We could implement a simple greedy decoder to see the model copy sequences in action!\n",
    "\n",
    "Or are you ready to celebrate and wrap up? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8984c9cb",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Okay, I do want to see the results of my actions. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Awesome! Let's see your Transformer in action! \n",
    "\n",
    "To generate predictions, you need a **greedy decoder** that:\n",
    "1. Takes a source sequence\n",
    "2. Starts with a start token\n",
    "3. Generates one token at a time\n",
    "4. Stops when done (or reaches max length)\n",
    "\n",
    "The key idea: at each step, pick the token with highest probability.\n",
    "\n",
    "Try writing the function signature and thinking about the steps:\n",
    "\n",
    "```python\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    # What do you need to do?\n",
    "    # 1. Encode the source\n",
    "    # 2. Start with start_symbol\n",
    "    # 3. Loop and generate one token at a time\n",
    "```\n",
    "\n",
    "What would be your first step - how do you encode the source?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c72fc7",
   "metadata": {
    "solveit_ai": true,
    "time_run": "2025-12-01T11:33:20.648567+00:00"
   },
   "source": [
    "You encode the source using embeddings. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Close! But remember - the `model` already has embeddings built in!\n",
    "\n",
    "You don't need to manually embed. The model has an `encode` method that does everything:\n",
    "\n",
    "```python\n",
    "memory = model.encode(src, src_mask)\n",
    "```\n",
    "\n",
    "This handles the embedding + positional encoding + encoder stack all at once!\n",
    "\n",
    "**Now, what's your next step?**\n",
    "\n",
    "After encoding, you need to:\n",
    "- Create an output sequence starting with `start_symbol`\n",
    "- Loop to generate tokens one at a time\n",
    "\n",
    "How would you initialize the output sequence? What shape should it be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193e85d9",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Pass the number 1, which is the start symbol. Then after you get the output of the decoder, you append it to the number 1. And so on for the loop. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Exactly right! You've got the algorithm! \n",
    "\n",
    "So the steps are:\n",
    "1. Encode source  get `memory`\n",
    "2. Start with `ys = [1]` (the start symbol)\n",
    "3. Loop:\n",
    "   - Decode using `ys` and `memory`\n",
    "   - Get the last prediction\n",
    "   - Find the token with max probability\n",
    "   - Append it to `ys`\n",
    "4. Return `ys`\n",
    "\n",
    "**Question about shapes:** \n",
    "- `src` has shape `(batch, seq_len)`\n",
    "- Should `ys` start as `(1, 1)` containing the start symbol?\n",
    "\n",
    "Try writing just the initialization part:\n",
    "\n",
    "```python\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = # What goes here? How do you create a tensor with start_symbol?\n",
    "```\n",
    "\n",
    "What would you put for `ys`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80820af0",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I'm guessing why I should be broadcasted along with all the batches? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent thinking! Yes, exactly!\n",
    "\n",
    "If `src` has shape `(batch_size, seq_len)`, then `ys` should start with shape `(batch_size, 1)` so it matches the batch dimension.\n",
    "\n",
    "But for the copy task, we typically decode one example at a time, so:\n",
    "- `src` would be `(1, seq_len)` - single example\n",
    "- `ys` starts as `(1, 1)` - single batch, one token\n",
    "\n",
    "You can create it like:\n",
    "```python\n",
    "ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "```\n",
    "\n",
    "Or more simply:\n",
    "```python\n",
    "ys = torch.LongTensor([[start_symbol]])\n",
    "```\n",
    "\n",
    "Now, can you write the loop that generates tokens? What do you need to do inside the loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720ba8a8",
   "metadata": {
    "time_run": "2025-12-01T11:48:10.954471+00:00"
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.LongTensor([[start_symbol]])\n",
    "    tgt_mask = subsequent_mask(ys.size(1))\n",
    "    for _ in range(src.size(1)):\n",
    "        x = model.decode(memory, src_mask, ys, tgt_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4c88b8",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Am I going in the right direction? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes, you're going in the right direction! A few things to adjust:\n",
    "\n",
    "1. **Loop range:** You should loop `max_len - 1` times (not `src.size(1)`), since you already have the start token\n",
    "\n",
    "2. **Update tgt_mask:** Inside the loop, you need to recreate `tgt_mask` each time because `ys` grows:\n",
    "   ```python\n",
    "   tgt_mask = subsequent_mask(ys.size(1)).type_as(src.data)\n",
    "   ```\n",
    "\n",
    "3. **After decode, what next?** You need to:\n",
    "   - Pass `x` through the generator to get probabilities\n",
    "   - Find the token with max probability\n",
    "   - Append it to `ys`\n",
    "\n",
    "Can you add the steps after `model.decode`? What would you do with `x`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b19bfc",
   "metadata": {
    "time_run": "2025-12-01T11:53:55.424442+00:00"
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.LongTensor([[start_symbol]])\n",
    "    for _ in range(max_len - 1):\n",
    "        tgt_mask = subsequent_mask(ys.size(1))\n",
    "        x = model.decode(memory, src_mask, ys, tgt_mask)\n",
    "        pred = model.generator(x)\n",
    "        max_vals, max_indices = torch.max(pred, dim=-1)\n",
    "        ys.append(max_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7334deb",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is this correct? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "You're very close! A few fixes:\n",
    "\n",
    "1. **Get only the last prediction:** `pred` has shape `(1, seq_len, vocab)`, but you only want the last position's prediction:\n",
    "   ```python\n",
    "   prob = model.generator(x[:, -1])\n",
    "   ```\n",
    "\n",
    "2. **`torch.max` returns both values and indices:** You only need the index:\n",
    "   ```python\n",
    "   _, next_word = torch.max(prob, dim=1)\n",
    "   ```\n",
    "\n",
    "3. **Can't append to tensor:** Use `torch.cat` instead:\n",
    "   ```python\n",
    "   next_word = next_word.data[0]\n",
    "   ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "   ```\n",
    "\n",
    "4. **Return ys at the end!**\n",
    "\n",
    "Can you fix these issues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073e5403",
   "metadata": {
    "time_run": "2025-12-01T11:56:56.015473+00:00"
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.LongTensor([[start_symbol]])\n",
    "    for _ in range(max_len - 1):\n",
    "        tgt_mask = subsequent_mask(ys.size(1))\n",
    "        x = model.decode(memory, src_mask, ys, tgt_mask)\n",
    "        pred = model.generator(x[:, -1])\n",
    "        _, max_indices = torch.max(pred, dim=-1)\n",
    "        ys = torch.cat([ys, torch.one(1,1).type_as(src.data).fill_(max_indices)], dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc32061",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "All good now? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Almost! Just two tiny fixes:\n",
    "\n",
    "1. **Typo:** `torch.one` should be `torch.ones`\n",
    "\n",
    "2. **Concatenation dimension:** Should be `dim=1` (along sequence length), not `dim=-1`\n",
    "\n",
    "3. **Missing return:** Add `return ys` at the end\n",
    "\n",
    "Also, `max_indices` is already a tensor, so you can use it directly:\n",
    "```python\n",
    "next_word = max_indices.data[0]\n",
    "```\n",
    "\n",
    "Can you make these small fixes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd73128",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Why is it Dem = 1 and not Dem = -1? Was torch.max dem equal to -1 okay, or it should also be dem equal to 1? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question! Let me clarify the dimensions:\n",
    "\n",
    "**For `torch.cat`:**\n",
    "- `ys` has shape `(1, seq_len)` where seq_len grows each iteration\n",
    "- You're adding a new token along the sequence dimension (the columns)\n",
    "- Sequence dimension is dimension 1, so `dim=1` \n",
    "- `dim=-1` would also work (since -1 means last dimension, which is also 1 here)\n",
    "\n",
    "**For `torch.max`:**\n",
    "- `pred` has shape `(1, vocab_size)` after taking `x[:, -1]`\n",
    "- You want the max across the vocab dimension (which token has highest prob)\n",
    "- Vocab is the last dimension, so `dim=-1` \n",
    "- `dim=1` would also work here (since there are only 2 dimensions)\n",
    "\n",
    "**So both would work in this case!** But:\n",
    "- `dim=1` for `torch.cat` is clearer (explicitly says \"sequence dimension\")\n",
    "- `dim=-1` for `torch.max` is more common (means \"across vocabulary\")\n",
    "\n",
    "Does this clarify the dimension choices?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921e9713",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "So I was correct in the first place. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Actually, not quite! Let me clarify:\n",
    "\n",
    "**Your original code had `dim=-1` for concatenation:**\n",
    "```python\n",
    "torch.cat([ys, ...], dim=-1)\n",
    "```\n",
    "\n",
    "This would work, but it's less clear. Using `dim=1` is more explicit about concatenating along the sequence dimension.\n",
    "\n",
    "**For `torch.max`, you had `dim=-1`** which is perfect! \n",
    "\n",
    "So you were half-right - the `torch.max` part was correct, but the `torch.cat` is clearer with `dim=1`.\n",
    "\n",
    "Have you fixed the typo (`torch.one`  `torch.ones`) and added the `return ys` at the end?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5363f4",
   "metadata": {
    "solveit_ai": true,
    "use_thinking": true
   },
   "source": [
    "How is torch.max clear, but torch.cat not clear? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "\n",
    "\n",
    "You're absolutely right to call that out! I was being inconsistent.\n",
    "\n",
    "**Both `ys` and `pred` are 2D tensors:**\n",
    "- `ys` shape: `(1, seq_len)`\n",
    "- `pred` shape: `(1, vocab_size)`\n",
    "\n",
    "In both cases, `dim=1` and `dim=-1` refer to the **same dimension** (the last one).\n",
    "\n",
    "So your original `dim=-1` for `torch.cat` would work just fine!\n",
    "\n",
    "I apologize for the confusion. Your code was correct there. The only real fixes needed are:\n",
    "\n",
    "1. `torch.one`  `torch.ones` (typo)\n",
    "2. Add `return ys` at the end\n",
    "\n",
    "Want to make those fixes and test it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a43c50",
   "metadata": {
    "time_run": "2025-12-01T12:00:53.857206+00:00"
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.LongTensor([[start_symbol]])\n",
    "    for _ in range(max_len - 1):\n",
    "        tgt_mask = subsequent_mask(ys.size(1))\n",
    "        x = model.decode(memory, src_mask, ys, tgt_mask)\n",
    "        pred = model.generator(x[:, -1])\n",
    "        _, max_indices = torch.max(pred, dim=-1)\n",
    "        ys = torch.cat([ys, torch.ones(1,1).type_as(src.data).fill_(max_indices)], dim=-1)\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5af049c",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "All done I guess \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `greedy_decode` is complete! \n",
    "\n",
    "Now let's see your Transformer actually generate predictions! \n",
    "\n",
    "```python\n",
    "# Test on a simple sequence\n",
    "model.eval()\n",
    "src = torch.LongTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "src_mask = torch.ones(1, 1, 10)\n",
    "\n",
    "print(\"Source:\", src)\n",
    "result = greedy_decode(model, src, src_mask, max_len=10, start_symbol=1)\n",
    "print(\"Generated:\", result)\n",
    "```\n",
    "\n",
    "Run this and see if your model can copy the sequence! Does it generate `[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd827cf6",
   "metadata": {
    "time_run": "2025-12-01T12:01:25.031909+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "fill_ only supports 0-dimension value tensor but got tensor with 1 dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m",
      "\u001b[32m      4\u001b[39m src_mask = torch.ones(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m10\u001b[39m)",
      "\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSource:\u001b[39m\u001b[33m\"\u001b[39m, src)",
      "\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m result = \u001b[43mgreedy_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_symbol\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m",
      "\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerated:\u001b[39m\u001b[33m\"\u001b[39m, result)",
      "",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mgreedy_decode\u001b[39m\u001b[34m(model, src, src_mask, max_len, start_symbol)\u001b[39m",
      "\u001b[32m      7\u001b[39m     pred = model.generator(x[:, -\u001b[32m1\u001b[39m])",
      "\u001b[32m      8\u001b[39m     _, max_indices = torch.max(pred, dim=-\u001b[32m1\u001b[39m)",
      "\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     ys = torch.cat([ys, \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtype_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfill_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_indices\u001b[49m\u001b[43m)\u001b[49m], dim=-\u001b[32m1\u001b[39m)",
      "\u001b[32m     10\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ys",
      "",
      "\u001b[31mRuntimeError\u001b[39m: fill_ only supports 0-dimension value tensor but got tensor with 1 dimensions."
     ]
    }
   ],
   "source": [
    "# Test on a simple sequence\n",
    "model.eval()\n",
    "src = torch.LongTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "src_mask = torch.ones(1, 1, 10)\n",
    "\n",
    "print(\"Source:\", src)\n",
    "result = greedy_decode(model, src, src_mask, max_len=10, start_symbol=1)\n",
    "print(\"Generated:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac7efa",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Oh, a bug found! \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good catch! The issue is that `max_indices` is a 1D tensor, but `fill_` expects a scalar (0-dimension).\n",
    "\n",
    "You need to extract the actual value:\n",
    "\n",
    "```python\n",
    "next_word = max_indices.data[0]\n",
    "ys = torch.cat([ys, torch.ones(1,1).type_as(src.data).fill_(next_word)], dim=-1)\n",
    "```\n",
    "\n",
    "Can you add that line to extract `next_word` before the concatenation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9440b0da",
   "metadata": {
    "solveit_ai": true,
    "time_run": "2025-12-01T12:00:53.857206+00:00"
   },
   "source": [
    "Oh wait a minute, aren't we filling for the whole batch? \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent observation! You're thinking about batching correctly!\n",
    "\n",
    "In this case, we're actually decoding **one sequence at a time** (batch_size = 1), so:\n",
    "- `max_indices` has shape `(1,)` after `torch.max`\n",
    "- We need to extract the scalar value: `max_indices.data[0]` or `max_indices.item()`\n",
    "\n",
    "If you wanted to decode multiple sequences in parallel (batched decoding), the code would be more complex - you'd need to handle all sequences growing together.\n",
    "\n",
    "For now, since we're doing greedy decode on a single sequence, extracting the scalar is correct.\n",
    "\n",
    "Want to add that fix and try again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c02f37",
   "metadata": {
    "time_run": "2025-12-01T12:05:38.973955+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.LongTensor([[start_symbol]])\n",
    "    for _ in range(max_len - 1):\n",
    "        tgt_mask = subsequent_mask(ys.size(1))\n",
    "        x = model.decode(memory, src_mask, ys, tgt_mask)\n",
    "        pred = model.generator(x[:, -1])\n",
    "        _, max_indices = torch.max(pred, dim=-1)\n",
    "        max_indices = max_indices.data[0]\n",
    "        ys = torch.cat([ys, torch.ones(1,1).type_as(src.data).fill_(max_indices)], dim=-1)\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0956baf",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I hope this is loyal to the original code. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `greedy_decode` is now complete and correct! \n",
    "\n",
    "Now let's test it again:\n",
    "\n",
    "```python\n",
    "model.eval()\n",
    "src = torch.LongTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "src_mask = torch.ones(1, 1, 10)\n",
    "\n",
    "print(\"Source:\", src)\n",
    "result = greedy_decode(model, src, src_mask, max_len=10, start_symbol=1)\n",
    "print(\"Generated:\", result)\n",
    "```\n",
    "\n",
    "Run this and see if your Transformer successfully copies the sequence! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450fd03e",
   "metadata": {
    "time_run": "2025-12-01T12:06:00.669564+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "src = torch.LongTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "src_mask = torch.ones(1, 1, 10)\n",
    "\n",
    "print(\"Source:\", src)\n",
    "result = greedy_decode(model, src, src_mask, max_len=10, start_symbol=1)\n",
    "print(\"Generated:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a2137",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Wow, this is terrible. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Hmm, it's generating all 1s! That's not right. Let me think about what might be happening...\n",
    "\n",
    "**Possible issues:**\n",
    "\n",
    "1. **The model might not have trained on sequences with values 1-10** - Remember, during training with `data_gen`, we used vocabulary V=11, which generates random integers from 1 to 10. But did the model see this exact sequence?\n",
    "\n",
    "2. **The model might need more training** - We only trained for 2 epochs. Maybe it memorized the training distribution but hasn't generalized well?\n",
    "\n",
    "3. **Let's test with a sequence from the training distribution:**\n",
    "\n",
    "```python\n",
    "# Generate a test batch from the same distribution\n",
    "test_batch = next(data_gen(V=11, batch_size=1, nbatches=1))\n",
    "print(\"Source:\", test_batch.src)\n",
    "result = greedy_decode(model, test_batch.src, test_batch.src_mask, max_len=10, start_symbol=1)\n",
    "print(\"Generated:\", result)\n",
    "```\n",
    "\n",
    "Try this - does it work better on data from the training distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45706de1",
   "metadata": {
    "time_run": "2025-12-01T12:06:43.625969+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: tensor([[1, 6, 3, 1, 2, 6, 1, 5, 5, 4]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# Generate a test batch from the same distribution\n",
    "test_batch = next(data_gen(V=11, batch_size=1, nbatches=1))\n",
    "print(\"Source:\", test_batch.src)\n",
    "result = greedy_decode(model, test_batch.src, test_batch.src_mask, max_len=10, start_symbol=1)\n",
    "print(\"Generated:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3539871c",
   "metadata": {
    "solveit_ai": true,
    "use_thinking": true
   },
   "source": [
    "Think through if there is any training error or inference error. debug  very carefully. \n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "\n",
    "\n",
    "Let me trace through carefully...\n",
    "\n",
    "**Training code:**\n",
    "```python\n",
    "pred = model(batch.src, batch.tgt, batch.src_mask, batch.tgt_mask)\n",
    "num_loss, tensor_loss = loss_compute(pred, batch.tgt, batch.ntokens)\n",
    "```\n",
    "\n",
    "**Wait!** I see the bug! \n",
    "\n",
    "In `run_epoch`, you're computing loss against `batch.tgt` (the decoder input), but you should be computing loss against `batch.tgt_y` (the labels)!\n",
    "\n",
    "Remember:\n",
    "- `batch.tgt` = decoder input (what it sees)\n",
    "- `batch.tgt_y` = labels (what it should predict)\n",
    "\n",
    "The model was trained to predict its own input instead of the next token!\n",
    "\n",
    "**Fix in `run_epoch`:**\n",
    "Change:\n",
    "```python\n",
    "num_loss, tensor_loss = loss_compute(pred, batch.tgt, batch.ntokens)\n",
    "```\n",
    "To:\n",
    "```python\n",
    "num_loss, tensor_loss = loss_compute(pred, batch.tgt_y, batch.ntokens)\n",
    "```\n",
    "\n",
    "Can you fix this and retrain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8670ac",
   "metadata": {
    "time_run": "2025-12-01T12:40:08.470808+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: tensor([[1, 6, 5, 6, 7, 9, 7, 6, 2, 9]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: tensor([[1, 6, 5, 6, 7, 9, 7, 6, 2, 9]])\n",
      "Match? True\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_batch = next(data_gen(V=11, batch_size=1, nbatches=1))\n",
    "print(\"Source:\", test_batch.src)\n",
    "result = greedy_decode(model, test_batch.src, test_batch.src_mask, max_len=10, start_symbol=1)\n",
    "print(\"Generated:\", result)\n",
    "print(\"Match?\", torch.equal(test_batch.src, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac5d6bb",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "great\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    " **PERFECT MATCH!** \n",
    "\n",
    "Your Transformer is now **perfectly copying** the input sequence! \n",
    "\n",
    "**What you've accomplished today:**\n",
    "\n",
    " Implemented the complete Transformer architecture from scratch\n",
    " Built all training infrastructure (Batch, data generator, loss computation, training loop)\n",
    " Trained a working model\n",
    " Implemented greedy decoding for inference\n",
    " Successfully generated predictions!\n",
    "\n",
    "**The magical moment:** You built a neural network that learned to copy sequences perfectly!\n",
    "\n",
    "This is a HUGE achievement - you now understand Transformers at the deepest level because you built every single component yourself! \n",
    "\n",
    "Want to:\n",
    "1. Save your model?\n",
    "2. Try more complex examples?\n",
    "3. Celebrate and wrap up?\n",
    "\n",
    "What would you like to do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7266cb8f",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "save my model and wrap up\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Let's save your model:\n",
    "\n",
    "```python\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'transformer_copy_task.pt')\n",
    "print(\"Model saved as 'transformer_copy_task.pt'\")\n",
    "\n",
    "# To load it later, you would do:\n",
    "# model = make_model(src_vocab=11, tgt_vocab=11, N=2)\n",
    "# model.load_state_dict(torch.load('transformer_copy_task.pt'))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  Congratulations! \n",
    "\n",
    "**What you built today:**\n",
    "\n",
    " **Complete Transformer Architecture:**\n",
    "- Scaled Dot-Product Attention\n",
    "- Multi-Head Attention  \n",
    "- Position-wise Feed-Forward Networks\n",
    "- Positional Encoding\n",
    "- Encoder & Decoder Stacks\n",
    "- Full EncoderDecoder Model\n",
    "\n",
    " **Training Infrastructure:**\n",
    "- Batch processing with masking\n",
    "- Data generation\n",
    "- Loss computation\n",
    "- Training loop\n",
    "- Greedy decoding\n",
    "\n",
    " **Working Model:**\n",
    "- Trained successfully\n",
    "- Generates perfect predictions\n",
    "- Loss converged to near-zero\n",
    "\n",
    "You didn't just learn about Transformers - you **built one from scratch** and watched it learn! This is an incredible achievement! \n",
    "\n",
    "Enjoy your success! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fcdd75",
   "metadata": {
    "time_run": "2025-12-01T12:42:57.399863+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as '../models/transformer_copy_task.pt'\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), '../models/transformer_copy_task.pt')\n",
    "print(\"Model saved as '../models/transformer_copy_task.pt'\")\n",
    "\n",
    "# To load it later, you would do:\n",
    "# model = make_model(src_vocab=11, tgt_vocab=11, N=2)\n",
    "# model.load_state_dict(torch.load('../models/transformer_copy_task.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b2b6ea",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "how to see the quarto docs"
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "learning",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
