{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mettafore/annotated-transformer/blob/master/nbs/04_transformer_workshop_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B9sa3p8Z3fs"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3ARPQM3Z3fs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from IPython.core.magic import register_cell_magic\n",
        "from IPython.display import HTML, display\n",
        "import html\n",
        "import math\n",
        "import copy\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGwi2glcZ3ft"
      },
      "source": [
        "https://arxiv.org/pdf/1706.03762"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSytGOTOZ3ft"
      },
      "source": [
        "I will be doing an implementation of the seminal paper \"Attention Is All You Need.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Jmjm0SZ3ft"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQjB8BzpZ3ft"
      },
      "source": [
        "Implement the scaled dot-product attention mechanism. Remember the formula: Attention(Q,K,V) = softmax(QK^T / âˆšd_k)V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NB0vxGpZ3ft"
      },
      "outputs": [],
      "source": [
        "def attention(Q, K, V, dropout, mask):\n",
        "    \"\"\"Scaled Dot-Product Attention\"\"\"\n",
        "    sqrt_d_k = math.sqrt(K.size(-1))\n",
        "    scores = Q @ K.transpose(-2,-1) / sqrt_d_k\n",
        "\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask==0, -1e9)\n",
        "\n",
        "    attention_weights = torch.softmax(scores, dim=-1)\n",
        "\n",
        "    if dropout is not None:\n",
        "        attention_weights = dropout(attention_weights)\n",
        "\n",
        "    output = attention_weights @ V\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGNHe4aZZ3ft"
      },
      "source": [
        "#### Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC_Rch8AZ3ft",
        "outputId": "d34a0b04-d74e-44be-b4fe-1e6ae9478948"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Result shape: torch.Size([2, 1, 4, 8])\n"
          ]
        }
      ],
      "source": [
        "# Test attention\n",
        "Q = torch.randn(2, 1, 4, 8)\n",
        "K = torch.randn(2, 1, 4, 8)\n",
        "V = torch.randn(2, 1, 4, 8)\n",
        "result = attention(Q, K, V, None, None)\n",
        "print(\"Result shape:\", result.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nRhO7XgZ3fu"
      },
      "source": [
        "## MultiHeadedAttention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANEELTaSZ3fu"
      },
      "source": [
        "Implement multi-head attention. Split d_model into h heads, apply attention to each, then concatenate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbdiGdESZ3fu"
      },
      "outputs": [],
      "source": [
        "class MultiHeadedAttention(torch.nn.Module):\n",
        "    def __init__(self, h, d_model, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % h == 0\n",
        "\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.dropout = torch.nn.Dropout(p=dropout)\n",
        "        self.attn = None\n",
        "\n",
        "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(d_model, d_model) for x in range(4)])\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        Q = self.linear_layers[0](query)\n",
        "        K = self.linear_layers[1](key)\n",
        "        V = self.linear_layers[2](value)\n",
        "\n",
        "        Q = Q.reshape(batch_size, -1, self.h, self.d_k).transpose(1,2)\n",
        "        K = K.reshape(batch_size, -1, self.h, self.d_k).transpose(1,2)\n",
        "        V = V.reshape(batch_size, -1, self.h, self.d_k).transpose(1,2)\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1)\n",
        "\n",
        "        x = attention(Q, K, V, self.dropout, mask)\n",
        "\n",
        "        x = x.transpose(1,2).reshape(batch_size, -1, self.h * self.d_k)\n",
        "\n",
        "        output = self.linear_layers[3](x)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qy8gBd1Z3fu"
      },
      "source": [
        "#### Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTVVt2QtZ3fu",
        "outputId": "e1ed891b-04c5-44c5-9356-5382cbc43a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 10, 512]) Output shape: torch.Size([2, 10, 512])\n"
          ]
        }
      ],
      "source": [
        "# Test MultiHeadedAttention\n",
        "mha = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
        "x = torch.randn(2, 10, 512)\n",
        "output = mha(x, x, x)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIOA8YVOZ3fu"
      },
      "source": [
        "## PositionwiseFeedForward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5GEWhy7Z3fu"
      },
      "source": [
        "Implement the position-wise feed-forward network: FFN(x) = max(0, xW1 + b1)W2 + b2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Um3HI_vVZ3fu"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedForward(torch.nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.linear_layer = torch.nn.Linear(d_model, d_ff)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.dropout = torch.nn.Dropout(p=dropout)\n",
        "        self.output_layer = torch.nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear_layer(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyKyxGX2Z3fu"
      },
      "source": [
        "#### Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjfLZhDaZ3fu",
        "outputId": "103499bd-8ade-4384-c2c5-587e37ad7a18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 10, 512]) Output shape: torch.Size([2, 10, 512])\n"
          ]
        }
      ],
      "source": [
        "# Test PositionwiseFeedForward\n",
        "ffn = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
        "x = torch.randn(2, 10, 512)\n",
        "output = ffn(x)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9s_fhuRZ3fu"
      },
      "source": [
        "## Positional Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnXeP7SvZ3fu"
      },
      "source": [
        "Since attention has no notion of position, we add positional encodings using sin/cos functions of different frequencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTrRfCAXZ3fu"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(torch.nn.Module):\n",
        "    def __init__(self, d_model, dropout, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.dropout = torch.nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        even_indices = torch.arange(0, d_model, 2)\n",
        "\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "\n",
        "        div_term = torch.exp(-even_indices * (torch.log(torch.tensor(10000.0)) / d_model))\n",
        "\n",
        "        pe[:, ::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.size(1)\n",
        "        x = x + self.pe[:,:seq_len,:].requires_grad_(False)\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9xT31wIZ3fu"
      },
      "source": [
        "#### Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AOXb7Z0Z3fu",
        "outputId": "a2e0e98f-7d70-44ea-9481-af65f3c03c6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 10, 512]) Output shape: torch.Size([2, 10, 512])\n"
          ]
        }
      ],
      "source": [
        "# Test PositionalEncoding\n",
        "pe = PositionalEncoding(d_model=512, dropout=0.1)\n",
        "x = torch.zeros(2, 10, 512)\n",
        "output = pe(x)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtFWOZtjZ3fu"
      },
      "source": [
        "## Encoder Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dlwy54o9Z3fv"
      },
      "source": [
        "Each encoder layer has two sub-layers: multi-head self-attention and feed-forward network, each with residual connections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyIHomphZ3fv"
      },
      "source": [
        "### Sublayer Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ucO8wTVZ3fv"
      },
      "outputs": [],
      "source": [
        "class SublayerConnection(torch.nn.Module):\n",
        "    \"A residual connection followed by layer norm\"\n",
        "    def __init__(self, size, dropout):\n",
        "        super().__init__()\n",
        "        self.layer_norm = torch.nn.LayerNorm(size)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        y = self.layer_norm(x)\n",
        "        y = sublayer(y)\n",
        "        y = self.dropout(y)\n",
        "        return x + y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRuWnjT1Z3fv"
      },
      "source": [
        "### Final clones function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwARhQjuZ3fv"
      },
      "outputs": [],
      "source": [
        "def clones(module, N):\n",
        "    \"Produce N identical layers\"\n",
        "    return torch.nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrcGoPJDZ3fv"
      },
      "source": [
        "### Final EncoderLayer Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Woqc7Bv9Z3fv"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(torch.nn.Module):\n",
        "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = torch.nn.ModuleList([SublayerConnection(size, dropout) for _ in range(2)])\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
        "        x = self.sublayer[1](x, lambda x: self.feed_forward(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUngjwAxZ3fv"
      },
      "source": [
        "#### Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKzrISpEZ3fv",
        "outputId": "e3f6202a-bea5-46c2-e148-b7828e17434b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 10, 512]) Output shape: torch.Size([2, 10, 512])\n"
          ]
        }
      ],
      "source": [
        "# Test EncoderLayer\n",
        "attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
        "ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
        "encoder_layer = EncoderLayer(size=512, self_attn=attn, feed_forward=ff, dropout=0.1)\n",
        "x = torch.randn(2, 10, 512)\n",
        "output = encoder_layer(x, None)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaYCCLvqZ3fv"
      },
      "source": [
        "## Encoder Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a-rfQvGZ3fv"
      },
      "source": [
        "Stack N encoder layers together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAKmYeOKZ3fv"
      },
      "outputs": [],
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    \"Stack of N encoder layers\"\n",
        "    def __init__(self, layer, N):\n",
        "        super().__init__()\n",
        "        self.encoders = clones(layer, N)\n",
        "        self.layer_norm = torch.nn.LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        for encoder in self.encoders:\n",
        "            x = encoder(x, mask)\n",
        "        return self.layer_norm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah7fGEdeZ3fv"
      },
      "source": [
        "#### Unit test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WZXLiOqZ3fv",
        "outputId": "2fc63ee9-688b-4f5a-d504-922a98636111"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 10, 512]) Output shape: torch.Size([2, 10, 512])\n"
          ]
        }
      ],
      "source": [
        "# Test Encoder\n",
        "encoder = Encoder(encoder_layer, N=6)\n",
        "x = torch.randn(2, 10, 512)\n",
        "output = encoder(x, None)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8dMwgv5Z3fw"
      },
      "source": [
        "## Decoder Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6AGE7JYZ3fw"
      },
      "source": [
        "Each decoder layer has three sub-layers: masked self-attention, cross-attention to encoder output, and feed-forward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3xTbbrdZ3fw"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(torch.nn.Module):\n",
        "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.src_attn = src_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayers = clones(SublayerConnection(size, dropout), 3)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        x = self.sublayers[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
        "        x = self.sublayers[1](x, lambda x: self.src_attn(x, memory, memory, src_mask))\n",
        "        x = self.sublayers[2](x, self.feed_forward)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuQ7e75RZ3fw"
      },
      "source": [
        "#### Unit test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhKxqdEPZ3fw",
        "outputId": "cd029b55-83b1-4ec6-c5a3-fb5df1325e50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 10, 512]) Output shape: torch.Size([2, 10, 512])\n"
          ]
        }
      ],
      "source": [
        "# Test DecoderLayer\n",
        "attn1 = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
        "attn2 = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
        "ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
        "decoder_layer = DecoderLayer(size=512, self_attn=attn1, src_attn=attn2, feed_forward=ff, dropout=0.1)\n",
        "x = torch.randn(2, 10, 512)\n",
        "memory = torch.randn(2, 10, 512)\n",
        "output = decoder_layer(x, memory, None, None)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMYk1ORyZ3fw"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZoVmHX6Z3fw"
      },
      "source": [
        "Stack N decoder layers together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9tReE3rZ3fw"
      },
      "outputs": [],
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "    def __init__(self, layer, N):\n",
        "        super().__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.layer_norm = torch.nn.LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, memory, src_mask, tgt_mask)\n",
        "        return self.layer_norm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3p8vuaqZ3fw"
      },
      "source": [
        "### Unit test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjzQtHeBZ3fw",
        "outputId": "2410e7e0-418f-4990-c5ee-46a3d914556c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 10, 512]) Output shape: torch.Size([2, 10, 512])\n"
          ]
        }
      ],
      "source": [
        "# Test Decoder\n",
        "decoder = Decoder(decoder_layer, N=6)\n",
        "x = torch.randn(2, 10, 512)\n",
        "memory = torch.randn(2, 10, 512)\n",
        "output = decoder(x, memory, None, None)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_q0fWBvZ3fw"
      },
      "source": [
        "## Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPrm0G-bZ3fw"
      },
      "source": [
        "Convert token IDs to dense vectors, scaled by sqrt(d_model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYomRThIZ3fw"
      },
      "outputs": [],
      "source": [
        "class Embeddings(torch.nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = torch.nn.Embedding(vocab, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.embedding(x) * math.sqrt(self.d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdcjHWJzZ3fw"
      },
      "source": [
        "### Unit test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bIf1b_zZ3fw",
        "outputId": "3bae797b-cc63-4345-e2ca-a41a8e4e5529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 10]) Output shape: torch.Size([2, 10, 512])\n"
          ]
        }
      ],
      "source": [
        "# Test Embeddings\n",
        "emb = Embeddings(d_model=512, vocab=1000)\n",
        "x = torch.randint(0, 1000, (2, 10))\n",
        "output = emb(x)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJo6zTr_Z3fw"
      },
      "source": [
        "## Generator class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk4cQ0gCZ3fw"
      },
      "source": [
        "Final linear layer + log softmax to convert decoder output to token probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsBzGOatZ3fw"
      },
      "outputs": [],
      "source": [
        "class Generator(torch.nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super().__init__()\n",
        "        self.linear = torch.nn.Linear(d_model, vocab)\n",
        "        self.logsoftmax = torch.nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        return self.logsoftmax(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3esvg3XxZ3fw"
      },
      "source": [
        "#### Unit test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "askaI53PZ3fw",
        "outputId": "9720fdf3-91cd-4086-c1f2-9cebcbf8274d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 10, 512]) Output shape: torch.Size([2, 10, 1000])\n"
          ]
        }
      ],
      "source": [
        "# Test Generator\n",
        "gen = Generator(d_model=512, vocab=1000)\n",
        "x = torch.randn(2, 10, 512)\n",
        "output = gen(x)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDnWmZ_jZ3fx"
      },
      "source": [
        "### Final Encoder Decoder Function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG8hd9rwZ3fx"
      },
      "outputs": [],
      "source": [
        "class EncoderDecoder(torch.nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.generator = generator\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        x = self.src_embed(src)\n",
        "        return self.encoder(x, src_mask)\n",
        "\n",
        "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
        "        x = self.tgt_embed(tgt)\n",
        "        return self.decoder(x, memory, src_mask, tgt_mask)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        memory = self.encode(src, src_mask)\n",
        "        return self.decode(memory, src_mask, tgt, tgt_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93EVZ4q1Z3fx"
      },
      "source": [
        "## Make Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTD6q0q1Z3fx"
      },
      "source": [
        "Helper function to construct the full transformer model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfDDJAryZ3fx"
      },
      "outputs": [],
      "source": [
        "def make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
        "    \"Construct transformer model from hyperparameters\"\n",
        "    multi_head_attentions = [copy.deepcopy(MultiHeadedAttention(h, d_model, dropout)) for _ in range(3)]\n",
        "    feedforward_layers = [copy.deepcopy(PositionwiseFeedForward(d_model, d_ff, dropout)) for _ in range(2)]\n",
        "    positional_encoding = [PositionalEncoding(d_model, dropout) for _ in range(2)]\n",
        "\n",
        "    src_embedding_layer = Embeddings(d_model, src_vocab)\n",
        "    tgt_embeddings_layer = Embeddings(d_model, tgt_vocab)\n",
        "    src_embed = torch.nn.Sequential(src_embedding_layer, positional_encoding[0])\n",
        "    tgt_embed = torch.nn.Sequential(tgt_embeddings_layer, positional_encoding[1])\n",
        "\n",
        "    encoder_layer = EncoderLayer(d_model, multi_head_attentions[0], feedforward_layers[0], dropout)\n",
        "    decoder_layer = DecoderLayer(d_model, multi_head_attentions[1], multi_head_attentions[2], feedforward_layers[1], dropout)\n",
        "\n",
        "    encoder = Encoder(encoder_layer, N)\n",
        "    decoder = Decoder(decoder_layer, N)\n",
        "    generator = Generator(d_model, tgt_vocab)\n",
        "\n",
        "    encoder_decoder = EncoderDecoder(encoder, decoder, src_embed, tgt_embed, generator)\n",
        "\n",
        "    for p in encoder_decoder.parameters():\n",
        "        if p.dim() > 1:\n",
        "            torch.nn.init.xavier_uniform_(p)\n",
        "\n",
        "    return encoder_decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkMUC3JOZ3fx"
      },
      "source": [
        "## Copy Code Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWCfdlIHZ3fx"
      },
      "source": [
        "Training utilities for the copy task (provided complete)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOkuljqGZ3fx"
      },
      "source": [
        "### Final subsequent mask function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZg8Ck42Z3fx"
      },
      "outputs": [],
      "source": [
        "def subsequent_mask(size):\n",
        "    \"Create mask to prevent attention to future positions\"\n",
        "    lower_t = torch.ones([size, size]).tril().bool()\n",
        "    lower_t = lower_t.unsqueeze(0)\n",
        "    return lower_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXpsqf5mZ3fx"
      },
      "source": [
        "### Final Batch Class for copy example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdGqKCX7Z3fx"
      },
      "outputs": [],
      "source": [
        "class Batch:\n",
        "    def __init__(self, src, tgt=None, pad=2):\n",
        "        self.src = src\n",
        "        self.src_mask = (src != pad).unsqueeze(-2)\n",
        "        if tgt is not None:\n",
        "            self.tgt = tgt[:, :-1]\n",
        "            self.tgt_y = tgt[:,1:]\n",
        "            self.pad_tgt_mask = (self.tgt!=pad).unsqueeze(-2)\n",
        "            self.subseq_tgt_mask = subsequent_mask(self.tgt.size(1))\n",
        "            self.tgt_mask = self.pad_tgt_mask & self.subseq_tgt_mask\n",
        "            self.ntokens = (self.tgt_y!=pad).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPV_s6WyZ3fx"
      },
      "source": [
        "### Final Data Gen Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcyV5c0-Z3fx"
      },
      "outputs": [],
      "source": [
        "def data_gen(V, batch_size, nbatches):\n",
        "    \"Generate random data for a src-tgt copy task\"\n",
        "    for i in range(nbatches):\n",
        "        random_int = np.random.randint(1, V, size=[batch_size, 10])\n",
        "        random_int[:,0] = 1\n",
        "        random_int = torch.tensor(random_int)\n",
        "        src = random_int\n",
        "        tgt = random_int\n",
        "        yield Batch(src, tgt, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2fbya4iZ3fx"
      },
      "source": [
        "### Final Simple Loss Compute Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6f-wsmQZ3fx"
      },
      "outputs": [],
      "source": [
        "class SimpleLossCompute:\n",
        "    def __init__(self, generator, criterion):\n",
        "        self.generator = generator\n",
        "        self.criterion = criterion\n",
        "\n",
        "    def __call__(self, x, y, norm):\n",
        "        pred = self.generator(x)\n",
        "        vocab = pred.size(-1)\n",
        "        pred_flat = pred.reshape(-1, vocab)\n",
        "        y_flat = y.reshape(-1)\n",
        "        loss = self.criterion(pred_flat, y_flat) / norm\n",
        "        return loss.data * norm, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYN6fj1fZ3fx"
      },
      "source": [
        "### Final Run Epoch Function for Copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lp437rCNZ3fx"
      },
      "outputs": [],
      "source": [
        "def run_epoch(data_iter, model, loss_compute, optimizer, scheduler, mode=\"train\"):\n",
        "    total_tokens = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(data_iter):\n",
        "        pred = model(batch.src, batch.tgt, batch.src_mask, batch.tgt_mask)\n",
        "        num_loss, tensor_loss = loss_compute(pred, batch.tgt_y, batch.ntokens)\n",
        "        if mode == \"train\":\n",
        "            tensor_loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            scheduler.step()\n",
        "        total_loss += num_loss\n",
        "        total_tokens += batch.ntokens\n",
        "\n",
        "    return total_loss / total_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLCboqYwZ3fx"
      },
      "source": [
        "### Greedy Decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7st-nodqZ3fx"
      },
      "outputs": [],
      "source": [
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.LongTensor([[start_symbol]])\n",
        "    for _ in range(max_len - 1):\n",
        "        tgt_mask = subsequent_mask(ys.size(1))\n",
        "        x = model.decode(memory, src_mask, ys, tgt_mask)\n",
        "        pred = model.generator(x[:, -1])\n",
        "        _, max_indices = torch.max(pred, dim=-1)\n",
        "        max_indices = max_indices.data[0]\n",
        "        ys = torch.cat([ys, torch.ones(1,1).type_as(src.data).fill_(max_indices)], dim=-1)\n",
        "    return ys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS2PTWOWZ3fx"
      },
      "source": [
        "### Training Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWZhRCERZ3fx",
        "outputId": "8f4c4d14-5e8e-4b10-a53c-2d916b6775d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Epoch 0 Loss: 0.0109\n",
            "Epoch 1 Loss: 0.0094\n",
            "Epoch 2 Loss: 0.0085\n",
            "Epoch 3 Loss: 0.0079\n",
            "Epoch 4 Loss: 0.0073\n",
            "Epoch 5 Loss: 0.0070\n",
            "Epoch 6 Loss: 0.0066\n",
            "Epoch 7 Loss: 0.0060\n",
            "Epoch 8 Loss: 0.0054\n",
            "Epoch 9 Loss: 0.0050\n",
            "Epoch 10 Loss: 0.0044\n",
            "Epoch 11 Loss: 0.0038\n",
            "Epoch 12 Loss: 0.0033\n",
            "Epoch 13 Loss: 0.0028\n",
            "Epoch 14 Loss: 0.0024\n",
            "Epoch 15 Loss: 0.0022\n",
            "Epoch 16 Loss: 0.0017\n",
            "Epoch 17 Loss: 0.0015\n",
            "Epoch 18 Loss: 0.0013\n",
            "Epoch 19 Loss: 0.0012\n",
            "Epoch 20 Loss: 0.0010\n",
            "Epoch 21 Loss: 0.0008\n",
            "Epoch 22 Loss: 0.0008\n",
            "Epoch 23 Loss: 0.0007\n",
            "Epoch 24 Loss: 0.0007\n",
            "Epoch 25 Loss: 0.0006\n",
            "Epoch 26 Loss: 0.0007\n",
            "Epoch 27 Loss: 0.0005\n",
            "Epoch 28 Loss: 0.0004\n",
            "Epoch 29 Loss: 0.0005\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "# Create small model for testing\n",
        "V = 11\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "model = make_model(V, V, N=2, d_model=64, d_ff=128, h=4, dropout=0.1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.5, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "def rate(step, model_size=64, factor=1.0, warmup=400):\n",
        "    if step == 0:\n",
        "        step = 1\n",
        "    return factor * (model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5)))\n",
        "\n",
        "scheduler = LambdaLR(optimizer, lr_lambda=lambda step: rate(step))\n",
        "\n",
        "print(\"Training...\")\n",
        "for epoch in range(30):\n",
        "    model.train()\n",
        "    loss_compute = SimpleLossCompute(model.generator, criterion)\n",
        "    loss = run_epoch(data_gen(V, batch_size=30, nbatches=20), model, loss_compute, optimizer, scheduler, mode=\"train\")\n",
        "    print(f\"Epoch {epoch} Loss: {loss:.4f}\")\n",
        "\n",
        "print(\"\\nTraining complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXfY8RYtZ3fy"
      },
      "source": [
        "### Test Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3VYphjuZ3fy",
        "outputId": "93ba401c-c683-414e-de01-e41fe9560aa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source: tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
            "Generated: tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
            "\n",
            "Success! True\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "src = torch.LongTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
        "src_mask = torch.ones(1, 1, 10)\n",
        "\n",
        "print(\"Source:\", src)\n",
        "result = greedy_decode(model, src, src_mask, max_len=10, start_symbol=1)\n",
        "print(\"Generated:\", result)\n",
        "print(\"\\nSuccess!\", torch.equal(src, result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4esHD2bjZ3fy"
      },
      "source": [
        "## ðŸŽ‰ Congratulations! ðŸŽ‰"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZAXao_hZ3fy"
      },
      "source": [
        "You've implemented a Transformer from scratch and trained it successfully!\n",
        "\n",
        "### Resources:\n",
        "- [Original Paper](https://arxiv.org/pdf/1706.03762)\n",
        "- [Harvard NLP Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "annotated-transformer",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}