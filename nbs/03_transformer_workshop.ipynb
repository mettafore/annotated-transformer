{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mettafore/annotated-transformer/blob/master/nbs/03_transformer_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3J94HFr0Zice"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4m3EFdlZice"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QszRUt8rZicf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from IPython.core.magic import register_cell_magic\n",
        "from IPython.display import HTML, display\n",
        "import html\n",
        "import math\n",
        "import copy\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZh9DaF4Zicf"
      },
      "source": [
        "https://arxiv.org/pdf/1706.03762"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMEvFlN4Zicf"
      },
      "source": [
        "I will be doing an implementation of the seminal paper \"Attention Is All You Need.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYKqkBPgZicf"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60kPvO1yZicf"
      },
      "source": [
        "Implement the scaled dot-product attention mechanism. Remember the formula: Attention(Q,K,V) = softmax(QK^T / âˆšd_k)V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQ8ILvQAZicg"
      },
      "outputs": [],
      "source": [
        "def attention(Q, K, V, dropout, mask):\n",
        "    \"\"\"Scaled Dot-Product Attention\"\"\"\n",
        "    sqrt_d_k = math.sqrt(K.size(-1))\n",
        "\n",
        "    # TODO: Compute attention scores (Q @ K^T / sqrt_d_k)\n",
        "    scores =\n",
        "\n",
        "    # TODO: Apply mask if provided (set masked positions to -1e9)\n",
        "    if mask is not None:\n",
        "        scores =\n",
        "\n",
        "    # TODO: Apply softmax to get attention weights\n",
        "    attention_weights =\n",
        "\n",
        "    # TODO: Apply dropout if provided\n",
        "    if dropout is not None:\n",
        "        attention_weights =\n",
        "\n",
        "    # TODO: Multiply attention weights by V\n",
        "    output =\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xL0XeN8Zicg"
      },
      "source": [
        "#### Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ac_E9cvZicg"
      },
      "outputs": [],
      "source": [
        "# Test attention\n",
        "Q = torch.randn(2, 1, 4, 8)\n",
        "K = torch.randn(2, 1, 4, 8)\n",
        "V = torch.randn(2, 1, 4, 8)\n",
        "result = attention(Q, K, V, None, None)\n",
        "print(\"Result shape:\", result.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIQQtCyFZicg"
      },
      "source": [
        "## MultiHeadedAttention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLMoi27cZicg"
      },
      "source": [
        "Implement multi-head attention. Split d_model into h heads, apply attention to each, then concatenate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukwz0C8YZicg"
      },
      "outputs": [],
      "source": [
        "class MultiHeadedAttention(torch.nn.Module):\n",
        "    def __init__(self, h, d_model, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % h == 0\n",
        "\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.dropout = torch.nn.Dropout(p=dropout)\n",
        "        self.attn = None\n",
        "\n",
        "        # TODO: Create 4 linear layers (Q, K, V projections + final output)\n",
        "        self.linear_layers =\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        # TODO: Project Q, K, V using first 3 linear layers\n",
        "        Q =\n",
        "        K =\n",
        "        V =\n",
        "\n",
        "        # TODO: Reshape to split into h heads: (batch, seq_len, d_model) -> (batch, h, seq_len, d_k)\n",
        "        Q = Q.reshape(batch_size, -1, self.h, self.d_k).transpose(1,2)\n",
        "        K =\n",
        "        V =\n",
        "\n",
        "        # TODO: Apply mask if provided\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1)\n",
        "\n",
        "        # TODO: Apply attention\n",
        "        x = attention(Q, K, V, self.dropout, mask)\n",
        "\n",
        "        # TODO: Concatenate heads back: (batch, h, seq_len, d_k) -> (batch, seq_len, d_model)\n",
        "        x = x.transpose(1,2).reshape(batch_size, -1, self.h * self.d_k)\n",
        "\n",
        "        # TODO: Apply final linear projection\n",
        "        output =\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTkIGZ59Zicg"
      },
      "source": [
        "#### Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwdMUmIUZicg"
      },
      "outputs": [],
      "source": [
        "# Test MultiHeadedAttention\n",
        "mha = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
        "x = torch.randn(2, 10, 512)\n",
        "output = mha(x, x, x)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZOwNOHoZicg"
      },
      "source": [
        "## PositionwiseFeedForward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us95Csx0Zicg"
      },
      "source": [
        "Implement the position-wise feed-forward network: FFN(x) = max(0, xW1 + b1)W2 + b2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WaAbwLCZicg"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedForward(torch.nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        # TODO: Create two linear layers: d_model -> d_ff -> d_model\n",
        "        self.linear_layer =\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.dropout =\n",
        "        self.output_layer =\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Apply linear -> ReLU -> dropout -> linear\n",
        "        x =\n",
        "        x = self.relu(x)\n",
        "        x =\n",
        "        x =\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0pHdyvjZicg"
      },
      "source": [
        "#### Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLgNer9hZicg"
      },
      "outputs": [],
      "source": [
        "# Test PositionwiseFeedForward\n",
        "ffn = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
        "x = torch.randn(2, 10, 512)\n",
        "output = ffn(x)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VBbXgHIZich"
      },
      "source": [
        "## Positional Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvWtUdoqZich"
      },
      "source": [
        "Since attention has no notion of position, we add positional encodings using sin/cos functions of different frequencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaZmuRwlZich"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(torch.nn.Module):\n",
        "    def __init__(self, d_model, dropout, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.dropout = torch.nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        even_indices = torch.arange(0, d_model, 2)\n",
        "\n",
        "        # TODO: Create position vector [0, 1, 2, ..., max_len-1]\n",
        "        position =\n",
        "\n",
        "        # TODO: Calculate div_term for the denominator\n",
        "        div_term = torch.exp(-even_indices * (torch.log(torch.tensor(10000.0)) / d_model))\n",
        "\n",
        "        # TODO: Apply sin to even indices, cos to odd indices\n",
        "        pe[:, ::2] =\n",
        "        pe[:, 1::2] =\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.size(1)\n",
        "        # TODO: Add positional encoding to x\n",
        "        x =\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsAAYu_VZich"
      },
      "source": [
        "#### Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1DYgvy6Zich"
      },
      "outputs": [],
      "source": [
        "# Test PositionalEncoding\n",
        "pe = PositionalEncoding(d_model=512, dropout=0.1)\n",
        "x = torch.zeros(2, 10, 512)\n",
        "output = pe(x)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ekNIOOBZich"
      },
      "source": [
        "## Encoder Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqFsv_6WZich"
      },
      "source": [
        "Each encoder layer has two sub-layers: multi-head self-attention and feed-forward network, each with residual connections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKmSDHy_Zich"
      },
      "source": [
        "### Sublayer Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGrvZG6WZich"
      },
      "outputs": [],
      "source": [
        "class SublayerConnection(torch.nn.Module):\n",
        "    \"A residual connection followed by layer norm\"\n",
        "    def __init__(self, size, dropout):\n",
        "        super().__init__()\n",
        "        # TODO: Create LayerNorm and Dropout\n",
        "        self.layer_norm =\n",
        "        self.dropout =\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        # TODO: Apply LayerNorm -> sublayer -> dropout -> add residual (x + dropout(sublayer(layer_norm(x))))\n",
        "        y = self.layer_norm(x)\n",
        "        y = sublayer(y)\n",
        "        y =\n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHp11Eu3Zich"
      },
      "source": [
        "### Final clones function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFALFlRUZich"
      },
      "outputs": [],
      "source": [
        "def clones(module, N):\n",
        "    \"Produce N identical layers\"\n",
        "    # TODO: Create N deep copies of module\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_dA1AaVZich"
      },
      "source": [
        "### Final EncoderLayer Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htRtux1GZich"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(torch.nn.Module):\n",
        "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        # TODO: Create 2 SublayerConnections\n",
        "        self.sublayer =\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # TODO: Apply self-attention with residual\n",
        "        x =\n",
        "        # TODO: Apply feed-forward with residual\n",
        "        x =\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIA2e5gQZich"
      },
      "source": [
        "#### Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjErLx2EZich"
      },
      "outputs": [],
      "source": [
        "# Test EncoderLayer\n",
        "attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
        "ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
        "encoder_layer = EncoderLayer(size=512, self_attn=attn, feed_forward=ff, dropout=0.1)\n",
        "x = torch.randn(2, 10, 512)\n",
        "output = encoder_layer(x, None)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOLpq8PUZich"
      },
      "source": [
        "## Encoder Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XE5gVr3Zich"
      },
      "source": [
        "Stack N encoder layers together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQAfvbBTZich"
      },
      "outputs": [],
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    \"Stack of N encoder layers\"\n",
        "    def __init__(self, layer, N):\n",
        "        super().__init__()\n",
        "        # TODO: Create N copies of layer\n",
        "        self.encoders =\n",
        "        # TODO: Create final LayerNorm\n",
        "        self.layer_norm =\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # TODO: Pass x through each encoder layer\n",
        "        for encoder in self.encoders:\n",
        "            x =\n",
        "        # TODO: Apply final layer norm\n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q-XUtVaZich"
      },
      "source": [
        "#### Unit test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rP2vJYKkZici"
      },
      "outputs": [],
      "source": [
        "# Test Encoder\n",
        "encoder = Encoder(encoder_layer, N=6)\n",
        "x = torch.randn(2, 10, 512)\n",
        "output = encoder(x, None)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkj_x0t7Zici"
      },
      "source": [
        "## Decoder Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lbaUWY-Zici"
      },
      "source": [
        "Each decoder layer has three sub-layers: masked self-attention, cross-attention to encoder output, and feed-forward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxSOvlFqZici"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(torch.nn.Module):\n",
        "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.src_attn = src_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        # TODO: Create 3 SublayerConnections\n",
        "        self.sublayers =\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        # TODO: Apply masked self-attention\n",
        "        x =\n",
        "        # TODO: Apply cross-attention to encoder output (memory)\n",
        "        x =\n",
        "        # TODO: Apply feed-forward\n",
        "        x =\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V31JlmNfZici"
      },
      "source": [
        "#### Unit test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tn-C6W2wZici"
      },
      "outputs": [],
      "source": [
        "# Test DecoderLayer\n",
        "attn1 = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
        "attn2 = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
        "ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
        "decoder_layer = DecoderLayer(size=512, self_attn=attn1, src_attn=attn2, feed_forward=ff, dropout=0.1)\n",
        "x = torch.randn(2, 10, 512)\n",
        "memory = torch.randn(2, 10, 512)\n",
        "output = decoder_layer(x, memory, None, None)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDmot0g1Zici"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyp1JvNXZici"
      },
      "source": [
        "Stack N decoder layers together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAfBuLEjZici"
      },
      "outputs": [],
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "    def __init__(self, layer, N):\n",
        "        super().__init__()\n",
        "        # TODO: Create N copies of layer\n",
        "        self.layers =\n",
        "        # TODO: Create final LayerNorm\n",
        "        self.layer_norm =\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        # TODO: Pass through each decoder layer\n",
        "        for layer in self.layers:\n",
        "            x =\n",
        "        # TODO: Apply final layer norm\n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrNBxJ37Zici"
      },
      "source": [
        "### Unit test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6NO-X9yZici"
      },
      "outputs": [],
      "source": [
        "# Test Decoder\n",
        "decoder = Decoder(decoder_layer, N=6)\n",
        "x = torch.randn(2, 10, 512)\n",
        "memory = torch.randn(2, 10, 512)\n",
        "output = decoder(x, memory, None, None)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f7P3yTtZici"
      },
      "source": [
        "## Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a63-UQndZici"
      },
      "source": [
        "Convert token IDs to dense vectors, scaled by sqrt(d_model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYf860oMZici"
      },
      "outputs": [],
      "source": [
        "class Embeddings(torch.nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        # TODO: Create embedding layer\n",
        "        self.embedding =\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Apply embedding and scale by sqrt(d_model)\n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsnQCKsHZici"
      },
      "source": [
        "### Unit test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDEarBUZZici"
      },
      "outputs": [],
      "source": [
        "# Test Embeddings\n",
        "emb = Embeddings(d_model=512, vocab=1000)\n",
        "x = torch.randint(0, 1000, (2, 10))\n",
        "output = emb(x)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMHolkhOZici"
      },
      "source": [
        "## Generator class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "766owsQ-Zici"
      },
      "source": [
        "Final linear layer + log softmax to convert decoder output to token probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQq-SsfaZici"
      },
      "outputs": [],
      "source": [
        "class Generator(torch.nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super().__init__()\n",
        "        # TODO: Create linear layer and log softmax\n",
        "        self.linear =\n",
        "        self.logsoftmax =\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Apply linear -> log_softmax\n",
        "        x =\n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5IthzpsZici"
      },
      "source": [
        "#### Unit test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRCQ5TbvZici"
      },
      "outputs": [],
      "source": [
        "# Test Generator\n",
        "gen = Generator(d_model=512, vocab=1000)\n",
        "x = torch.randn(2, 10, 512)\n",
        "output = gen(x)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lk5IwmJhZici"
      },
      "source": [
        "### Final Encoder Decoder Function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuTmYkp_Zicj"
      },
      "outputs": [],
      "source": [
        "class EncoderDecoder(torch.nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.generator = generator\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        x = self.src_embed(src)\n",
        "        return self.encoder(x, src_mask)\n",
        "\n",
        "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
        "        x = self.tgt_embed(tgt)\n",
        "        return self.decoder(x, memory, src_mask, tgt_mask)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        memory = self.encode(src, src_mask)\n",
        "        return self.decode(memory, src_mask, tgt, tgt_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3ruPMTkZicj"
      },
      "source": [
        "## Make Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BAviAjmZicj"
      },
      "source": [
        "Helper function to construct the full transformer model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_C1TvDnEZicj"
      },
      "outputs": [],
      "source": [
        "def make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
        "    \"Construct transformer model from hyperparameters\"\n",
        "    # Create shared components\n",
        "    multi_head_attentions = [copy.deepcopy(MultiHeadedAttention(h, d_model, dropout)) for _ in range(3)]\n",
        "    feedforward_layers = [copy.deepcopy(PositionwiseFeedForward(d_model, d_ff, dropout)) for _ in range(2)]\n",
        "    positional_encoding = [PositionalEncoding(d_model, dropout) for _ in range(2)]\n",
        "\n",
        "    src_embedding_layer = Embeddings(d_model, src_vocab)\n",
        "    tgt_embeddings_layer = Embeddings(d_model, tgt_vocab)\n",
        "    src_embed = torch.nn.Sequential(src_embedding_layer, positional_encoding[0])\n",
        "    tgt_embed = torch.nn.Sequential(tgt_embeddings_layer, positional_encoding[1])\n",
        "\n",
        "    encoder_layer = EncoderLayer(d_model, multi_head_attentions[0], feedforward_layers[0], dropout)\n",
        "    decoder_layer = DecoderLayer(d_model, multi_head_attentions[1], multi_head_attentions[2], feedforward_layers[1], dropout)\n",
        "\n",
        "    encoder = Encoder(encoder_layer, N)\n",
        "    decoder = Decoder(decoder_layer, N)\n",
        "    generator = Generator(d_model, tgt_vocab)\n",
        "\n",
        "    encoder_decoder = EncoderDecoder(encoder, decoder, src_embed, tgt_embed, generator)\n",
        "\n",
        "    # Initialize parameters\n",
        "    for p in encoder_decoder.parameters():\n",
        "        if p.dim() > 1:\n",
        "            torch.nn.init.xavier_uniform_(p)\n",
        "\n",
        "    return encoder_decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukACVjTgZicj"
      },
      "source": [
        "## Copy Code Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCvwNMj5Zicj"
      },
      "source": [
        "Training utilities for the copy task (provided complete)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HdPCjbCZicj"
      },
      "source": [
        "### Final subsequent mask function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTVtrfsMZicj"
      },
      "outputs": [],
      "source": [
        "def subsequent_mask(size):\n",
        "    \"Create mask to prevent attention to future positions\"\n",
        "    lower_t = torch.ones([size, size]).tril().bool()\n",
        "    lower_t = lower_t.unsqueeze(0)\n",
        "    return lower_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RyixtEaZicj"
      },
      "source": [
        "### Final Batch Class for copy example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AT4AYF2Zicj"
      },
      "outputs": [],
      "source": [
        "class Batch:\n",
        "    def __init__(self, src, tgt=None, pad=2):\n",
        "        self.src = src\n",
        "        self.src_mask = (src != pad).unsqueeze(-2)\n",
        "        if tgt is not None:\n",
        "            self.tgt = tgt[:, :-1]\n",
        "            self.tgt_y = tgt[:,1:]\n",
        "            self.pad_tgt_mask = (self.tgt!=pad).unsqueeze(-2)\n",
        "            self.subseq_tgt_mask = subsequent_mask(self.tgt.size(1))\n",
        "            self.tgt_mask = self.pad_tgt_mask & self.subseq_tgt_mask\n",
        "            self.ntokens = (self.tgt_y!=pad).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spDiFSWgZicj"
      },
      "source": [
        "### Final Data Gen Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HP3OfXGgZicj"
      },
      "outputs": [],
      "source": [
        "def data_gen(V, batch_size, nbatches):\n",
        "    \"Generate random data for a src-tgt copy task\"\n",
        "    for i in range(nbatches):\n",
        "        random_int = np.random.randint(1, V, size=[batch_size, 10])\n",
        "        random_int[:,0] = 1\n",
        "        random_int = torch.tensor(random_int)\n",
        "        src = random_int\n",
        "        tgt = random_int\n",
        "        yield Batch(src, tgt, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auAnSQ5IZicj"
      },
      "source": [
        "### Final Simple Loss Compute Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elW-JtvIZicj"
      },
      "outputs": [],
      "source": [
        "class SimpleLossCompute:\n",
        "    def __init__(self, generator, criterion):\n",
        "        self.generator = generator\n",
        "        self.criterion = criterion\n",
        "\n",
        "    def __call__(self, x, y, norm):\n",
        "        pred = self.generator(x)\n",
        "        vocab = pred.size(-1)\n",
        "        pred_flat = pred.reshape(-1, vocab)\n",
        "        y_flat = y.reshape(-1)\n",
        "        loss = self.criterion(pred_flat, y_flat) / norm\n",
        "        return loss.data * norm, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viNd_9zhZicj"
      },
      "source": [
        "### Final Run Epoch Function for Copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E63LTnWJZicj"
      },
      "outputs": [],
      "source": [
        "def run_epoch(data_iter, model, loss_compute, optimizer, scheduler, mode=\"train\"):\n",
        "    total_tokens = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(data_iter):\n",
        "        pred = model(batch.src, batch.tgt, batch.src_mask, batch.tgt_mask)\n",
        "        num_loss, tensor_loss = loss_compute(pred, batch.tgt_y, batch.ntokens)\n",
        "        if mode == \"train\":\n",
        "            tensor_loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            scheduler.step()\n",
        "        total_loss += num_loss\n",
        "        total_tokens += batch.ntokens\n",
        "\n",
        "    return total_loss / total_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_HSBKBWZicj"
      },
      "source": [
        "### Greedy Decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZ2nxDY2Zicj"
      },
      "outputs": [],
      "source": [
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.LongTensor([[start_symbol]])\n",
        "    for _ in range(max_len - 1):\n",
        "        tgt_mask = subsequent_mask(ys.size(1))\n",
        "        x = model.decode(memory, src_mask, ys, tgt_mask)\n",
        "        pred = model.generator(x[:, -1])\n",
        "        _, max_indices = torch.max(pred, dim=-1)\n",
        "        max_indices = max_indices.data[0]\n",
        "        ys = torch.cat([ys, torch.ones(1,1).type_as(src.data).fill_(max_indices)], dim=-1)\n",
        "    return ys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Ul9L8KZicj"
      },
      "source": [
        "### Training Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Mlgxuf6Zicj"
      },
      "outputs": [],
      "source": [
        "# Create small model for testing\n",
        "V = 11\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "model = make_model(V, V, N=2, d_model=64, d_ff=128, h=4, dropout=0.1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.5, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "def rate(step, model_size=64, factor=1.0, warmup=400):\n",
        "    if step == 0:\n",
        "        step = 1\n",
        "    return factor * (model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5)))\n",
        "\n",
        "scheduler = LambdaLR(optimizer, lr_lambda=lambda step: rate(step))\n",
        "\n",
        "print(\"Training...\")\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    loss_compute = SimpleLossCompute(model.generator, criterion)\n",
        "    loss = run_epoch(data_gen(V, batch_size=30, nbatches=20), model, loss_compute, optimizer, scheduler, mode=\"train\")\n",
        "    print(f\"Epoch {epoch} Loss: {loss:.4f}\")\n",
        "\n",
        "print(\"\\nTraining complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSdU_yGtZicj"
      },
      "source": [
        "### Test Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xy_SRerNZicj"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "src = torch.LongTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
        "src_mask = torch.ones(1, 1, 10)\n",
        "\n",
        "print(\"Source:\", src)\n",
        "result = greedy_decode(model, src, src_mask, max_len=10, start_symbol=1)\n",
        "print(\"Generated:\", result)\n",
        "print(\"\\nSuccess!\", torch.equal(src, result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPkynPkoZicj"
      },
      "source": [
        "## ðŸŽ‰ Congratulations! ðŸŽ‰"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5htQuTTFZick"
      },
      "source": [
        "You've implemented a Transformer from scratch and trained it successfully!\n",
        "\n",
        "### Resources:\n",
        "- [Original Paper](https://arxiv.org/pdf/1706.03762)\n",
        "- [Harvard NLP Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}