# Autogenerated by nbdev

d = { 'settings': { 'branch': 'master',
                'doc_baseurl': '/annotated-transformer',
                'doc_host': 'https://mettafore.github.io',
                'git_url': 'https://github.com/mettafore/annotated-transformer',
                'lib_path': 'annotated_transformer'},
  'syms': { 'annotated_transformer.attention': { 'annotated_transformer.attention.Decoder': ( 'attention_is_all_you_need_dup1.html#decoder',
                                                                                              'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.Decoder.__init__': ( 'attention_is_all_you_need_dup1.html#decoder.__init__',
                                                                                                       'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.Decoder.forward': ( 'attention_is_all_you_need_dup1.html#decoder.forward',
                                                                                                      'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.DecoderLayer': ( 'attention_is_all_you_need_dup1.html#decoderlayer',
                                                                                                   'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.DecoderLayer.__init__': ( 'attention_is_all_you_need_dup1.html#decoderlayer.__init__',
                                                                                                            'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.DecoderLayer.forward': ( 'attention_is_all_you_need_dup1.html#decoderlayer.forward',
                                                                                                           'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.Embeddings': ( 'attention_is_all_you_need_dup1.html#embeddings',
                                                                                                 'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.Embeddings.__init__': ( 'attention_is_all_you_need_dup1.html#embeddings.__init__',
                                                                                                          'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.Embeddings.forward': ( 'attention_is_all_you_need_dup1.html#embeddings.forward',
                                                                                                         'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.Encoder': ( 'attention_is_all_you_need_dup1.html#encoder',
                                                                                              'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.Encoder.__init__': ( 'attention_is_all_you_need_dup1.html#encoder.__init__',
                                                                                                       'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.Encoder.forward': ( 'attention_is_all_you_need_dup1.html#encoder.forward',
                                                                                                      'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.EncoderDecoder': ( 'attention_is_all_you_need_dup1.html#encoderdecoder',
                                                                                                     'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.EncoderDecoder.__init__': ( 'attention_is_all_you_need_dup1.html#encoderdecoder.__init__',
                                                                                                              'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.EncoderDecoder.decode': ( 'attention_is_all_you_need_dup1.html#encoderdecoder.decode',
                                                                                                            'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.EncoderDecoder.encode': ( 'attention_is_all_you_need_dup1.html#encoderdecoder.encode',
                                                                                                            'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.EncoderDecoder.forward': ( 'attention_is_all_you_need_dup1.html#encoderdecoder.forward',
                                                                                                             'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.EncoderLayer': ( 'attention_is_all_you_need_dup1.html#encoderlayer',
                                                                                                   'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.EncoderLayer.__init__': ( 'attention_is_all_you_need_dup1.html#encoderlayer.__init__',
                                                                                                            'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.EncoderLayer.forward': ( 'attention_is_all_you_need_dup1.html#encoderlayer.forward',
                                                                                                           'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.Generator': ( 'attention_is_all_you_need_dup1.html#generator',
                                                                                                'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.Generator.__init__': ( 'attention_is_all_you_need_dup1.html#generator.__init__',
                                                                                                         'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.Generator.forward': ( 'attention_is_all_you_need_dup1.html#generator.forward',
                                                                                                        'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.MultiHeadedAttention': ( 'attention_is_all_you_need_dup1.html#multiheadedattention',
                                                                                                           'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.MultiHeadedAttention.__init__': ( 'attention_is_all_you_need_dup1.html#multiheadedattention.__init__',
                                                                                                                    'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.MultiHeadedAttention.forward': ( 'attention_is_all_you_need_dup1.html#multiheadedattention.forward',
                                                                                                                   'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.PositionalEncoding': ( 'attention_is_all_you_need_dup1.html#positionalencoding',
                                                                                                         'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.PositionalEncoding.__init__': ( 'attention_is_all_you_need_dup1.html#positionalencoding.__init__',
                                                                                                                  'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.PositionalEncoding.forward': ( 'attention_is_all_you_need_dup1.html#positionalencoding.forward',
                                                                                                                 'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.PositionwiseFeedForward': ( 'attention_is_all_you_need_dup1.html#positionwisefeedforward',
                                                                                                              'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.PositionwiseFeedForward.__init__': ( 'attention_is_all_you_need_dup1.html#positionwisefeedforward.__init__',
                                                                                                                       'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.PositionwiseFeedForward.forward': ( 'attention_is_all_you_need_dup1.html#positionwisefeedforward.forward',
                                                                                                                      'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.SublayerConnection': ( 'attention_is_all_you_need_dup1.html#sublayerconnection',
                                                                                                         'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.SublayerConnection.__init__': ( 'attention_is_all_you_need_dup1.html#sublayerconnection.__init__',
                                                                                                                  'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.SublayerConnection.forward': ( 'attention_is_all_you_need_dup1.html#sublayerconnection.forward',
                                                                                                                 'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.attention': ( 'attention_is_all_you_need_dup1.html#attention',
                                                                                                'annotated_transformer/attention.py'),
                                                 'annotated_transformer.attention.clones': ( 'attention_is_all_you_need_dup1.html#clones',
                                                                                             'annotated_transformer/attention.py')},
            'annotated_transformer.core': {'annotated_transformer.core.foo': ('core.html#foo', 'annotated_transformer/core.py')}}}
