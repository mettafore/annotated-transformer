{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mettafore/annotated-transformer/blob/master/04_transformer_workshop_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqbRWNHHYKJx"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3OOKkfvyYKJx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from IPython.core.magic import register_cell_magic\n",
        "from IPython.display import HTML, display\n",
        "import html\n",
        "import math\n",
        "import copy\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00yTFEiVYKJy"
      },
      "source": [
        "https://arxiv.org/pdf/1706.03762"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCW-Gq_3YKJy"
      },
      "source": [
        "I will be doing an implementation of the seminal paper \"Attention Is All You Need.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I2TgquXYKJy"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oioqCu5HYKJy"
      },
      "source": [
        "Implement the scaled dot-product attention mechanism. Remember the formula: Attention(Q,K,V) = softmax(QK^T / âˆšd_k)V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1vlP1PdGYKJy"
      },
      "outputs": [],
      "source": [
        "def attention(Q, K, V, dropout, mask):\n",
        "    \"\"\"Scaled Dot-Product Attention\"\"\"\n",
        "    sqrt_d_k = math.sqrt(K.size(-1))\n",
        "    scores = Q @ K.transpose(-2,-1) / sqrt_d_k\n",
        "\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask==0, -1e9)\n",
        "\n",
        "    attention_weights = torch.softmax(scores, dim=-1)\n",
        "\n",
        "    if dropout is not None:\n",
        "        attention_weights = dropout(attention_weights)\n",
        "\n",
        "    output = attention_weights @ V\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jibXSMfeYKJy"
      },
      "source": [
        "#### Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWxX_ja2YKJy",
        "outputId": "4a5591f2-57eb-4bf0-8e61-b32f1d753e58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result shape: torch.Size([2, 1, 4, 8])\n"
          ]
        }
      ],
      "source": [
        "# Test attention\n",
        "Q = torch.randn(2, 1, 4, 8)\n",
        "K = torch.randn(2, 1, 4, 8)\n",
        "V = torch.randn(2, 1, 4, 8)\n",
        "result = attention(Q, K, V, None, None)\n",
        "print(\"Result shape:\", result.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5d-XXjVYKJz"
      },
      "source": [
        "## MultiHeadedAttention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i21Rlwt1YKJz"
      },
      "source": [
        "Implement multi-head attention. Split d_model into h heads, apply attention to each, then concatenate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b844NQH8YKJz"
      },
      "outputs": [],
      "source": [
        "class MultiHeadedAttention(torch.nn.Module):\n",
        "    def __init__(self, h, d_model, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % h == 0\n",
        "\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.dropout = torch.nn.Dropout(p=dropout)\n",
        "        self.attn = None\n",
        "\n",
        "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(d_model, d_model) for x in range(4)])\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        Q = self.linear_layers[0](query)\n",
        "        K = self.linear_layers[1](key)\n",
        "        V = self.linear_layers[2](value)\n",
        "\n",
        "        Q = Q.reshape(batch_size, -1, self.h, self.d_k).transpose(1,2)\n",
        "        K = K.reshape(batch_size, -1, self.h, self.d_k).transpose(1,2)\n",
        "        V = V.reshape(batch_size, -1, self.h, self.d_k).transpose(1,2)\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1)\n",
        "\n",
        "        x = attention(Q, K, V, self.dropout, mask)\n",
        "\n",
        "        x = x.transpose(1,2).reshape(batch_size, -1, self.h * self.d_k)\n",
        "\n",
        "        output = self.linear_layers[3](x)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QntnkK9dYKJz"
      },
      "source": [
        "#### Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y50hUWu5YKJz",
        "outputId": "85b7de99-1d65-462b-9a96-917f7a15e4b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 10, 512]) Output shape: torch.Size([2, 10, 512])\n"
          ]
        }
      ],
      "source": [
        "# Test MultiHeadedAttention\n",
        "mha = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
        "x = torch.randn(2, 10, 512)\n",
        "output = mha(x, x, x)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEwPoLQMYKJz"
      },
      "source": [
        "## PositionwiseFeedForward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Es80NcCYKJz"
      },
      "source": [
        "Implement the position-wise feed-forward network: FFN(x) = max(0, xW1 + b1)W2 + b2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ljqo3cXEYKJz"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedForward(torch.nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.linear_layer = torch.nn.Linear(d_model, d_ff)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.dropout = torch.nn.Dropout(p=dropout)\n",
        "        self.output_layer = torch.nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear_layer(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq47xi6LYKJz"
      },
      "source": [
        "#### Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsCf3gL1YKJz",
        "outputId": "cf9bad68-f334-4547-af5b-8974b416416f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 10, 512]) Output shape: torch.Size([2, 10, 512])\n"
          ]
        }
      ],
      "source": [
        "# Test PositionwiseFeedForward\n",
        "ffn = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
        "x = torch.randn(2, 10, 512)\n",
        "output = ffn(x)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqkjo8hFYKJz"
      },
      "source": [
        "## Positional Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoanLadgYKJz"
      },
      "source": [
        "Since attention has no notion of position, we add positional encodings using sin/cos functions of different frequencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0SVxlTZQYKJz"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(torch.nn.Module):\n",
        "    def __init__(self, d_model, dropout, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.dropout = torch.nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        even_indices = torch.arange(0, d_model, 2)\n",
        "\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "\n",
        "        div_term = torch.exp(-even_indices * (torch.log(torch.tensor(10000.0)) / d_model))\n",
        "\n",
        "        pe[:, ::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.size(1)\n",
        "        x = x + self.pe[:,:seq_len,:].requires_grad_(False)\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNCRjejxYKJz"
      },
      "source": [
        "#### Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCF9IofbYKJz",
        "outputId": "7e20ec91-59da-4973-c9bb-b9f0f623ddf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 10, 512]) Output shape: torch.Size([2, 10, 512])\n"
          ]
        }
      ],
      "source": [
        "# Test PositionalEncoding\n",
        "pe = PositionalEncoding(d_model=512, dropout=0.1)\n",
        "x = torch.zeros(2, 10, 512)\n",
        "output = pe(x)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbgQtUpFYKJz"
      },
      "source": [
        "## Encoder Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x09Rt9FvYKJ0"
      },
      "source": [
        "Each encoder layer has two sub-layers: multi-head self-attention and feed-forward network, each with residual connections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvaz55J2YKJ0"
      },
      "source": [
        "### Sublayer Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "URS4RONKYKJ0"
      },
      "outputs": [],
      "source": [
        "class SublayerConnection(torch.nn.Module):\n",
        "    \"A residual connection followed by layer norm\"\n",
        "    def __init__(self, size, dropout):\n",
        "        super().__init__()\n",
        "        self.layer_norm = torch.nn.LayerNorm(size)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        y = self.layer_norm(x)\n",
        "        y = sublayer(y)\n",
        "        y = self.dropout(y)\n",
        "        return x + y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZDaYglrYKJ0"
      },
      "source": [
        "### Final clones function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RHVflAErYKJ0"
      },
      "outputs": [],
      "source": [
        "def clones(module, N):\n",
        "    \"Produce N identical layers\"\n",
        "    return torch.nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pRa_THaYKJ0"
      },
      "source": [
        "### Final EncoderLayer Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XpAfjVffYKJ0"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(torch.nn.Module):\n",
        "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = torch.nn.ModuleList([SublayerConnection(size, dropout) for _ in range(2)])\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
        "        x = self.sublayer[1](x, lambda x: self.feed_forward(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9oDVz7YYKJ0"
      },
      "source": [
        "#### Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ-1Tch3YKJ0",
        "outputId": "2f7ea62a-c2ae-46e6-f25a-df562a50c1b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 10, 512]) Output shape: torch.Size([2, 10, 512])\n"
          ]
        }
      ],
      "source": [
        "# Test EncoderLayer\n",
        "attn = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
        "ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
        "encoder_layer = EncoderLayer(size=512, self_attn=attn, feed_forward=ff, dropout=0.1)\n",
        "x = torch.randn(2, 10, 512)\n",
        "output = encoder_layer(x, None)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SCAJeiqYKJ0"
      },
      "source": [
        "## Encoder Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05ZcLyd6YKJ0"
      },
      "source": [
        "Stack N encoder layers together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uxUv7oYtYKJ0"
      },
      "outputs": [],
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    \"Stack of N encoder layers\"\n",
        "    def __init__(self, layer, N):\n",
        "        super().__init__()\n",
        "        self.encoders = clones(layer, N)\n",
        "        self.layer_norm = torch.nn.LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        for encoder in self.encoders:\n",
        "            x = encoder(x, mask)\n",
        "        return self.layer_norm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaaW3kxPYKJ0"
      },
      "source": [
        "#### Unit test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us6AlVHQYKJ0",
        "outputId": "90bd49ed-5cfd-498d-c811-d90f9d598887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 10, 512]) Output shape: torch.Size([2, 10, 512])\n"
          ]
        }
      ],
      "source": [
        "# Test Encoder\n",
        "encoder = Encoder(encoder_layer, N=6)\n",
        "x = torch.randn(2, 10, 512)\n",
        "output = encoder(x, None)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVePvfNPYKJ4"
      },
      "source": [
        "## Decoder Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlY_E3cNYKJ4"
      },
      "source": [
        "Each decoder layer has three sub-layers: masked self-attention, cross-attention to encoder output, and feed-forward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0wh0VGK_YKJ4"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(torch.nn.Module):\n",
        "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.src_attn = src_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayers = clones(SublayerConnection(size, dropout), 3)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        x = self.sublayers[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
        "        x = self.sublayers[1](x, lambda x: self.src_attn(x, memory, memory, src_mask))\n",
        "        x = self.sublayers[2](x, self.feed_forward)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7UyBWKbYKJ5"
      },
      "source": [
        "#### Unit test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wvpcCxKYKJ5",
        "outputId": "435cdf06-3ff8-4a89-957d-000454d89fe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 10, 512]) Output shape: torch.Size([2, 10, 512])\n"
          ]
        }
      ],
      "source": [
        "# Test DecoderLayer\n",
        "attn1 = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
        "attn2 = MultiHeadedAttention(h=8, d_model=512, dropout=0.1)\n",
        "ff = PositionwiseFeedForward(d_model=512, d_ff=2048, dropout=0.1)\n",
        "decoder_layer = DecoderLayer(size=512, self_attn=attn1, src_attn=attn2, feed_forward=ff, dropout=0.1)\n",
        "x = torch.randn(2, 10, 512)\n",
        "memory = torch.randn(2, 10, 512)\n",
        "output = decoder_layer(x, memory, None, None)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8bENqquYKJ5"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujdjUogwYKJ5"
      },
      "source": [
        "Stack N decoder layers together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "e3H2_OpbYKJ5"
      },
      "outputs": [],
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "    def __init__(self, layer, N):\n",
        "        super().__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.layer_norm = torch.nn.LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, memory, src_mask, tgt_mask)\n",
        "        return self.layer_norm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHm_MdykYKJ5"
      },
      "source": [
        "### Unit test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgKJItrUYKJ5",
        "outputId": "c350251d-a984-4b5f-eca3-8712a03e058d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 10, 512]) Output shape: torch.Size([2, 10, 512])\n"
          ]
        }
      ],
      "source": [
        "# Test Decoder\n",
        "decoder = Decoder(decoder_layer, N=6)\n",
        "x = torch.randn(2, 10, 512)\n",
        "memory = torch.randn(2, 10, 512)\n",
        "output = decoder(x, memory, None, None)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI_Y53hRYKJ5"
      },
      "source": [
        "## Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVPryxt0YKJ5"
      },
      "source": [
        "Convert token IDs to dense vectors, scaled by sqrt(d_model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "G-KRA_LbYKJ5"
      },
      "outputs": [],
      "source": [
        "class Embeddings(torch.nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = torch.nn.Embedding(vocab, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.embedding(x) * math.sqrt(self.d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK9KXRAqYKJ5"
      },
      "source": [
        "### Unit test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CovbHRrcYKJ5",
        "outputId": "f8902856-6412-4162-9340-168c1d80cd72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 10]) Output shape: torch.Size([2, 10, 512])\n"
          ]
        }
      ],
      "source": [
        "# Test Embeddings\n",
        "emb = Embeddings(d_model=512, vocab=1000)\n",
        "x = torch.randint(0, 1000, (2, 10))\n",
        "output = emb(x)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNYJpgdeYKJ5"
      },
      "source": [
        "## Generator class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuKhN_SfYKJ5"
      },
      "source": [
        "Final linear layer + log softmax to convert decoder output to token probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "dLeOq1_-YKJ5"
      },
      "outputs": [],
      "source": [
        "class Generator(torch.nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super().__init__()\n",
        "        self.linear = torch.nn.Linear(d_model, vocab)\n",
        "        self.logsoftmax = torch.nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        return self.logsoftmax(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FChvEtaYKJ5"
      },
      "source": [
        "#### Unit test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAuRtnrRYKJ5",
        "outputId": "f4fa279c-8b45-4aec-f2ae-2218dd293b52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 10, 512]) Output shape: torch.Size([2, 10, 1000])\n"
          ]
        }
      ],
      "source": [
        "# Test Generator\n",
        "gen = Generator(d_model=512, vocab=1000)\n",
        "x = torch.randn(2, 10, 512)\n",
        "output = gen(x)\n",
        "print(\"Input shape:\", x.shape, \"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNK_TSs4YKJ5"
      },
      "source": [
        "### Final Encoder Decoder Function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YLMups-tYKJ5"
      },
      "outputs": [],
      "source": [
        "class EncoderDecoder(torch.nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.generator = generator\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        x = self.src_embed(src)\n",
        "        return self.encoder(x, src_mask)\n",
        "\n",
        "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
        "        x = self.tgt_embed(tgt)\n",
        "        return self.decoder(x, memory, src_mask, tgt_mask)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        memory = self.encode(src, src_mask)\n",
        "        return self.decode(memory, src_mask, tgt, tgt_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxxmcQx1YKJ6"
      },
      "source": [
        "## Make Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSCPH2V6YKJ6"
      },
      "source": [
        "Helper function to construct the full transformer model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Qq8X7156YKJ6"
      },
      "outputs": [],
      "source": [
        "def make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
        "    \"Construct transformer model from hyperparameters\"\n",
        "    multi_head_attentions = [copy.deepcopy(MultiHeadedAttention(h, d_model, dropout)) for _ in range(3)]\n",
        "    feedforward_layers = [copy.deepcopy(PositionwiseFeedForward(d_model, d_ff, dropout)) for _ in range(2)]\n",
        "    positional_encoding = [PositionalEncoding(d_model, dropout) for _ in range(2)]\n",
        "\n",
        "    src_embedding_layer = Embeddings(d_model, src_vocab)\n",
        "    tgt_embeddings_layer = Embeddings(d_model, tgt_vocab)\n",
        "    src_embed = torch.nn.Sequential(src_embedding_layer, positional_encoding[0])\n",
        "    tgt_embed = torch.nn.Sequential(tgt_embeddings_layer, positional_encoding[1])\n",
        "\n",
        "    encoder_layer = EncoderLayer(d_model, multi_head_attentions[0], feedforward_layers[0], dropout)\n",
        "    decoder_layer = DecoderLayer(d_model, multi_head_attentions[1], multi_head_attentions[2], feedforward_layers[1], dropout)\n",
        "\n",
        "    encoder = Encoder(encoder_layer, N)\n",
        "    decoder = Decoder(decoder_layer, N)\n",
        "    generator = Generator(d_model, tgt_vocab)\n",
        "\n",
        "    encoder_decoder = EncoderDecoder(encoder, decoder, src_embed, tgt_embed, generator)\n",
        "\n",
        "    for p in encoder_decoder.parameters():\n",
        "        if p.dim() > 1:\n",
        "            torch.nn.init.xavier_uniform_(p)\n",
        "\n",
        "    return encoder_decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxLFdaRnYKJ6"
      },
      "source": [
        "## Copy Code Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WSE8SQxYKJ6"
      },
      "source": [
        "Training utilities for the copy task (provided complete)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKAmZzqZYKJ6"
      },
      "source": [
        "### Final subsequent mask function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "i6MYQDluYKJ6"
      },
      "outputs": [],
      "source": [
        "def subsequent_mask(size):\n",
        "    \"Create mask to prevent attention to future positions\"\n",
        "    lower_t = torch.ones([size, size]).tril().bool()\n",
        "    lower_t = lower_t.unsqueeze(0)\n",
        "    return lower_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6cTSIJ_YKJ6"
      },
      "source": [
        "### Final Batch Class for copy example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vkOWxJvJYKJ6"
      },
      "outputs": [],
      "source": [
        "class Batch:\n",
        "    def __init__(self, src, tgt=None, pad=2):\n",
        "        self.src = src\n",
        "        self.src_mask = (src != pad).unsqueeze(-2)\n",
        "        if tgt is not None:\n",
        "            self.tgt = tgt[:, :-1]\n",
        "            self.tgt_y = tgt[:,1:]\n",
        "            self.pad_tgt_mask = (self.tgt!=pad).unsqueeze(-2)\n",
        "            self.subseq_tgt_mask = subsequent_mask(self.tgt.size(1))\n",
        "            self.tgt_mask = self.pad_tgt_mask & self.subseq_tgt_mask\n",
        "            self.ntokens = (self.tgt_y!=pad).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9m1_U_aYKJ6"
      },
      "source": [
        "### Final Data Gen Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1fV1XXmsYKJ6"
      },
      "outputs": [],
      "source": [
        "def data_gen(V, batch_size, nbatches):\n",
        "    \"Generate random data for a src-tgt copy task\"\n",
        "    for i in range(nbatches):\n",
        "        random_int = np.random.randint(1, V, size=[batch_size, 10])\n",
        "        random_int[:,0] = 1\n",
        "        random_int = torch.tensor(random_int)\n",
        "        src = random_int\n",
        "        tgt = random_int\n",
        "        yield Batch(src, tgt, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKe1DbfXYKJ6"
      },
      "source": [
        "### Final Simple Loss Compute Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "YmjyUZQDYKJ6"
      },
      "outputs": [],
      "source": [
        "class SimpleLossCompute:\n",
        "    def __init__(self, generator, criterion):\n",
        "        self.generator = generator\n",
        "        self.criterion = criterion\n",
        "\n",
        "    def __call__(self, x, y, norm):\n",
        "        pred = self.generator(x)\n",
        "        vocab = pred.size(-1)\n",
        "        pred_flat = pred.reshape(-1, vocab)\n",
        "        y_flat = y.reshape(-1)\n",
        "        loss = self.criterion(pred_flat, y_flat) / norm\n",
        "        return loss.data * norm, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm43MoW2YKJ6"
      },
      "source": [
        "### Final Run Epoch Function for Copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "E3Z-FihpYKJ6"
      },
      "outputs": [],
      "source": [
        "def run_epoch(data_iter, model, loss_compute, optimizer, scheduler, mode=\"train\"):\n",
        "    total_tokens = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(data_iter):\n",
        "        pred = model(batch.src, batch.tgt, batch.src_mask, batch.tgt_mask)\n",
        "        num_loss, tensor_loss = loss_compute(pred, batch.tgt_y, batch.ntokens)\n",
        "        if mode == \"train\":\n",
        "            tensor_loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            scheduler.step()\n",
        "        total_loss += num_loss\n",
        "        total_tokens += batch.ntokens\n",
        "\n",
        "    return total_loss / total_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6jPYTjZYKJ6"
      },
      "source": [
        "### Greedy Decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "v6hJyeY8YKJ6"
      },
      "outputs": [],
      "source": [
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.LongTensor([[start_symbol]])\n",
        "    for _ in range(max_len - 1):\n",
        "        tgt_mask = subsequent_mask(ys.size(1))\n",
        "        x = model.decode(memory, src_mask, ys, tgt_mask)\n",
        "        pred = model.generator(x[:, -1])\n",
        "        _, max_indices = torch.max(pred, dim=-1)\n",
        "        max_indices = max_indices.data[0]\n",
        "        ys = torch.cat([ys, torch.ones(1,1).type_as(src.data).fill_(max_indices)], dim=-1)\n",
        "    return ys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQQOo9nWYKJ6"
      },
      "source": [
        "### Training Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Lm_FQb9YKJ6",
        "outputId": "24c6cfcf-8f2e-4884-892e-5ef7262c47fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training...\n",
            "Epoch 0 Loss: 0.0111\n",
            "Epoch 1 Loss: 0.0093\n",
            "Epoch 2 Loss: 0.0085\n",
            "Epoch 3 Loss: 0.0078\n",
            "Epoch 4 Loss: 0.0073\n",
            "Epoch 5 Loss: 0.0069\n",
            "Epoch 6 Loss: 0.0066\n",
            "Epoch 7 Loss: 0.0061\n",
            "Epoch 8 Loss: 0.0055\n",
            "Epoch 9 Loss: 0.0049\n",
            "Epoch 10 Loss: 0.0045\n",
            "Epoch 11 Loss: 0.0039\n",
            "Epoch 12 Loss: 0.0032\n",
            "Epoch 13 Loss: 0.0029\n",
            "Epoch 14 Loss: 0.0023\n",
            "Epoch 15 Loss: 0.0020\n",
            "Epoch 16 Loss: 0.0017\n",
            "Epoch 17 Loss: 0.0016\n",
            "Epoch 18 Loss: 0.0013\n",
            "Epoch 19 Loss: 0.0011\n",
            "Epoch 20 Loss: 0.0010\n",
            "Epoch 21 Loss: 0.0008\n",
            "Epoch 22 Loss: 0.0007\n",
            "Epoch 23 Loss: 0.0007\n",
            "Epoch 24 Loss: 0.0006\n",
            "Epoch 25 Loss: 0.0006\n",
            "Epoch 26 Loss: 0.0005\n",
            "Epoch 27 Loss: 0.0005\n",
            "Epoch 28 Loss: 0.0005\n",
            "Epoch 29 Loss: 0.0004\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "# Create small model for testing\n",
        "V = 11\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "model = make_model(V, V, N=2, d_model=64, d_ff=128, h=4, dropout=0.1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.5, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "def rate(step, model_size=64, factor=1.0, warmup=400):\n",
        "    if step == 0:\n",
        "        step = 1\n",
        "    return factor * (model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5)))\n",
        "\n",
        "scheduler = LambdaLR(optimizer, lr_lambda=lambda step: rate(step))\n",
        "\n",
        "print(\"Training...\")\n",
        "for epoch in range(30):\n",
        "    model.train()\n",
        "    loss_compute = SimpleLossCompute(model.generator, criterion)\n",
        "    loss = run_epoch(data_gen(V, batch_size=30, nbatches=20), model, loss_compute, optimizer, scheduler, mode=\"train\")\n",
        "    print(f\"Epoch {epoch} Loss: {loss:.4f}\")\n",
        "\n",
        "print(\"\\nTraining complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWfIxqBKYKJ7"
      },
      "source": [
        "### Test Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDW2XCgTYKJ7",
        "outputId": "3534850f-8024-4957-8de4-48b6c08e59ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source: tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
            "Generated: tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
            "\n",
            "Success! True\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "src = torch.LongTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
        "src_mask = torch.ones(1, 1, 10)\n",
        "\n",
        "print(\"Source:\", src)\n",
        "result = greedy_decode(model, src, src_mask, max_len=10, start_symbol=1)\n",
        "print(\"Generated:\", result)\n",
        "print(\"\\nSuccess!\", torch.equal(src, result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u77lIto4YKJ7"
      },
      "source": [
        "## ðŸŽ‰ Congratulations! ðŸŽ‰"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk_cf7OCYKJ7"
      },
      "source": [
        "You've implemented a Transformer from scratch and trained it successfully!\n",
        "\n",
        "### Resources:\n",
        "- [Original Paper](https://arxiv.org/pdf/1706.03762)\n",
        "- [Harvard NLP Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CPtSD4Y_YkL6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "annotated-transformer",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}